{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import helper\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yannn\\AppData\\Local\\Temp\\ipykernel_24956\\4143636409.py:1: DtypeWarning: Columns (8,11,13,14,15,17,18,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('images\\metadata.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>acquisition_day</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>dermoscopic_type</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>mel_type</th>\n",
       "      <th>mel_ulcer</th>\n",
       "      <th>melanocytic</th>\n",
       "      <th>nevus_type</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>personal_hx_mm</th>\n",
       "      <th>pixels_x</th>\n",
       "      <th>pixels_y</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_3491559</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>benign</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seborrheic keratosis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_0918668</td>\n",
       "      <td>False</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_3622379</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>8.8</td>\n",
       "      <td>contact polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_6028537</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_2443008</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>malignant</td>\n",
       "      <td>7.7</td>\n",
       "      <td>non-contact polarized</td>\n",
       "      <td>squamous cell carcinoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_2891227</td>\n",
       "      <td>False</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_6892286</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>9.4</td>\n",
       "      <td>contact polarized</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_3056186</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_1979534</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>malignant</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>squamous cell carcinoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_2084621</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id                             attribution copyright_license  \\\n",
       "0  ISIC_3491559  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "1  ISIC_3622379  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "2  ISIC_2443008  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "3  ISIC_6892286  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "4  ISIC_1979534  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "\n",
       "   acquisition_day  age_approx anatom_site_general benign_malignant  \\\n",
       "0              NaN        45.0     upper extremity           benign   \n",
       "1              NaN        65.0     posterior torso           benign   \n",
       "2              NaN        45.0     upper extremity        malignant   \n",
       "3              NaN        75.0     posterior torso        malignant   \n",
       "4              NaN        80.0           head/neck        malignant   \n",
       "\n",
       "   clin_size_long_diam_mm       dermoscopic_type                diagnosis  \\\n",
       "0                     1.4                    NaN     seborrheic keratosis   \n",
       "1                     8.8      contact polarized                    nevus   \n",
       "2                     7.7  non-contact polarized  squamous cell carcinoma   \n",
       "3                     9.4      contact polarized                 melanoma   \n",
       "4                    20.0                    NaN  squamous cell carcinoma   \n",
       "\n",
       "   ... mel_thick_mm mel_type mel_ulcer melanocytic nevus_type  patient_id  \\\n",
       "0  ...          NaN      NaN       NaN        True        NaN  IP_0918668   \n",
       "1  ...          NaN      NaN       NaN        True        NaN  IP_6028537   \n",
       "2  ...          NaN      NaN       NaN       False        NaN  IP_2891227   \n",
       "3  ...          0.3      NaN     False        True        NaN  IP_3056186   \n",
       "4  ...          NaN      NaN       NaN       False        NaN  IP_2084621   \n",
       "\n",
       "   personal_hx_mm pixels_x pixels_y     sex  \n",
       "0           False     3264     2448  female  \n",
       "1            True     3264     2448    male  \n",
       "2           False     3264     2448    male  \n",
       "3            True     3264     2448    male  \n",
       "4            True     3264     2448    male  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('images\\metadata.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isic_id', 'attribution', 'copyright_license', 'acquisition_day', 'age_approx', 'anatom_site_general', 'benign_malignant', 'clin_size_long_diam_mm', 'dermoscopic_type', 'diagnosis', 'diagnosis_confirm_type', 'family_hx_mm', 'image_type', 'lesion_id', 'mel_class', 'mel_mitotic_index', 'mel_thick_mm', 'mel_type', 'mel_ulcer', 'melanocytic', 'nevus_type', 'patient_id', 'personal_hx_mm', 'pixels_x', 'pixels_y', 'sex']\n"
     ]
    }
   ],
   "source": [
    "columns = data.columns.tolist()\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>acquisition_day</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_confirm_type</th>\n",
       "      <th>...</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>mel_type</th>\n",
       "      <th>mel_ulcer</th>\n",
       "      <th>melanocytic</th>\n",
       "      <th>nevus_type</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>personal_hx_mm</th>\n",
       "      <th>pixels_x</th>\n",
       "      <th>pixels_y</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dermoscopic_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contact non-polarized</th>\n",
       "      <td>10097</td>\n",
       "      <td>10097</td>\n",
       "      <td>10097</td>\n",
       "      <td>7945</td>\n",
       "      <td>10017</td>\n",
       "      <td>9604</td>\n",
       "      <td>10086</td>\n",
       "      <td>240</td>\n",
       "      <td>2100</td>\n",
       "      <td>10096</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>543</td>\n",
       "      <td>7963</td>\n",
       "      <td>7969</td>\n",
       "      <td>10097</td>\n",
       "      <td>10097</td>\n",
       "      <td>9991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact polarized</th>\n",
       "      <td>4925</td>\n",
       "      <td>4925</td>\n",
       "      <td>4925</td>\n",
       "      <td>1892</td>\n",
       "      <td>4911</td>\n",
       "      <td>2299</td>\n",
       "      <td>4925</td>\n",
       "      <td>459</td>\n",
       "      <td>4925</td>\n",
       "      <td>4924</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>4925</td>\n",
       "      <td>25</td>\n",
       "      <td>4833</td>\n",
       "      <td>466</td>\n",
       "      <td>4925</td>\n",
       "      <td>4925</td>\n",
       "      <td>4907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-contact polarized</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       isic_id  attribution  copyright_license  \\\n",
       "dermoscopic_type                                                 \n",
       "contact non-polarized    10097        10097              10097   \n",
       "contact polarized         4925         4925               4925   \n",
       "non-contact polarized       49           49                 49   \n",
       "\n",
       "                       acquisition_day  age_approx  anatom_site_general  \\\n",
       "dermoscopic_type                                                          \n",
       "contact non-polarized             7945       10017                 9604   \n",
       "contact polarized                 1892        4911                 2299   \n",
       "non-contact polarized                0          49                   49   \n",
       "\n",
       "                       benign_malignant  clin_size_long_diam_mm  diagnosis  \\\n",
       "dermoscopic_type                                                             \n",
       "contact non-polarized             10086                     240       2100   \n",
       "contact polarized                  4925                     459       4925   \n",
       "non-contact polarized                49                      46         49   \n",
       "\n",
       "                       diagnosis_confirm_type  ...  mel_thick_mm  mel_type  \\\n",
       "dermoscopic_type                               ...                           \n",
       "contact non-polarized                   10096  ...             6         5   \n",
       "contact polarized                        4924  ...            78        28   \n",
       "non-contact polarized                      49  ...             6         0   \n",
       "\n",
       "                       mel_ulcer  melanocytic  nevus_type  patient_id  \\\n",
       "dermoscopic_type                                                        \n",
       "contact non-polarized          6         1958         543        7963   \n",
       "contact polarized             44         4925          25        4833   \n",
       "non-contact polarized          5           49           1          46   \n",
       "\n",
       "                       personal_hx_mm  pixels_x  pixels_y   sex  \n",
       "dermoscopic_type                                                 \n",
       "contact non-polarized            7969     10097     10097  9991  \n",
       "contact polarized                 466      4925      4925  4907  \n",
       "non-contact polarized              49        49        49    49  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.df_groupby_count(data, 'dermoscopic_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>acquisition_day</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>dermoscopic_type</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>mel_type</th>\n",
       "      <th>mel_ulcer</th>\n",
       "      <th>melanocytic</th>\n",
       "      <th>nevus_type</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>personal_hx_mm</th>\n",
       "      <th>pixels_x</th>\n",
       "      <th>pixels_y</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ISIC_9381247</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>4.1</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4340091</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ISIC_4701313</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>8.9</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>squamous cell carcinoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_5789947</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ISIC_1300267</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>7.1</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>lichenoid keratosis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_2712283</td>\n",
       "      <td>False</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ISIC_1474512</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>benign</td>\n",
       "      <td>2.2</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4633465</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ISIC_3654066</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>palms/soles</td>\n",
       "      <td>benign</td>\n",
       "      <td>3.5</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4468352</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          isic_id                             attribution copyright_license  \\\n",
       "10   ISIC_9381247  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "22   ISIC_4701313  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "26   ISIC_1300267  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "60   ISIC_1474512  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "127  ISIC_3654066  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "\n",
       "     acquisition_day  age_approx anatom_site_general benign_malignant  \\\n",
       "10               NaN        45.0      anterior torso           benign   \n",
       "22               NaN        75.0      anterior torso        malignant   \n",
       "26               NaN        65.0     posterior torso           benign   \n",
       "60               NaN        70.0     lower extremity           benign   \n",
       "127              NaN        25.0         palms/soles           benign   \n",
       "\n",
       "     clin_size_long_diam_mm       dermoscopic_type                diagnosis  \\\n",
       "10                      4.1  contact non-polarized                    nevus   \n",
       "22                      8.9  contact non-polarized  squamous cell carcinoma   \n",
       "26                      7.1  contact non-polarized      lichenoid keratosis   \n",
       "60                      2.2  contact non-polarized                    nevus   \n",
       "127                     3.5  contact non-polarized                    nevus   \n",
       "\n",
       "     ... mel_thick_mm mel_type mel_ulcer melanocytic nevus_type  patient_id  \\\n",
       "10   ...          NaN      NaN       NaN        True        NaN  IP_4340091   \n",
       "22   ...          NaN      NaN       NaN       False        NaN  IP_5789947   \n",
       "26   ...          NaN      NaN       NaN       False        NaN  IP_2712283   \n",
       "60   ...          NaN      NaN       NaN        True        NaN  IP_4633465   \n",
       "127  ...          NaN      NaN       NaN        True        NaN  IP_4468352   \n",
       "\n",
       "     personal_hx_mm pixels_x pixels_y     sex  \n",
       "10             True     3264     2448    male  \n",
       "22             True     3264     2448  female  \n",
       "26            False     3264     2448    male  \n",
       "60             True     3264     2448    male  \n",
       "127            True     3264     2448  female  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_contact = data.loc[data.dermoscopic_type == 'contact non-polarized', :]\n",
    "data_no_contact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>acquisition_day</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>dermoscopic_type</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_confirm_type</th>\n",
       "      <th>...</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>mel_type</th>\n",
       "      <th>mel_ulcer</th>\n",
       "      <th>melanocytic</th>\n",
       "      <th>nevus_type</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>personal_hx_mm</th>\n",
       "      <th>pixels_x</th>\n",
       "      <th>pixels_y</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anterior torso</th>\n",
       "      <td>1564</td>\n",
       "      <td>1564</td>\n",
       "      <td>1564</td>\n",
       "      <td>1240</td>\n",
       "      <td>1552</td>\n",
       "      <td>1560</td>\n",
       "      <td>31</td>\n",
       "      <td>1564</td>\n",
       "      <td>309</td>\n",
       "      <td>1564</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>54</td>\n",
       "      <td>1243</td>\n",
       "      <td>1245</td>\n",
       "      <td>1564</td>\n",
       "      <td>1564</td>\n",
       "      <td>1541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head/neck</th>\n",
       "      <td>913</td>\n",
       "      <td>913</td>\n",
       "      <td>913</td>\n",
       "      <td>648</td>\n",
       "      <td>908</td>\n",
       "      <td>911</td>\n",
       "      <td>22</td>\n",
       "      <td>913</td>\n",
       "      <td>232</td>\n",
       "      <td>913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>35</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>913</td>\n",
       "      <td>913</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lateral torso</th>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>211</td>\n",
       "      <td>271</td>\n",
       "      <td>277</td>\n",
       "      <td>9</td>\n",
       "      <td>277</td>\n",
       "      <td>65</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lower extremity</th>\n",
       "      <td>2133</td>\n",
       "      <td>2133</td>\n",
       "      <td>2133</td>\n",
       "      <td>1768</td>\n",
       "      <td>2116</td>\n",
       "      <td>2130</td>\n",
       "      <td>56</td>\n",
       "      <td>2133</td>\n",
       "      <td>361</td>\n",
       "      <td>2133</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>335</td>\n",
       "      <td>91</td>\n",
       "      <td>1773</td>\n",
       "      <td>1775</td>\n",
       "      <td>2133</td>\n",
       "      <td>2133</td>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oral/genital</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palms/soles</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posterior torso</th>\n",
       "      <td>2883</td>\n",
       "      <td>2883</td>\n",
       "      <td>2883</td>\n",
       "      <td>2468</td>\n",
       "      <td>2863</td>\n",
       "      <td>2883</td>\n",
       "      <td>68</td>\n",
       "      <td>2883</td>\n",
       "      <td>442</td>\n",
       "      <td>2883</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>388</td>\n",
       "      <td>113</td>\n",
       "      <td>2472</td>\n",
       "      <td>2475</td>\n",
       "      <td>2883</td>\n",
       "      <td>2883</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upper extremity</th>\n",
       "      <td>1809</td>\n",
       "      <td>1809</td>\n",
       "      <td>1809</td>\n",
       "      <td>1448</td>\n",
       "      <td>1792</td>\n",
       "      <td>1807</td>\n",
       "      <td>44</td>\n",
       "      <td>1809</td>\n",
       "      <td>343</td>\n",
       "      <td>1809</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>65</td>\n",
       "      <td>1448</td>\n",
       "      <td>1449</td>\n",
       "      <td>1809</td>\n",
       "      <td>1809</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     isic_id  attribution  copyright_license  acquisition_day  \\\n",
       "anatom_site_general                                                             \n",
       "anterior torso          1564         1564               1564             1240   \n",
       "head/neck                913          913                913              648   \n",
       "lateral torso            277          277                277              211   \n",
       "lower extremity         2133         2133               2133             1768   \n",
       "oral/genital               1            1                  1                1   \n",
       "palms/soles               24           24                 24               12   \n",
       "posterior torso         2883         2883               2883             2468   \n",
       "upper extremity         1809         1809               1809             1448   \n",
       "\n",
       "                     age_approx  benign_malignant  clin_size_long_diam_mm  \\\n",
       "anatom_site_general                                                         \n",
       "anterior torso             1552              1560                      31   \n",
       "head/neck                   908               911                      22   \n",
       "lateral torso               271               277                       9   \n",
       "lower extremity            2116              2130                      56   \n",
       "oral/genital                  1                 1                       0   \n",
       "palms/soles                  22                24                       2   \n",
       "posterior torso            2863              2883                      68   \n",
       "upper extremity            1792              1807                      44   \n",
       "\n",
       "                     dermoscopic_type  diagnosis  diagnosis_confirm_type  ...  \\\n",
       "anatom_site_general                                                       ...   \n",
       "anterior torso                   1564        309                    1564  ...   \n",
       "head/neck                         913        232                     913  ...   \n",
       "lateral torso                     277         65                     277  ...   \n",
       "lower extremity                  2133        361                    2133  ...   \n",
       "oral/genital                        1          0                       1  ...   \n",
       "palms/soles                        24          9                      24  ...   \n",
       "posterior torso                  2883        442                    2883  ...   \n",
       "upper extremity                  1809        343                    1809  ...   \n",
       "\n",
       "                     mel_thick_mm  mel_type  mel_ulcer  melanocytic  \\\n",
       "anatom_site_general                                                   \n",
       "anterior torso                  1         1          0          289   \n",
       "head/neck                       0         0          0          223   \n",
       "lateral torso                   0         0          1           60   \n",
       "lower extremity                 1         2          2          335   \n",
       "oral/genital                    0         0          0            0   \n",
       "palms/soles                     0         0          0            9   \n",
       "posterior torso                 2         0          1          388   \n",
       "upper extremity                 1         1          1          317   \n",
       "\n",
       "                     nevus_type  patient_id  personal_hx_mm  pixels_x  \\\n",
       "anatom_site_general                                                     \n",
       "anterior torso               54        1243            1245      1564   \n",
       "head/neck                    35         650             650       913   \n",
       "lateral torso                10         212             212       277   \n",
       "lower extremity              91        1773            1775      2133   \n",
       "oral/genital                  0           1               1         1   \n",
       "palms/soles                   2          13              13        24   \n",
       "posterior torso             113        2472            2475      2883   \n",
       "upper extremity              65        1448            1449      1809   \n",
       "\n",
       "                     pixels_y   sex  \n",
       "anatom_site_general                  \n",
       "anterior torso           1564  1541  \n",
       "head/neck                 913   911  \n",
       "lateral torso             277   273  \n",
       "lower extremity          2133  2107  \n",
       "oral/genital                1     1  \n",
       "palms/soles                24    19  \n",
       "posterior torso          2883  2859  \n",
       "upper extremity          1809  1790  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.df_groupby_count(data_no_contact, 'anatom_site_general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>acquisition_day</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>dermoscopic_type</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>mel_type</th>\n",
       "      <th>mel_ulcer</th>\n",
       "      <th>melanocytic</th>\n",
       "      <th>nevus_type</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>personal_hx_mm</th>\n",
       "      <th>pixels_x</th>\n",
       "      <th>pixels_y</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ISIC_9381247</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>4.1</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4340091</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ISIC_4701313</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>8.9</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>squamous cell carcinoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_5789947</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ISIC_1300267</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>7.1</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>lichenoid keratosis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_2712283</td>\n",
       "      <td>False</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ISIC_1474512</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>benign</td>\n",
       "      <td>2.2</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4633465</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ISIC_3654066</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>palms/soles</td>\n",
       "      <td>benign</td>\n",
       "      <td>3.5</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4468352</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          isic_id                             attribution copyright_license  \\\n",
       "10   ISIC_9381247  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "22   ISIC_4701313  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "26   ISIC_1300267  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "60   ISIC_1474512  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "127  ISIC_3654066  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "\n",
       "     acquisition_day  age_approx anatom_site_general benign_malignant  \\\n",
       "10               NaN        45.0      anterior torso           benign   \n",
       "22               NaN        75.0      anterior torso        malignant   \n",
       "26               NaN        65.0     posterior torso           benign   \n",
       "60               NaN        70.0     lower extremity           benign   \n",
       "127              NaN        25.0         palms/soles           benign   \n",
       "\n",
       "     clin_size_long_diam_mm       dermoscopic_type                diagnosis  \\\n",
       "10                      4.1  contact non-polarized                    nevus   \n",
       "22                      8.9  contact non-polarized  squamous cell carcinoma   \n",
       "26                      7.1  contact non-polarized      lichenoid keratosis   \n",
       "60                      2.2  contact non-polarized                    nevus   \n",
       "127                     3.5  contact non-polarized                    nevus   \n",
       "\n",
       "     ... mel_thick_mm mel_type mel_ulcer melanocytic nevus_type  patient_id  \\\n",
       "10   ...          NaN      NaN       NaN        True        NaN  IP_4340091   \n",
       "22   ...          NaN      NaN       NaN       False        NaN  IP_5789947   \n",
       "26   ...          NaN      NaN       NaN       False        NaN  IP_2712283   \n",
       "60   ...          NaN      NaN       NaN        True        NaN  IP_4633465   \n",
       "127  ...          NaN      NaN       NaN        True        NaN  IP_4468352   \n",
       "\n",
       "     personal_hx_mm pixels_x pixels_y     sex  \n",
       "10             True     3264     2448    male  \n",
       "22             True     3264     2448  female  \n",
       "26            False     3264     2448    male  \n",
       "60             True     3264     2448    male  \n",
       "127            True     3264     2448  female  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_anatomic_filter = data_no_contact[~data_no_contact[\"anatom_site_general\"].isin(['oral/genital', 'palm/soles'])]\n",
    "data_anatomic_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nevus                                 1237\n",
       "melanoma                               457\n",
       "seborrheic keratosis                   284\n",
       "basal cell carcinoma                    28\n",
       "other                                   18\n",
       "solar lentigo                           17\n",
       "lentigo simplex                         15\n",
       "angioma                                 12\n",
       "lichenoid keratosis                      6\n",
       "squamous cell carcinoma                  6\n",
       "dermatofibroma                           5\n",
       "lentigo NOS                              5\n",
       "scar                                     3\n",
       "angiofibroma or fibrous papule           2\n",
       "atypical melanocytic proliferation       2\n",
       "pigmented benign keratosis               1\n",
       "acrochordon                              1\n",
       "melanoma metastasis                      1\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_anatomic_filter.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>acquisition_day</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>dermoscopic_type</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>mel_type</th>\n",
       "      <th>mel_ulcer</th>\n",
       "      <th>melanocytic</th>\n",
       "      <th>nevus_type</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>personal_hx_mm</th>\n",
       "      <th>pixels_x</th>\n",
       "      <th>pixels_y</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ISIC_9381247</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>4.1</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4340091</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ISIC_1474512</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>benign</td>\n",
       "      <td>2.2</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4633465</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ISIC_3654066</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>palms/soles</td>\n",
       "      <td>benign</td>\n",
       "      <td>3.5</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_4468352</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>ISIC_9572761</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>5.8</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_3889950</td>\n",
       "      <td>True</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ISIC_4094938</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>3.5</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>nevus</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_7346735</td>\n",
       "      <td>False</td>\n",
       "      <td>3264</td>\n",
       "      <td>2448</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          isic_id                             attribution copyright_license  \\\n",
       "10   ISIC_9381247  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "60   ISIC_1474512  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "127  ISIC_3654066  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "130  ISIC_9572761  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "195  ISIC_4094938  Memorial Sloan Kettering Cancer Center              CC-0   \n",
       "\n",
       "     acquisition_day  age_approx anatom_site_general benign_malignant  \\\n",
       "10               NaN        45.0      anterior torso           benign   \n",
       "60               NaN        70.0     lower extremity           benign   \n",
       "127              NaN        25.0         palms/soles           benign   \n",
       "130              NaN        75.0     posterior torso        malignant   \n",
       "195              NaN        65.0     posterior torso           benign   \n",
       "\n",
       "     clin_size_long_diam_mm       dermoscopic_type diagnosis  ...  \\\n",
       "10                      4.1  contact non-polarized     nevus  ...   \n",
       "60                      2.2  contact non-polarized     nevus  ...   \n",
       "127                     3.5  contact non-polarized     nevus  ...   \n",
       "130                     5.8  contact non-polarized  melanoma  ...   \n",
       "195                     3.5  contact non-polarized     nevus  ...   \n",
       "\n",
       "    mel_thick_mm mel_type mel_ulcer melanocytic nevus_type  patient_id  \\\n",
       "10           NaN      NaN       NaN        True        NaN  IP_4340091   \n",
       "60           NaN      NaN       NaN        True        NaN  IP_4633465   \n",
       "127          NaN      NaN       NaN        True        NaN  IP_4468352   \n",
       "130         0.35      NaN     False        True        NaN  IP_3889950   \n",
       "195          NaN      NaN       NaN        True        NaN  IP_7346735   \n",
       "\n",
       "     personal_hx_mm pixels_x pixels_y     sex  \n",
       "10             True     3264     2448    male  \n",
       "60             True     3264     2448    male  \n",
       "127            True     3264     2448  female  \n",
       "130            True     3264     2448    male  \n",
       "195           False     3264     2448  female  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diagnosis_filter = helper.df_group_drop_min_count(data_anatomic_filter, 'diagnosis')\n",
    "\n",
    "data_diagnosis_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nevus                   1237\n",
       "melanoma                 457\n",
       "seborrheic keratosis     284\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_diagnosis_filter.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diagnosis_filter = data_diagnosis_filter[data_diagnosis_filter[\"benign_malignant\"].isin(['benign', 'malignant'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>acquisition_day</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>dermoscopic_type</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>mel_thick_mm</th>\n",
       "      <th>mel_type</th>\n",
       "      <th>mel_ulcer</th>\n",
       "      <th>melanocytic</th>\n",
       "      <th>nevus_type</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>personal_hx_mm</th>\n",
       "      <th>pixels_x</th>\n",
       "      <th>pixels_y</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0013581</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>malignant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4288</td>\n",
       "      <td>2848</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0013184</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3872</td>\n",
       "      <td>2592</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015251</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6688</td>\n",
       "      <td>4459</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0011474</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6661</td>\n",
       "      <td>4441</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_6539127</td>\n",
       "      <td>The University of Queensland Diamantina Instit...</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact non-polarized</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IP_6021072</td>\n",
       "      <td>True</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id                                        attribution  \\\n",
       "0  ISIC_0013581                                          Anonymous   \n",
       "1  ISIC_0013184                                          Anonymous   \n",
       "2  ISIC_0015251                                          Anonymous   \n",
       "3  ISIC_0011474                                          Anonymous   \n",
       "4  ISIC_6539127  The University of Queensland Diamantina Instit...   \n",
       "\n",
       "  copyright_license  acquisition_day  age_approx anatom_site_general  \\\n",
       "0              CC-0              NaN        60.0     upper extremity   \n",
       "1              CC-0              NaN        55.0      anterior torso   \n",
       "2              CC-0              NaN        45.0     posterior torso   \n",
       "3              CC-0              NaN        45.0     posterior torso   \n",
       "4             CC-BY              1.0        65.0     posterior torso   \n",
       "\n",
       "  benign_malignant  clin_size_long_diam_mm       dermoscopic_type diagnosis  \\\n",
       "0        malignant                     NaN  contact non-polarized  melanoma   \n",
       "1        malignant                     NaN  contact non-polarized  melanoma   \n",
       "2        malignant                     NaN  contact non-polarized  melanoma   \n",
       "3        malignant                     NaN  contact non-polarized  melanoma   \n",
       "4        malignant                     NaN  contact non-polarized  melanoma   \n",
       "\n",
       "   ... mel_thick_mm mel_type mel_ulcer melanocytic nevus_type  patient_id  \\\n",
       "0  ...          NaN      NaN       NaN        True        NaN         NaN   \n",
       "1  ...          NaN      NaN       NaN        True        NaN         NaN   \n",
       "2  ...          NaN      NaN       NaN        True        NaN         NaN   \n",
       "3  ...          NaN      NaN       NaN        True        NaN         NaN   \n",
       "4  ...          NaN      NaN       NaN         NaN        NaN  IP_6021072   \n",
       "\n",
       "   personal_hx_mm pixels_x pixels_y     sex  \n",
       "0             NaN     4288     2848  female  \n",
       "1             NaN     3872     2592    male  \n",
       "2             NaN     6688     4459  female  \n",
       "3             NaN     6661     4441    male  \n",
       "4            True     6000     4000  female  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = helper.df_sample_by_column_value(data_diagnosis_filter, 'diagnosis', 284)\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0013581</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0013184</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015251</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0011474</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_6539127</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id diagnosis benign_malignant\n",
       "0  ISIC_0013581  melanoma        malignant\n",
       "1  ISIC_0013184  melanoma        malignant\n",
       "2  ISIC_0015251  melanoma        malignant\n",
       "3  ISIC_0011474  melanoma        malignant\n",
       "4  ISIC_6539127  melanoma        malignant"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data_clean[['isic_id', 'diagnosis', 'benign_malignant']]\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "melanoma                284\n",
       "nevus                   284\n",
       "seborrheic keratosis    284\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [name + '.jpg' for name in data_clean.isic_id.tolist()]\n",
    "labels = data_clean.diagnosis.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'melanoma': 0, 'nevus': 1, 'seborrheic keratosis': 2}\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "encoded = le.fit_transform(labels)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx, trainy, testy = model_selection.train_test_split(images, encoded, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, valx, trainy, valy = model_selection.train_test_split(trainx, trainy, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(images, labels, name):\n",
    "    df = pd.DataFrame(((i, l) for i, l in zip(images, labels)), \n",
    "                      columns=['images', 'labels'])\n",
    "    df.to_csv(f'{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_csv(trainx,trainy,'subset/train')\n",
    "make_csv(valx,valy,'subset/val')\n",
    "make_csv(testx,testy,'subset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from imagenet import ImageNetLightningModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "*************** Loading model vgg19\n",
      "********************************************************************************\n",
      "\n",
      "Sanity Checking: 0it [00:00, ?it/s]\n",
      "Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:02<00:02,  2.59s/it]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]\n",
      "                                                                           \n",
      "\n",
      "Training: 0it [00:00, ?it/s]\n",
      "Training:   0%|          | 0/38 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/38 [00:00<?, ?it/s] \n",
      "Epoch 0:   3%|▎         | 1/38 [00:18<11:36, 18.82s/it]\n",
      "Epoch 0:   3%|▎         | 1/38 [00:18<11:37, 18.84s/it, loss=1.13, v_num=33, train_acc1_step=18.80]\n",
      "Epoch 0:   5%|▌         | 2/38 [00:18<05:41,  9.50s/it, loss=1.13, v_num=33, train_acc1_step=18.80]\n",
      "Epoch 0:   5%|▌         | 2/38 [00:19<05:42,  9.50s/it, loss=1.25, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:   8%|▊         | 3/38 [00:19<03:43,  6.39s/it, loss=1.25, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:   8%|▊         | 3/38 [00:19<03:43,  6.39s/it, loss=1.21, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  11%|█         | 4/38 [00:19<02:44,  4.83s/it, loss=1.21, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  11%|█         | 4/38 [00:19<02:44,  4.83s/it, loss=1.19, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  13%|█▎        | 5/38 [00:21<02:24,  4.37s/it, loss=1.19, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  13%|█▎        | 5/38 [00:21<02:24,  4.37s/it, loss=1.17, v_num=33, train_acc1_step=18.80]\n",
      "Epoch 0:  16%|█▌        | 6/38 [00:22<01:57,  3.67s/it, loss=1.17, v_num=33, train_acc1_step=18.80]\n",
      "Epoch 0:  16%|█▌        | 6/38 [00:22<01:57,  3.67s/it, loss=1.16, v_num=33, train_acc1_step=31.20]\n",
      "Epoch 0:  18%|█▊        | 7/38 [00:22<01:38,  3.17s/it, loss=1.16, v_num=33, train_acc1_step=31.20]\n",
      "Epoch 0:  18%|█▊        | 7/38 [00:22<01:38,  3.17s/it, loss=1.15, v_num=33, train_acc1_step=37.50]\n",
      "Epoch 0:  21%|██        | 8/38 [00:22<01:23,  2.79s/it, loss=1.15, v_num=33, train_acc1_step=37.50]\n",
      "Epoch 0:  21%|██        | 8/38 [00:22<01:23,  2.79s/it, loss=1.15, v_num=33, train_acc1_step=37.50]\n",
      "Epoch 0:  24%|██▎       | 9/38 [00:26<01:23,  2.89s/it, loss=1.15, v_num=33, train_acc1_step=37.50]\n",
      "Epoch 0:  24%|██▎       | 9/38 [00:26<01:23,  2.89s/it, loss=1.14, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  26%|██▋       | 10/38 [00:26<01:13,  2.62s/it, loss=1.14, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  26%|██▋       | 10/38 [00:26<01:13,  2.62s/it, loss=1.14, v_num=33, train_acc1_step=43.80]\n",
      "Epoch 0:  29%|██▉       | 11/38 [00:26<01:04,  2.40s/it, loss=1.14, v_num=33, train_acc1_step=43.80]\n",
      "Epoch 0:  29%|██▉       | 11/38 [00:26<01:04,  2.40s/it, loss=1.14, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  32%|███▏      | 12/38 [00:26<00:57,  2.21s/it, loss=1.14, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  32%|███▏      | 12/38 [00:26<00:57,  2.21s/it, loss=1.14, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:  34%|███▍      | 13/38 [00:29<00:57,  2.29s/it, loss=1.14, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:  34%|███▍      | 13/38 [00:29<00:57,  2.29s/it, loss=1.14, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  37%|███▋      | 14/38 [00:29<00:51,  2.14s/it, loss=1.14, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  37%|███▋      | 14/38 [00:29<00:51,  2.14s/it, loss=1.13, v_num=33, train_acc1_step=37.50]\n",
      "Epoch 0:  39%|███▉      | 15/38 [00:30<00:46,  2.01s/it, loss=1.13, v_num=33, train_acc1_step=37.50]\n",
      "Epoch 0:  39%|███▉      | 15/38 [00:30<00:46,  2.01s/it, loss=1.13, v_num=33, train_acc1_step=12.50]\n",
      "Epoch 0:  42%|████▏     | 16/38 [00:30<00:41,  1.89s/it, loss=1.13, v_num=33, train_acc1_step=12.50]\n",
      "Epoch 0:  42%|████▏     | 16/38 [00:30<00:41,  1.90s/it, loss=1.13, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:  45%|████▍     | 17/38 [00:34<00:42,  2.01s/it, loss=1.13, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:  45%|████▍     | 17/38 [00:34<00:42,  2.01s/it, loss=1.13, v_num=33, train_acc1_step=37.50]\n",
      "Epoch 0:  47%|████▋     | 18/38 [00:34<00:38,  1.91s/it, loss=1.13, v_num=33, train_acc1_step=37.50]\n",
      "Epoch 0:  47%|████▋     | 18/38 [00:34<00:38,  1.91s/it, loss=1.13, v_num=33, train_acc1_step=43.80]\n",
      "Epoch 0:  50%|█████     | 19/38 [00:34<00:34,  1.81s/it, loss=1.13, v_num=33, train_acc1_step=43.80]\n",
      "Epoch 0:  50%|█████     | 19/38 [00:34<00:34,  1.82s/it, loss=1.12, v_num=33, train_acc1_step=43.80]\n",
      "Epoch 0:  53%|█████▎    | 20/38 [00:34<00:31,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=43.80]\n",
      "Epoch 0:  53%|█████▎    | 20/38 [00:34<00:31,  1.73s/it, loss=1.13, v_num=33, train_acc1_step=31.20]\n",
      "Epoch 0:  55%|█████▌    | 21/38 [00:38<00:31,  1.83s/it, loss=1.13, v_num=33, train_acc1_step=31.20]\n",
      "Epoch 0:  55%|█████▌    | 21/38 [00:38<00:31,  1.83s/it, loss=1.13, v_num=33, train_acc1_step=31.20]\n",
      "Epoch 0:  58%|█████▊    | 22/38 [00:38<00:28,  1.76s/it, loss=1.13, v_num=33, train_acc1_step=31.20]\n",
      "Epoch 0:  58%|█████▊    | 22/38 [00:38<00:28,  1.76s/it, loss=1.12, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  61%|██████    | 23/38 [00:38<00:25,  1.69s/it, loss=1.12, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  61%|██████    | 23/38 [00:38<00:25,  1.69s/it, loss=1.12, v_num=33, train_acc1_step=18.80]\n",
      "Epoch 0:  63%|██████▎   | 24/38 [00:39<00:22,  1.63s/it, loss=1.12, v_num=33, train_acc1_step=18.80]\n",
      "Epoch 0:  63%|██████▎   | 24/38 [00:39<00:22,  1.63s/it, loss=1.11, v_num=33, train_acc1_step=43.80]\n",
      "Epoch 0:  66%|██████▌   | 25/38 [00:41<00:21,  1.68s/it, loss=1.11, v_num=33, train_acc1_step=43.80]\n",
      "Epoch 0:  66%|██████▌   | 25/38 [00:41<00:21,  1.68s/it, loss=1.11, v_num=33, train_acc1_step=31.20]\n",
      "Epoch 0:  68%|██████▊   | 26/38 [00:42<00:19,  1.62s/it, loss=1.11, v_num=33, train_acc1_step=31.20]\n",
      "Epoch 0:  68%|██████▊   | 26/38 [00:42<00:19,  1.62s/it, loss=1.11, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  71%|███████   | 27/38 [00:42<00:17,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  71%|███████   | 27/38 [00:42<00:17,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  74%|███████▎  | 28/38 [00:42<00:15,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=25.00]\n",
      "Epoch 0:  74%|███████▎  | 28/38 [00:42<00:15,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:  76%|███████▋  | 29/38 [00:45<00:14,  1.56s/it, loss=1.11, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:  76%|███████▋  | 29/38 [00:45<00:14,  1.56s/it, loss=1.11, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:  79%|███████▉  | 30/38 [00:45<00:12,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=50.00]\n",
      "Epoch 0:  79%|███████▉  | 30/38 [00:45<00:12,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  5.10it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 31/38 [00:54<00:12,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:01<00:03,  1.97it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 32/38 [00:55<00:10,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.70it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 33/38 [00:55<00:08,  1.67s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.33it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 34/38 [00:55<00:06,  1.63s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.30it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 35/38 [00:57<00:04,  1.65s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.24it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 36/38 [00:58<00:03,  1.64s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:05<00:00,  1.32it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 37/38 [00:59<00:01,  1.60s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:05<00:00,  1.47it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 38/38 [00:59<00:00,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=33.30]\n",
      "Epoch 0: 100%|██████████| 38/38 [00:59<00:00,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 0: 100%|██████████| 38/38 [00:59<00:00,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 0:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]         \n",
      "Epoch 1:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:   3%|▎         | 1/38 [00:18<11:22, 18.44s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:   3%|▎         | 1/38 [00:18<11:22, 18.45s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:   5%|▌         | 2/38 [00:19<05:44,  9.57s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:   5%|▌         | 2/38 [00:19<05:44,  9.58s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:   8%|▊         | 3/38 [00:19<03:45,  6.44s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:   8%|▊         | 3/38 [00:19<03:45,  6.44s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  11%|█         | 4/38 [00:19<02:45,  4.87s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  11%|█         | 4/38 [00:19<02:45,  4.87s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  13%|█▎        | 5/38 [00:21<02:23,  4.36s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  13%|█▎        | 5/38 [00:21<02:24,  4.36s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  16%|█▌        | 6/38 [00:22<02:02,  3.82s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  16%|█▌        | 6/38 [00:22<02:02,  3.82s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  18%|█▊        | 7/38 [00:23<01:42,  3.30s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  18%|█▊        | 7/38 [00:23<01:42,  3.30s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  21%|██        | 8/38 [00:23<01:27,  2.91s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  21%|██        | 8/38 [00:23<01:27,  2.91s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  24%|██▎       | 9/38 [00:26<01:23,  2.89s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  24%|██▎       | 9/38 [00:26<01:23,  2.89s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  26%|██▋       | 10/38 [00:26<01:13,  2.62s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  26%|██▋       | 10/38 [00:26<01:13,  2.62s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  29%|██▉       | 11/38 [00:26<01:04,  2.40s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  29%|██▉       | 11/38 [00:26<01:04,  2.40s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  32%|███▏      | 12/38 [00:26<00:57,  2.21s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  32%|███▏      | 12/38 [00:26<00:57,  2.21s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  34%|███▍      | 13/38 [00:28<00:54,  2.20s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  34%|███▍      | 13/38 [00:28<00:54,  2.20s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  37%|███▋      | 14/38 [00:28<00:49,  2.05s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  37%|███▋      | 14/38 [00:28<00:49,  2.05s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  39%|███▉      | 15/38 [00:29<00:44,  1.94s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  39%|███▉      | 15/38 [00:29<00:44,  1.94s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  42%|████▏     | 16/38 [00:29<00:40,  1.83s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  42%|████▏     | 16/38 [00:29<00:40,  1.83s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  45%|████▍     | 17/38 [00:31<00:39,  1.87s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  45%|████▍     | 17/38 [00:31<00:39,  1.87s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  47%|████▋     | 18/38 [00:33<00:36,  1.84s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  47%|████▋     | 18/38 [00:33<00:36,  1.84s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  50%|█████     | 19/38 [00:33<00:33,  1.78s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  50%|█████     | 19/38 [00:33<00:33,  1.78s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  53%|█████▎    | 20/38 [00:34<00:30,  1.70s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  53%|█████▎    | 20/38 [00:34<00:30,  1.70s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  55%|█████▌    | 21/38 [00:35<00:28,  1.70s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  55%|█████▌    | 21/38 [00:35<00:28,  1.70s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  58%|█████▊    | 22/38 [00:36<00:26,  1.65s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  58%|█████▊    | 22/38 [00:36<00:26,  1.65s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  61%|██████    | 23/38 [00:37<00:24,  1.64s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  61%|██████    | 23/38 [00:37<00:24,  1.64s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  63%|██████▎   | 24/38 [00:37<00:22,  1.58s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  63%|██████▎   | 24/38 [00:37<00:22,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  66%|██████▌   | 25/38 [00:39<00:20,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  66%|██████▌   | 25/38 [00:39<00:20,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  68%|██████▊   | 26/38 [00:39<00:18,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  68%|██████▊   | 26/38 [00:39<00:18,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  71%|███████   | 27/38 [00:41<00:16,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  71%|███████   | 27/38 [00:41<00:16,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  74%|███████▎  | 28/38 [00:41<00:14,  1.47s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  74%|███████▎  | 28/38 [00:41<00:14,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40] \n",
      "Epoch 1:  76%|███████▋  | 29/38 [00:42<00:13,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  76%|███████▋  | 29/38 [00:42<00:13,  1.48s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  79%|███████▉  | 30/38 [00:42<00:11,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1:  79%|███████▉  | 30/38 [00:42<00:11,  1.43s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.16it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 31/38 [00:52<00:11,  1.68s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:01,  3.69it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 32/38 [00:52<00:09,  1.64s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.58it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 33/38 [00:52<00:07,  1.60s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.37it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 34/38 [00:52<00:06,  1.55s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.30it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 35/38 [00:55<00:04,  1.59s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.37it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 36/38 [00:56<00:03,  1.56s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.44it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 37/38 [00:56<00:01,  1.53s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 38/38 [00:56<00:00,  1.49s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.40]\n",
      "Epoch 1: 100%|██████████| 38/38 [00:56<00:00,  1.49s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.40]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 1: 100%|██████████| 38/38 [00:56<00:00,  1.49s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 1:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]         \n",
      "Epoch 2:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:   3%|▎         | 1/38 [00:17<10:49, 17.56s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:   3%|▎         | 1/38 [00:17<10:50, 17.57s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:   5%|▌         | 2/38 [00:18<05:40,  9.47s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:   5%|▌         | 2/38 [00:18<05:41,  9.48s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:   8%|▊         | 3/38 [00:19<03:42,  6.37s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:   8%|▊         | 3/38 [00:19<03:43,  6.37s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  11%|█         | 4/38 [00:19<02:43,  4.82s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  11%|█         | 4/38 [00:19<02:43,  4.82s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  13%|█▎        | 5/38 [00:20<02:13,  4.04s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  13%|█▎        | 5/38 [00:20<02:13,  4.04s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  16%|█▌        | 6/38 [00:23<02:02,  3.83s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  16%|█▌        | 6/38 [00:23<02:02,  3.84s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  18%|█▊        | 7/38 [00:23<01:42,  3.31s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  18%|█▊        | 7/38 [00:23<01:42,  3.31s/it, loss=1.15, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  21%|██        | 8/38 [00:23<01:27,  2.92s/it, loss=1.15, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  21%|██        | 8/38 [00:23<01:27,  2.92s/it, loss=1.15, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  24%|██▎       | 9/38 [00:23<01:15,  2.61s/it, loss=1.15, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  24%|██▎       | 9/38 [00:23<01:15,  2.61s/it, loss=1.15, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  26%|██▋       | 10/38 [00:25<01:11,  2.54s/it, loss=1.15, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  26%|██▋       | 10/38 [00:25<01:11,  2.54s/it, loss=1.15, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  29%|██▉       | 11/38 [00:25<01:02,  2.32s/it, loss=1.15, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  29%|██▉       | 11/38 [00:25<01:02,  2.32s/it, loss=1.15, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  32%|███▏      | 12/38 [00:25<00:55,  2.14s/it, loss=1.15, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  32%|███▏      | 12/38 [00:25<00:55,  2.15s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  34%|███▍      | 13/38 [00:25<00:49,  2.00s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  34%|███▍      | 13/38 [00:25<00:49,  2.00s/it, loss=1.14, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  37%|███▋      | 14/38 [00:28<00:49,  2.06s/it, loss=1.14, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  37%|███▋      | 14/38 [00:28<00:49,  2.06s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  39%|███▉      | 15/38 [00:28<00:44,  1.93s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  39%|███▉      | 15/38 [00:28<00:44,  1.93s/it, loss=1.15, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  42%|████▏     | 16/38 [00:29<00:40,  1.82s/it, loss=1.15, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  42%|████▏     | 16/38 [00:29<00:40,  1.82s/it, loss=1.15, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.15, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.15, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  47%|████▋     | 18/38 [00:32<00:35,  1.79s/it, loss=1.15, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  47%|████▋     | 18/38 [00:32<00:35,  1.79s/it, loss=1.15, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  50%|█████     | 19/38 [00:32<00:32,  1.70s/it, loss=1.15, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  50%|█████     | 19/38 [00:32<00:32,  1.70s/it, loss=1.14, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  53%|█████▎    | 20/38 [00:32<00:29,  1.63s/it, loss=1.14, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  53%|█████▎    | 20/38 [00:32<00:29,  1.63s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  55%|█████▌    | 21/38 [00:32<00:26,  1.56s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  55%|█████▌    | 21/38 [00:32<00:26,  1.56s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  58%|█████▊    | 22/38 [00:34<00:25,  1.57s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  58%|█████▊    | 22/38 [00:34<00:25,  1.57s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  61%|██████    | 23/38 [00:35<00:22,  1.53s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  61%|██████    | 23/38 [00:35<00:22,  1.53s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  63%|██████▎   | 24/38 [00:35<00:20,  1.47s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  63%|██████▎   | 24/38 [00:35<00:20,  1.47s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  68%|██████▊   | 26/38 [00:37<00:17,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  68%|██████▊   | 26/38 [00:37<00:17,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  71%|███████   | 27/38 [00:37<00:15,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  71%|███████   | 27/38 [00:37<00:15,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  74%|███████▎  | 28/38 [00:37<00:13,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  74%|███████▎  | 28/38 [00:37<00:13,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  76%|███████▋  | 29/38 [00:38<00:12,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  76%|███████▋  | 29/38 [00:38<00:12,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  79%|███████▉  | 30/38 [00:39<00:10,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2:  79%|███████▉  | 30/38 [00:39<00:10,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  5.11it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 31/38 [00:47<00:10,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.45it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 32/38 [00:47<00:08,  1.50s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.09it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 33/38 [00:47<00:07,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.82it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 34/38 [00:48<00:05,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.47it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 35/38 [00:50<00:04,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 36/38 [00:51<00:02,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 37/38 [00:51<00:01,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 2: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 2: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 2:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]         \n",
      "Epoch 3:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:   3%|▎         | 1/38 [00:16<10:28, 17.00s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:   3%|▎         | 1/38 [00:17<10:29, 17.01s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:   5%|▌         | 2/38 [00:17<05:09,  8.59s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:   5%|▌         | 2/38 [00:17<05:09,  8.59s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:   8%|▊         | 3/38 [00:17<03:23,  5.81s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:   8%|▊         | 3/38 [00:17<03:23,  5.81s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  13%|█▎        | 5/38 [00:20<02:12,  4.03s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  13%|█▎        | 5/38 [00:20<02:13,  4.03s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  16%|█▌        | 6/38 [00:20<01:48,  3.39s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  16%|█▌        | 6/38 [00:20<01:48,  3.39s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  18%|█▊        | 7/38 [00:20<01:32,  2.98s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  18%|█▊        | 7/38 [00:20<01:32,  2.99s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  21%|██        | 8/38 [00:21<01:18,  2.63s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  21%|██        | 8/38 [00:21<01:19,  2.63s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  24%|██▎       | 9/38 [00:23<01:15,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  24%|██▎       | 9/38 [00:23<01:15,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  26%|██▋       | 10/38 [00:23<01:06,  2.37s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  26%|██▋       | 10/38 [00:23<01:06,  2.37s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  32%|███▏      | 12/38 [00:24<00:52,  2.00s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  32%|███▏      | 12/38 [00:24<00:52,  2.00s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  34%|███▍      | 13/38 [00:25<00:49,  1.96s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  47%|████▋     | 18/38 [00:28<00:31,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  47%|████▋     | 18/38 [00:28<00:31,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30] \n",
      "Epoch 3:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.79it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 31/38 [00:45<00:10,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.25it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 32/38 [00:45<00:08,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.05it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 33/38 [00:45<00:06,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.71it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 34/38 [00:46<00:05,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.38it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 35/38 [00:48<00:04,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.37it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 36/38 [00:49<00:02,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.44it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 37/38 [00:49<00:01,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.61it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 38/38 [00:49<00:00,  1.31s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 3: 100%|██████████| 38/38 [00:49<00:00,  1.31s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=30.30]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 3: 100%|██████████| 38/38 [00:49<00:00,  1.31s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 3:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]         \n",
      "Epoch 4:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:   3%|▎         | 1/38 [00:17<10:48, 17.53s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:   3%|▎         | 1/38 [00:17<10:49, 17.54s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:   5%|▌         | 2/38 [00:17<05:18,  8.85s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:   5%|▌         | 2/38 [00:17<05:18,  8.86s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:   8%|▊         | 3/38 [00:17<03:28,  5.96s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:   8%|▊         | 3/38 [00:17<03:28,  5.96s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  11%|█         | 4/38 [00:18<02:33,  4.51s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  11%|█         | 4/38 [00:18<02:33,  4.52s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  13%|█▎        | 5/38 [00:20<02:16,  4.13s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  13%|█▎        | 5/38 [00:20<02:16,  4.14s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  16%|█▌        | 6/38 [00:20<01:51,  3.48s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  16%|█▌        | 6/38 [00:20<01:51,  3.48s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  18%|█▊        | 7/38 [00:21<01:33,  3.02s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  18%|█▊        | 7/38 [00:21<01:33,  3.02s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.12, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  24%|██▎       | 9/38 [00:23<01:15,  2.60s/it, loss=1.12, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  24%|██▎       | 9/38 [00:23<01:15,  2.60s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  26%|██▋       | 10/38 [00:23<01:05,  2.36s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  26%|██▋       | 10/38 [00:23<01:06,  2.36s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  29%|██▉       | 11/38 [00:24<00:59,  2.22s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  29%|██▉       | 11/38 [00:24<00:59,  2.22s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  32%|███▏      | 12/38 [00:24<00:53,  2.05s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  32%|███▏      | 12/38 [00:24<00:53,  2.05s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  39%|███▉      | 15/38 [00:27<00:42,  1.83s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  39%|███▉      | 15/38 [00:27<00:42,  1.83s/it, loss=1.14, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  42%|████▏     | 16/38 [00:27<00:37,  1.72s/it, loss=1.14, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  42%|████▏     | 16/38 [00:27<00:37,  1.73s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  45%|████▍     | 17/38 [00:30<00:37,  1.77s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  45%|████▍     | 17/38 [00:30<00:37,  1.77s/it, loss=1.14, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  47%|████▋     | 18/38 [00:30<00:33,  1.68s/it, loss=1.14, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  47%|████▋     | 18/38 [00:30<00:33,  1.68s/it, loss=1.14, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.14, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  53%|█████▎    | 20/38 [00:30<00:27,  1.53s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  53%|█████▎    | 20/38 [00:30<00:27,  1.53s/it, loss=1.14, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  55%|█████▌    | 21/38 [00:33<00:27,  1.60s/it, loss=1.14, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  55%|█████▌    | 21/38 [00:33<00:27,  1.61s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  58%|█████▊    | 22/38 [00:33<00:24,  1.54s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  58%|█████▊    | 22/38 [00:33<00:24,  1.54s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  61%|██████    | 23/38 [00:34<00:22,  1.48s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  61%|██████    | 23/38 [00:34<00:22,  1.48s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  63%|██████▎   | 24/38 [00:34<00:19,  1.43s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  63%|██████▎   | 24/38 [00:34<00:19,  1.43s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  66%|██████▌   | 25/38 [00:37<00:19,  1.49s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  66%|██████▌   | 25/38 [00:37<00:19,  1.49s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  68%|██████▊   | 26/38 [00:37<00:17,  1.44s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  68%|██████▊   | 26/38 [00:37<00:17,  1.44s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  71%|███████   | 27/38 [00:37<00:15,  1.39s/it, loss=1.14, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  71%|███████   | 27/38 [00:37<00:15,  1.39s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  74%|███████▎  | 28/38 [00:37<00:13,  1.34s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  74%|███████▎  | 28/38 [00:37<00:13,  1.34s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  76%|███████▋  | 29/38 [00:39<00:12,  1.35s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  76%|███████▋  | 29/38 [00:39<00:12,  1.35s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  79%|███████▉  | 30/38 [00:39<00:10,  1.31s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4:  79%|███████▉  | 30/38 [00:39<00:10,  1.31s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:00,  8.39it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 31/38 [00:47<00:10,  1.53s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.43it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 32/38 [00:48<00:09,  1.50s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.96it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 33/38 [00:48<00:07,  1.46s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.56it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 34/38 [00:48<00:05,  1.42s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.36it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 35/38 [00:50<00:04,  1.46s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 36/38 [00:51<00:02,  1.43s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.50it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 37/38 [00:51<00:01,  1.40s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.69it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 38/38 [00:52<00:00,  1.37s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.50]\n",
      "Epoch 4: 100%|██████████| 38/38 [00:52<00:00,  1.37s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.50]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 4: 100%|██████████| 38/38 [00:52<00:00,  1.37s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 4:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]         \n",
      "Epoch 5:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:   3%|▎         | 1/38 [00:16<10:25, 16.89s/it, loss=1.14, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:   3%|▎         | 1/38 [00:16<10:25, 16.91s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:   5%|▌         | 2/38 [00:17<05:07,  8.54s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:   5%|▌         | 2/38 [00:17<05:07,  8.54s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:   8%|▊         | 3/38 [00:17<03:24,  5.85s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:   8%|▊         | 3/38 [00:17<03:25,  5.86s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  11%|█         | 4/38 [00:17<02:30,  4.43s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  11%|█         | 4/38 [00:17<02:30,  4.43s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  13%|█▎        | 5/38 [00:19<02:08,  3.90s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  13%|█▎        | 5/38 [00:19<02:08,  3.90s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  18%|█▊        | 7/38 [00:21<01:33,  3.00s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  18%|█▊        | 7/38 [00:21<01:33,  3.00s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  21%|██        | 8/38 [00:21<01:19,  2.65s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  21%|██        | 8/38 [00:21<01:19,  2.65s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  24%|██▎       | 9/38 [00:21<01:10,  2.44s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  24%|██▎       | 9/38 [00:21<01:10,  2.44s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60] \n",
      "Epoch 5:  29%|██▉       | 11/38 [00:24<00:59,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  29%|██▉       | 11/38 [00:24<00:59,  2.22s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  32%|███▏      | 12/38 [00:24<00:53,  2.05s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  32%|███▏      | 12/38 [00:24<00:53,  2.05s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  34%|███▍      | 13/38 [00:24<00:47,  1.90s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  34%|███▍      | 13/38 [00:24<00:47,  1.90s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  45%|████▍     | 17/38 [00:27<00:33,  1.60s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  45%|████▍     | 17/38 [00:27<00:33,  1.60s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  53%|█████▎    | 20/38 [00:29<00:26,  1.50s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  53%|█████▎    | 20/38 [00:30<00:27,  1.50s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  66%|██████▌   | 25/38 [00:33<00:17,  1.32s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  66%|██████▌   | 25/38 [00:33<00:17,  1.32s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.13, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.13, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.13, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.13, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.26it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 31/38 [00:44<00:10,  1.45s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.49it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.66it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.31it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 34/38 [00:45<00:05,  1.35s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.36it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 35/38 [00:48<00:04,  1.38s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.41it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 36/38 [00:48<00:02,  1.36s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.46it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.65it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 5: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 5: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 5:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]         \n",
      "Epoch 6:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:   3%|▎         | 1/38 [00:17<10:48, 17.52s/it, loss=1.13, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:   3%|▎         | 1/38 [00:17<10:48, 17.53s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:   5%|▌         | 2/38 [00:17<05:18,  8.85s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:   5%|▌         | 2/38 [00:17<05:18,  8.85s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:   8%|▊         | 3/38 [00:17<03:28,  5.95s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:   8%|▊         | 3/38 [00:17<03:28,  5.96s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  11%|█         | 4/38 [00:18<02:33,  4.51s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  11%|█         | 4/38 [00:18<02:33,  4.51s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  13%|█▎        | 5/38 [00:20<02:17,  4.17s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  13%|█▎        | 5/38 [00:20<02:17,  4.17s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  16%|█▌        | 6/38 [00:21<01:52,  3.50s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  16%|█▌        | 6/38 [00:21<01:52,  3.51s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  18%|█▊        | 7/38 [00:21<01:33,  3.03s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  18%|█▊        | 7/38 [00:21<01:33,  3.03s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  21%|██        | 8/38 [00:21<01:20,  2.67s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  21%|██        | 8/38 [00:21<01:20,  2.67s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  24%|██▎       | 9/38 [00:23<01:16,  2.63s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  24%|██▎       | 9/38 [00:23<01:16,  2.64s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  26%|██▋       | 10/38 [00:23<01:06,  2.39s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  26%|██▋       | 10/38 [00:23<01:06,  2.39s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  29%|██▉       | 11/38 [00:24<00:59,  2.19s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  29%|██▉       | 11/38 [00:24<00:59,  2.19s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  32%|███▏      | 12/38 [00:24<00:52,  2.02s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  32%|███▏      | 12/38 [00:24<00:52,  2.02s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.11, v_num=33, train_acc1_step=68.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.11, v_num=33, train_acc1_step=68.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  39%|███▉      | 15/38 [00:27<00:41,  1.82s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  39%|███▉      | 15/38 [00:27<00:41,  1.82s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  42%|████▏     | 16/38 [00:27<00:37,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  42%|████▏     | 16/38 [00:27<00:37,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  47%|████▋     | 18/38 [00:29<00:33,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  53%|█████▎    | 20/38 [00:30<00:27,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  53%|█████▎    | 20/38 [00:30<00:27,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  61%|██████    | 23/38 [00:33<00:21,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  61%|██████    | 23/38 [00:33<00:21,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  63%|██████▎   | 24/38 [00:33<00:19,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  63%|██████▎   | 24/38 [00:33<00:19,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  66%|██████▌   | 25/38 [00:35<00:18,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  66%|██████▌   | 25/38 [00:35<00:18,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  74%|███████▎  | 28/38 [00:36<00:13,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  74%|███████▎  | 28/38 [00:36<00:13,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  76%|███████▋  | 29/38 [00:37<00:11,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  76%|███████▋  | 29/38 [00:37<00:11,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  79%|███████▉  | 30/38 [00:38<00:10,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6:  79%|███████▉  | 30/38 [00:38<00:10,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:00,  8.68it/s]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 31/38 [00:46<00:10,  1.50s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.22it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 32/38 [00:47<00:08,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.65it/s]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 33/38 [00:47<00:07,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.28it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 34/38 [00:47<00:05,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.36it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 35/38 [00:49<00:04,  1.43s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.37it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 36/38 [00:50<00:02,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.44it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 37/38 [00:51<00:01,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]\u001b[A\n",
      "Epoch 6: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 6: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 6: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 6:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]         \n",
      "Epoch 7:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:   3%|▎         | 1/38 [00:17<10:51, 17.61s/it, loss=1.11, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:   3%|▎         | 1/38 [00:17<10:51, 17.62s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:   5%|▌         | 2/38 [00:18<05:37,  9.38s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:   5%|▌         | 2/38 [00:18<05:37,  9.38s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:   8%|▊         | 3/38 [00:18<03:40,  6.30s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:   8%|▊         | 3/38 [00:18<03:40,  6.30s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  11%|█         | 4/38 [00:19<02:41,  4.76s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  11%|█         | 4/38 [00:19<02:42,  4.77s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  13%|█▎        | 5/38 [00:20<02:15,  4.10s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  13%|█▎        | 5/38 [00:20<02:15,  4.10s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  16%|█▌        | 6/38 [00:21<01:56,  3.63s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  16%|█▌        | 6/38 [00:21<01:56,  3.63s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  18%|█▊        | 7/38 [00:21<01:37,  3.13s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  18%|█▊        | 7/38 [00:21<01:37,  3.13s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  21%|██        | 8/38 [00:22<01:22,  2.76s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  21%|██        | 8/38 [00:22<01:22,  2.76s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  24%|██▎       | 9/38 [00:23<01:16,  2.64s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  24%|██▎       | 9/38 [00:23<01:16,  2.64s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  26%|██▋       | 10/38 [00:24<01:08,  2.44s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  26%|██▋       | 10/38 [00:24<01:08,  2.44s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  29%|██▉       | 11/38 [00:24<01:00,  2.23s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  29%|██▉       | 11/38 [00:24<01:00,  2.23s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  32%|███▏      | 12/38 [00:24<00:53,  2.06s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  32%|███▏      | 12/38 [00:24<00:53,  2.06s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  34%|███▍      | 13/38 [00:27<00:51,  2.08s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  34%|███▍      | 13/38 [00:27<00:52,  2.08s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  37%|███▋      | 14/38 [00:27<00:46,  1.96s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  37%|███▋      | 14/38 [00:27<00:47,  1.96s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  39%|███▉      | 15/38 [00:27<00:42,  1.84s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  39%|███▉      | 15/38 [00:27<00:42,  1.84s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  42%|████▏     | 16/38 [00:27<00:38,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  42%|████▏     | 16/38 [00:27<00:38,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  45%|████▍     | 17/38 [00:29<00:36,  1.74s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  45%|████▍     | 17/38 [00:29<00:36,  1.74s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  47%|████▋     | 18/38 [00:30<00:33,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  47%|████▋     | 18/38 [00:30<00:33,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  50%|█████     | 19/38 [00:30<00:30,  1.59s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  50%|█████     | 19/38 [00:30<00:30,  1.59s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  55%|█████▌    | 21/38 [00:32<00:26,  1.53s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  55%|█████▌    | 21/38 [00:32<00:26,  1.53s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  58%|█████▊    | 22/38 [00:32<00:23,  1.50s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  58%|█████▊    | 22/38 [00:32<00:23,  1.50s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  63%|██████▎   | 24/38 [00:33<00:19,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  63%|██████▎   | 24/38 [00:33<00:19,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  68%|██████▊   | 26/38 [00:36<00:16,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  68%|██████▊   | 26/38 [00:36<00:16,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  74%|███████▎  | 28/38 [00:36<00:13,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  74%|███████▎  | 28/38 [00:36<00:13,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  76%|███████▋  | 29/38 [00:37<00:11,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  76%|███████▋  | 29/38 [00:37<00:11,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  79%|███████▉  | 30/38 [00:38<00:10,  1.27s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7:  79%|███████▉  | 30/38 [00:38<00:10,  1.27s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.36it/s]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 31/38 [00:46<00:10,  1.49s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.55it/s]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 32/38 [00:46<00:08,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.24it/s]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 33/38 [00:46<00:07,  1.42s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.95it/s]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 34/38 [00:47<00:05,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.41it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 35/38 [00:49<00:04,  1.42s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 36/38 [00:50<00:02,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.52it/s]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 37/38 [00:50<00:01,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\u001b[A\n",
      "Epoch 7: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 7: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=29.80]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 7: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 7:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]         \n",
      "Epoch 8:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:   3%|▎         | 1/38 [00:17<10:31, 17.05s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:   3%|▎         | 1/38 [00:17<10:31, 17.07s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:   5%|▌         | 2/38 [00:17<05:09,  8.61s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:   5%|▌         | 2/38 [00:17<05:10,  8.62s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:   8%|▊         | 3/38 [00:17<03:22,  5.80s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:   8%|▊         | 3/38 [00:17<03:23,  5.80s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  13%|█▎        | 5/38 [00:19<02:11,  4.00s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  13%|█▎        | 5/38 [00:20<02:12,  4.00s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  16%|█▌        | 6/38 [00:20<01:47,  3.36s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  16%|█▌        | 6/38 [00:20<01:47,  3.37s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  18%|█▊        | 7/38 [00:20<01:30,  2.91s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  18%|█▊        | 7/38 [00:20<01:30,  2.91s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  21%|██        | 8/38 [00:20<01:16,  2.56s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  21%|██        | 8/38 [00:20<01:16,  2.56s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  24%|██▎       | 9/38 [00:22<01:13,  2.54s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  24%|██▎       | 9/38 [00:22<01:13,  2.54s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  26%|██▋       | 10/38 [00:23<01:04,  2.30s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  32%|███▏      | 12/38 [00:23<00:50,  1.96s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  39%|███▉      | 15/38 [00:26<00:39,  1.74s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  39%|███▉      | 15/38 [00:26<00:39,  1.74s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  42%|████▏     | 16/38 [00:26<00:36,  1.64s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  42%|████▏     | 16/38 [00:26<00:36,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10] \n",
      "Epoch 8:  45%|████▍     | 17/38 [00:29<00:35,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  45%|████▍     | 17/38 [00:29<00:36,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10] \n",
      "Epoch 8:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.22it/s]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 31/38 [00:45<00:10,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.51it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 32/38 [00:45<00:08,  1.43s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.15it/s]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 33/38 [00:45<00:06,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.88it/s]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 34/38 [00:45<00:05,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.38it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 35/38 [00:48<00:04,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.45it/s]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 36/38 [00:49<00:02,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.55it/s]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 37/38 [00:49<00:01,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 8: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.10]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 8: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 8:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]         \n",
      "Epoch 9:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:   3%|▎         | 1/38 [00:16<10:26, 16.94s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:   3%|▎         | 1/38 [00:16<10:27, 16.96s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:   5%|▌         | 2/38 [00:17<05:07,  8.55s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:   5%|▌         | 2/38 [00:17<05:08,  8.56s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:   8%|▊         | 3/38 [00:17<03:21,  5.76s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:   8%|▊         | 3/38 [00:17<03:21,  5.76s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  11%|█         | 4/38 [00:17<02:28,  4.36s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  11%|█         | 4/38 [00:17<02:28,  4.37s/it, loss=1.13, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.13, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  13%|█▎        | 5/38 [00:19<02:10,  3.96s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  16%|█▌        | 6/38 [00:20<01:47,  3.36s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  16%|█▌        | 6/38 [00:20<01:47,  3.37s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  18%|█▊        | 7/38 [00:20<01:30,  2.91s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  18%|█▊        | 7/38 [00:20<01:30,  2.91s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  21%|██        | 8/38 [00:20<01:17,  2.57s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  21%|██        | 8/38 [00:20<01:17,  2.57s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  24%|██▎       | 9/38 [00:22<01:12,  2.49s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  24%|██▎       | 9/38 [00:22<01:12,  2.50s/it, loss=1.13, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.13, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.13, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  32%|███▏      | 12/38 [00:24<00:52,  2.00s/it, loss=1.13, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  32%|███▏      | 12/38 [00:24<00:52,  2.00s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  42%|████▏     | 16/38 [00:26<00:37,  1.68s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  42%|████▏     | 16/38 [00:26<00:37,  1.68s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  47%|████▋     | 18/38 [00:28<00:32,  1.60s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  47%|████▋     | 18/38 [00:28<00:32,  1.60s/it, loss=1.15, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.15, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  53%|█████▎    | 20/38 [00:29<00:26,  1.50s/it, loss=1.14, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  53%|█████▎    | 20/38 [00:29<00:26,  1.50s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  68%|██████▊   | 26/38 [00:35<00:16,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.25it/s]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 31/38 [00:44<00:10,  1.45s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.40it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.85it/s]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.51it/s]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 34/38 [00:45<00:05,  1.34s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.29it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 35/38 [00:48<00:04,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.38it/s]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 36/38 [00:48<00:02,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.45it/s]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.64it/s]\u001b[A\n",
      "Epoch 9: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "Epoch 9: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.70]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 9: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 9:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]         \n",
      "Epoch 10:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:   3%|▎         | 1/38 [00:17<10:56, 17.75s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:   3%|▎         | 1/38 [00:17<10:57, 17.77s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:   5%|▌         | 2/38 [00:17<05:22,  8.96s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:   5%|▌         | 2/38 [00:17<05:22,  8.96s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:   8%|▊         | 3/38 [00:18<03:30,  6.03s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:   8%|▊         | 3/38 [00:18<03:31,  6.03s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  11%|█         | 4/38 [00:18<02:37,  4.62s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  11%|█         | 4/38 [00:18<02:37,  4.62s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  13%|█▎        | 5/38 [00:20<02:14,  4.06s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  13%|█▎        | 5/38 [00:20<02:14,  4.07s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  16%|█▌        | 6/38 [00:20<01:51,  3.49s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  16%|█▌        | 6/38 [00:20<01:51,  3.49s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  18%|█▊        | 7/38 [00:21<01:33,  3.01s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  18%|█▊        | 7/38 [00:21<01:33,  3.01s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  24%|██▎       | 9/38 [00:23<01:15,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  24%|██▎       | 9/38 [00:23<01:15,  2.62s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  26%|██▋       | 10/38 [00:23<01:06,  2.37s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  26%|██▋       | 10/38 [00:23<01:06,  2.37s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  32%|███▏      | 12/38 [00:24<00:53,  2.05s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  32%|███▏      | 12/38 [00:24<00:53,  2.05s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  34%|███▍      | 13/38 [00:26<00:50,  2.01s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  34%|███▍      | 13/38 [00:26<00:50,  2.01s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50] \n",
      "Epoch 10:  42%|████▏     | 16/38 [00:27<00:37,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  42%|████▏     | 16/38 [00:27<00:38,  1.73s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  45%|████▍     | 17/38 [00:29<00:35,  1.71s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  45%|████▍     | 17/38 [00:29<00:35,  1.71s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.11, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  63%|██████▎   | 24/38 [00:32<00:19,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  63%|██████▎   | 24/38 [00:32<00:19,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.75it/s]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 31/38 [00:45<00:10,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.47it/s]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.37it/s]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.14it/s]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 34/38 [00:45<00:05,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:01,  1.53it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 35/38 [00:47<00:04,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 36/38 [00:48<00:02,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 10: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.50]\n",
      "Epoch 10: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.50]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 10: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 10:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]         \n",
      "Epoch 11:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:   3%|▎         | 1/38 [00:17<10:43, 17.38s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:   3%|▎         | 1/38 [00:17<10:43, 17.40s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:   5%|▌         | 2/38 [00:17<05:15,  8.77s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:   5%|▌         | 2/38 [00:17<05:15,  8.78s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:   8%|▊         | 3/38 [00:17<03:26,  5.90s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:   8%|▊         | 3/38 [00:17<03:26,  5.91s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  11%|█         | 4/38 [00:17<02:31,  4.47s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  11%|█         | 4/38 [00:17<02:32,  4.47s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  18%|█▊        | 7/38 [00:19<01:26,  2.81s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  18%|█▊        | 7/38 [00:19<01:27,  2.81s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  21%|██        | 8/38 [00:19<01:14,  2.47s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  21%|██        | 8/38 [00:19<01:14,  2.48s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  24%|██▎       | 9/38 [00:22<01:13,  2.54s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  24%|██▎       | 9/38 [00:22<01:13,  2.54s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  29%|██▉       | 11/38 [00:23<00:57,  2.11s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  29%|██▉       | 11/38 [00:23<00:57,  2.11s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  58%|█████▊    | 22/38 [00:32<00:23,  1.47s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  58%|█████▊    | 22/38 [00:32<00:23,  1.47s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20] \n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:00,  8.46it/s]\u001b[A\n",
      "Epoch 11:  82%|████████▏ | 31/38 [00:46<00:10,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.05it/s]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 32/38 [00:47<00:08,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:02,  2.37it/s]\u001b[A\n",
      "Epoch 11:  87%|████████▋ | 33/38 [00:47<00:07,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  2.90it/s]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 34/38 [00:47<00:05,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:04<00:02,  1.15it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 35/38 [00:50<00:04,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.25it/s]\u001b[A\n",
      "Epoch 11:  95%|█████████▍| 36/38 [00:51<00:02,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:05<00:00,  1.31it/s]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 37/38 [00:51<00:01,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:05<00:00,  1.48it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "Epoch 11: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 11: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 11:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]         \n",
      "Epoch 12:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:   3%|▎         | 1/38 [00:18<11:16, 18.28s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:   3%|▎         | 1/38 [00:18<11:16, 18.29s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:   5%|▌         | 2/38 [00:18<05:31,  9.22s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:   5%|▌         | 2/38 [00:18<05:32,  9.23s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:   8%|▊         | 3/38 [00:18<03:37,  6.20s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:   8%|▊         | 3/38 [00:18<03:37,  6.21s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  11%|█         | 4/38 [00:18<02:39,  4.69s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  11%|█         | 4/38 [00:18<02:39,  4.70s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  13%|█▎        | 5/38 [00:21<02:19,  4.22s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  13%|█▎        | 5/38 [00:21<02:19,  4.22s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  16%|█▌        | 6/38 [00:21<01:53,  3.54s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  16%|█▌        | 6/38 [00:21<01:53,  3.55s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70] \n",
      "Epoch 12:  18%|█▊        | 7/38 [00:21<01:34,  3.06s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  18%|█▊        | 7/38 [00:21<01:34,  3.06s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  21%|██        | 8/38 [00:21<01:20,  2.70s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  21%|██        | 8/38 [00:21<01:21,  2.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  24%|██▎       | 9/38 [00:23<01:16,  2.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  24%|██▎       | 9/38 [00:23<01:17,  2.66s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  26%|██▋       | 10/38 [00:24<01:07,  2.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  26%|██▋       | 10/38 [00:24<01:07,  2.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  29%|██▉       | 11/38 [00:24<00:59,  2.20s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  29%|██▉       | 11/38 [00:24<00:59,  2.20s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  32%|███▏      | 12/38 [00:24<00:52,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  32%|███▏      | 12/38 [00:24<00:52,  2.03s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  34%|███▍      | 13/38 [00:27<00:51,  2.08s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  34%|███▍      | 13/38 [00:27<00:51,  2.08s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  37%|███▋      | 14/38 [00:27<00:46,  1.94s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  37%|███▋      | 14/38 [00:27<00:46,  1.94s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  39%|███▉      | 15/38 [00:27<00:41,  1.82s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  39%|███▉      | 15/38 [00:27<00:41,  1.83s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  42%|████▏     | 16/38 [00:27<00:37,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  42%|████▏     | 16/38 [00:27<00:37,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  45%|████▍     | 17/38 [00:30<00:37,  1.81s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  45%|████▍     | 17/38 [00:30<00:37,  1.81s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  47%|████▋     | 18/38 [00:30<00:34,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  47%|████▋     | 18/38 [00:30<00:34,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  50%|█████     | 19/38 [00:31<00:31,  1.63s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  50%|█████     | 19/38 [00:31<00:31,  1.64s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  53%|█████▎    | 20/38 [00:31<00:28,  1.56s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  53%|█████▎    | 20/38 [00:31<00:28,  1.56s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  55%|█████▌    | 21/38 [00:33<00:26,  1.59s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  55%|█████▌    | 21/38 [00:33<00:26,  1.59s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  58%|█████▊    | 22/38 [00:33<00:24,  1.52s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  58%|█████▊    | 22/38 [00:33<00:24,  1.52s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  61%|██████    | 23/38 [00:33<00:21,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  61%|██████    | 23/38 [00:33<00:21,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  63%|██████▎   | 24/38 [00:33<00:19,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  63%|██████▎   | 24/38 [00:33<00:19,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  66%|██████▌   | 25/38 [00:36<00:18,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  66%|██████▌   | 25/38 [00:36<00:18,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  68%|██████▊   | 26/38 [00:36<00:16,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  68%|██████▊   | 26/38 [00:36<00:16,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  71%|███████   | 27/38 [00:36<00:14,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  71%|███████   | 27/38 [00:36<00:14,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  74%|███████▎  | 28/38 [00:36<00:13,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  74%|███████▎  | 28/38 [00:36<00:13,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  76%|███████▋  | 29/38 [00:38<00:11,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  76%|███████▋  | 29/38 [00:38<00:11,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  79%|███████▉  | 30/38 [00:38<00:10,  1.29s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12:  79%|███████▉  | 30/38 [00:38<00:10,  1.29s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.20it/s]\u001b[A\n",
      "Epoch 12:  82%|████████▏ | 31/38 [00:46<00:10,  1.50s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.67it/s]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 32/38 [00:46<00:08,  1.47s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.32it/s]\u001b[A\n",
      "Epoch 12:  87%|████████▋ | 33/38 [00:47<00:07,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.05it/s]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 34/38 [00:47<00:05,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.38it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 35/38 [00:49<00:04,  1.42s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.40it/s]\u001b[A\n",
      "Epoch 12:  95%|█████████▍| 36/38 [00:50<00:02,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.48it/s]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 37/38 [00:50<00:01,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.66it/s]\u001b[A\n",
      "Epoch 12: 100%|██████████| 38/38 [00:51<00:00,  1.34s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "Epoch 12: 100%|██████████| 38/38 [00:51<00:00,  1.34s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.70]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 12: 100%|██████████| 38/38 [00:51<00:00,  1.34s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 12:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]         \n",
      "Epoch 13:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:   3%|▎         | 1/38 [00:17<10:36, 17.21s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:   3%|▎         | 1/38 [00:17<10:37, 17.22s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:   5%|▌         | 2/38 [00:17<05:21,  8.93s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:   5%|▌         | 2/38 [00:17<05:21,  8.93s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:   8%|▊         | 3/38 [00:18<03:30,  6.00s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:   8%|▊         | 3/38 [00:18<03:30,  6.01s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  11%|█         | 4/38 [00:18<02:34,  4.54s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  11%|█         | 4/38 [00:18<02:34,  4.55s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  13%|█▎        | 5/38 [00:20<02:16,  4.14s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  13%|█▎        | 5/38 [00:20<02:16,  4.14s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  16%|█▌        | 6/38 [00:20<01:51,  3.48s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  16%|█▌        | 6/38 [00:20<01:51,  3.48s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  18%|█▊        | 7/38 [00:21<01:33,  3.00s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  18%|█▊        | 7/38 [00:21<01:33,  3.01s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  21%|██        | 8/38 [00:21<01:19,  2.65s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  21%|██        | 8/38 [00:21<01:19,  2.65s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  26%|██▋       | 10/38 [00:23<01:06,  2.38s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  26%|██▋       | 10/38 [00:23<01:06,  2.38s/it, loss=1.11, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  29%|██▉       | 11/38 [00:23<00:58,  2.18s/it, loss=1.11, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  29%|██▉       | 11/38 [00:23<00:58,  2.18s/it, loss=1.11, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  32%|███▏      | 12/38 [00:24<00:53,  2.06s/it, loss=1.11, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  32%|███▏      | 12/38 [00:24<00:53,  2.06s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  34%|███▍      | 13/38 [00:26<00:51,  2.04s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  34%|███▍      | 13/38 [00:26<00:51,  2.04s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  37%|███▋      | 14/38 [00:26<00:45,  1.91s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  37%|███▋      | 14/38 [00:26<00:45,  1.91s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  42%|████▏     | 16/38 [00:27<00:37,  1.73s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  42%|████▏     | 16/38 [00:27<00:37,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  47%|████▋     | 18/38 [00:30<00:33,  1.68s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  47%|████▋     | 18/38 [00:30<00:33,  1.68s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  53%|█████▎    | 20/38 [00:30<00:27,  1.53s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  53%|█████▎    | 20/38 [00:30<00:27,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  58%|█████▊    | 22/38 [00:33<00:24,  1.52s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  58%|█████▊    | 22/38 [00:33<00:24,  1.52s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  61%|██████    | 23/38 [00:33<00:21,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  61%|██████    | 23/38 [00:33<00:21,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  63%|██████▎   | 24/38 [00:33<00:19,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  63%|██████▎   | 24/38 [00:33<00:19,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  68%|██████▊   | 26/38 [00:36<00:16,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  68%|██████▊   | 26/38 [00:36<00:16,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  71%|███████   | 27/38 [00:36<00:15,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  71%|███████   | 27/38 [00:36<00:15,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  74%|███████▎  | 28/38 [00:37<00:13,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  74%|███████▎  | 28/38 [00:37<00:13,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  79%|███████▉  | 30/38 [00:38<00:10,  1.29s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13:  79%|███████▉  | 30/38 [00:38<00:10,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:00,  8.69it/s]\u001b[A\n",
      "Epoch 13:  82%|████████▏ | 31/38 [00:46<00:10,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.35it/s]\u001b[A\n",
      "Epoch 13:  84%|████████▍ | 32/38 [00:47<00:08,  1.49s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.08it/s]\u001b[A\n",
      "Epoch 13:  87%|████████▋ | 33/38 [00:47<00:07,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.78it/s]\u001b[A\n",
      "Epoch 13:  89%|████████▉ | 34/38 [00:47<00:05,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.37it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 35/38 [00:50<00:04,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.40it/s]\u001b[A\n",
      "Epoch 13:  95%|█████████▍| 36/38 [00:51<00:02,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.48it/s]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 37/38 [00:51<00:01,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.67it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "Epoch 13: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.40]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 13: 100%|██████████| 38/38 [00:51<00:00,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 13:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]         \n",
      "Epoch 14:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:   3%|▎         | 1/38 [00:18<11:07, 18.03s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:   3%|▎         | 1/38 [00:18<11:07, 18.04s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:   5%|▌         | 2/38 [00:18<05:27,  9.10s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:   5%|▌         | 2/38 [00:18<05:27,  9.11s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:   8%|▊         | 3/38 [00:18<03:35,  6.16s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:   8%|▊         | 3/38 [00:18<03:35,  6.16s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  11%|█         | 4/38 [00:18<02:38,  4.66s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  11%|█         | 4/38 [00:18<02:38,  4.66s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  13%|█▎        | 5/38 [00:21<02:20,  4.26s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  13%|█▎        | 5/38 [00:21<02:20,  4.26s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  16%|█▌        | 6/38 [00:21<01:54,  3.57s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  16%|█▌        | 6/38 [00:21<01:54,  3.57s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  18%|█▊        | 7/38 [00:21<01:35,  3.08s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  18%|█▊        | 7/38 [00:21<01:35,  3.09s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  21%|██        | 8/38 [00:21<01:21,  2.72s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  21%|██        | 8/38 [00:21<01:21,  2.72s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10] \n",
      "Epoch 14:  24%|██▎       | 9/38 [00:24<01:18,  2.71s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  24%|██▎       | 9/38 [00:24<01:18,  2.72s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  26%|██▋       | 10/38 [00:24<01:09,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  26%|██▋       | 10/38 [00:24<01:09,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  29%|██▉       | 11/38 [00:24<01:01,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  29%|██▉       | 11/38 [00:24<01:01,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  32%|███▏      | 12/38 [00:25<00:54,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  32%|███▏      | 12/38 [00:25<00:54,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  34%|███▍      | 13/38 [00:27<00:52,  2.10s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  34%|███▍      | 13/38 [00:27<00:52,  2.10s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  37%|███▋      | 14/38 [00:28<00:48,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  37%|███▋      | 14/38 [00:28<00:48,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  39%|███▉      | 15/38 [00:28<00:43,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  39%|███▉      | 15/38 [00:28<00:43,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  42%|████▏     | 16/38 [00:28<00:39,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  42%|████▏     | 16/38 [00:28<00:39,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  45%|████▍     | 17/38 [00:29<00:36,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  45%|████▍     | 17/38 [00:29<00:36,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  47%|████▋     | 18/38 [00:31<00:35,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  47%|████▋     | 18/38 [00:31<00:35,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  50%|█████     | 19/38 [00:31<00:31,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  50%|█████     | 19/38 [00:31<00:31,  1.67s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  53%|█████▎    | 20/38 [00:31<00:28,  1.59s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  53%|█████▎    | 20/38 [00:31<00:28,  1.59s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  55%|█████▌    | 21/38 [00:33<00:26,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  55%|█████▌    | 21/38 [00:33<00:26,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  58%|█████▊    | 22/38 [00:34<00:25,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  58%|█████▊    | 22/38 [00:34<00:25,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  61%|██████    | 23/38 [00:34<00:22,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  61%|██████    | 23/38 [00:34<00:22,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  63%|██████▎   | 24/38 [00:34<00:20,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  63%|██████▎   | 24/38 [00:34<00:20,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  66%|██████▌   | 25/38 [00:36<00:18,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  66%|██████▌   | 25/38 [00:36<00:18,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  68%|██████▊   | 26/38 [00:37<00:17,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  68%|██████▊   | 26/38 [00:37<00:17,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10] \n",
      "Epoch 14:  71%|███████   | 27/38 [00:37<00:15,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  71%|███████   | 27/38 [00:37<00:15,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  74%|███████▎  | 28/38 [00:38<00:13,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  74%|███████▎  | 28/38 [00:38<00:13,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  76%|███████▋  | 29/38 [00:39<00:12,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  76%|███████▋  | 29/38 [00:39<00:12,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  79%|███████▉  | 30/38 [00:39<00:10,  1.32s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14:  79%|███████▉  | 30/38 [00:39<00:10,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10] \n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:00, 13.77it/s]\u001b[A\n",
      "Epoch 14:  82%|████████▏ | 31/38 [00:47<00:10,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.25it/s]\u001b[A\n",
      "Epoch 14:  84%|████████▍ | 32/38 [00:48<00:09,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.61it/s]\u001b[A\n",
      "Epoch 14:  87%|████████▋ | 33/38 [00:48<00:07,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.26it/s]\u001b[A\n",
      "Epoch 14:  89%|████████▉ | 34/38 [00:48<00:05,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.37it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 35/38 [00:51<00:04,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.39it/s]\u001b[A\n",
      "Epoch 14:  95%|█████████▍| 36/38 [00:51<00:02,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.43it/s]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 37/38 [00:52<00:01,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.61it/s]\u001b[A\n",
      "Epoch 14: 100%|██████████| 38/38 [00:52<00:00,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "Epoch 14: 100%|██████████| 38/38 [00:52<00:00,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 14: 100%|██████████| 38/38 [00:52<00:00,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 14:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]         \n",
      "Epoch 15:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:   3%|▎         | 1/38 [00:18<11:14, 18.24s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:   3%|▎         | 1/38 [00:18<11:15, 18.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:   5%|▌         | 2/38 [00:18<05:31,  9.20s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:   5%|▌         | 2/38 [00:18<05:31,  9.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:   8%|▊         | 3/38 [00:18<03:36,  6.19s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:   8%|▊         | 3/38 [00:18<03:36,  6.19s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  11%|█         | 4/38 [00:18<02:39,  4.68s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  11%|█         | 4/38 [00:18<02:39,  4.68s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  13%|█▎        | 5/38 [00:21<02:19,  4.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  13%|█▎        | 5/38 [00:21<02:19,  4.23s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  16%|█▌        | 6/38 [00:21<01:53,  3.55s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  16%|█▌        | 6/38 [00:21<01:53,  3.56s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  18%|█▊        | 7/38 [00:21<01:35,  3.07s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  18%|█▊        | 7/38 [00:21<01:35,  3.07s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  21%|██        | 8/38 [00:21<01:21,  2.71s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  21%|██        | 8/38 [00:21<01:21,  2.71s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  24%|██▎       | 9/38 [00:24<01:18,  2.70s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  24%|██▎       | 9/38 [00:24<01:18,  2.70s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  26%|██▋       | 10/38 [00:24<01:08,  2.45s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  26%|██▋       | 10/38 [00:24<01:08,  2.45s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  29%|██▉       | 11/38 [00:24<01:00,  2.24s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  29%|██▉       | 11/38 [00:24<01:00,  2.25s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  32%|███▏      | 12/38 [00:24<00:53,  2.07s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  32%|███▏      | 12/38 [00:24<00:53,  2.07s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  34%|███▍      | 13/38 [00:28<00:53,  2.15s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  34%|███▍      | 13/38 [00:28<00:53,  2.16s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  37%|███▋      | 14/38 [00:28<00:48,  2.01s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  37%|███▋      | 14/38 [00:28<00:48,  2.02s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  39%|███▉      | 15/38 [00:28<00:43,  1.89s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  39%|███▉      | 15/38 [00:28<00:43,  1.89s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  42%|████▏     | 16/38 [00:28<00:39,  1.78s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  42%|████▏     | 16/38 [00:28<00:39,  1.79s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  45%|████▍     | 17/38 [00:31<00:38,  1.85s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  45%|████▍     | 17/38 [00:31<00:38,  1.85s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  47%|████▋     | 18/38 [00:31<00:35,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  47%|████▋     | 18/38 [00:31<00:35,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  50%|█████     | 19/38 [00:31<00:31,  1.67s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  50%|█████     | 19/38 [00:31<00:31,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  53%|█████▎    | 20/38 [00:31<00:28,  1.59s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  53%|█████▎    | 20/38 [00:31<00:28,  1.59s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  55%|█████▌    | 21/38 [00:34<00:27,  1.64s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  55%|█████▌    | 21/38 [00:34<00:27,  1.64s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  58%|█████▊    | 22/38 [00:34<00:25,  1.57s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  58%|█████▊    | 22/38 [00:34<00:25,  1.57s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  61%|██████    | 23/38 [00:34<00:22,  1.51s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  61%|██████    | 23/38 [00:34<00:22,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  63%|██████▎   | 24/38 [00:34<00:20,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  63%|██████▎   | 24/38 [00:34<00:20,  1.45s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  66%|██████▌   | 25/38 [00:37<00:19,  1.51s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  66%|██████▌   | 25/38 [00:37<00:19,  1.51s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  68%|██████▊   | 26/38 [00:37<00:17,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  68%|██████▊   | 26/38 [00:37<00:17,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  71%|███████   | 27/38 [00:38<00:15,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  71%|███████   | 27/38 [00:38<00:15,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  74%|███████▎  | 28/38 [00:38<00:13,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  74%|███████▎  | 28/38 [00:38<00:13,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  76%|███████▋  | 29/38 [00:40<00:12,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  76%|███████▋  | 29/38 [00:40<00:12,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  79%|███████▉  | 30/38 [00:40<00:10,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15:  79%|███████▉  | 30/38 [00:40<00:10,  1.34s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.99it/s]\u001b[A\n",
      "Epoch 15:  82%|████████▏ | 31/38 [00:48<00:10,  1.55s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.43it/s]\u001b[A\n",
      "Epoch 15:  84%|████████▍ | 32/38 [00:48<00:09,  1.52s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.30it/s]\u001b[A\n",
      "Epoch 15:  87%|████████▋ | 33/38 [00:48<00:07,  1.48s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.04it/s]\u001b[A\n",
      "Epoch 15:  89%|████████▉ | 34/38 [00:48<00:05,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 35/38 [00:51<00:04,  1.47s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.40it/s]\u001b[A\n",
      "Epoch 15:  95%|█████████▍| 36/38 [00:52<00:02,  1.45s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.49it/s]\u001b[A\n",
      "Epoch 15:  97%|█████████▋| 37/38 [00:52<00:01,  1.42s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.68it/s]\u001b[A\n",
      "Epoch 15: 100%|██████████| 38/38 [00:52<00:00,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 15: 100%|██████████| 38/38 [00:52<00:00,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 15: 100%|██████████| 38/38 [00:52<00:00,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 15:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]         \n",
      "Epoch 16:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:   3%|▎         | 1/38 [00:17<10:52, 17.63s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:   3%|▎         | 1/38 [00:17<10:52, 17.64s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:   5%|▌         | 2/38 [00:17<05:20,  8.90s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:   5%|▌         | 2/38 [00:17<05:20,  8.91s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:   8%|▊         | 3/38 [00:17<03:29,  5.99s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:   8%|▊         | 3/38 [00:17<03:29,  5.99s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  11%|█         | 4/38 [00:18<02:34,  4.54s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  11%|█         | 4/38 [00:18<02:34,  4.54s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  13%|█▎        | 5/38 [00:19<02:08,  3.90s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  13%|█▎        | 5/38 [00:19<02:08,  3.90s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  16%|█▌        | 6/38 [00:20<01:49,  3.42s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  16%|█▌        | 6/38 [00:20<01:49,  3.42s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  18%|█▊        | 7/38 [00:20<01:31,  2.95s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  32%|███▏      | 12/38 [00:23<00:51,  1.97s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  32%|███▏      | 12/38 [00:23<00:51,  1.97s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  34%|███▍      | 13/38 [00:25<00:49,  1.99s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  68%|██████▊   | 26/38 [00:34<00:16,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  68%|██████▊   | 26/38 [00:35<00:16,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.86it/s]\u001b[A\n",
      "Epoch 16:  82%|████████▏ | 31/38 [00:45<00:10,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.79it/s]\u001b[A\n",
      "Epoch 16:  84%|████████▍ | 32/38 [00:45<00:08,  1.43s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.06it/s]\u001b[A\n",
      "Epoch 16:  87%|████████▋ | 33/38 [00:45<00:06,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.78it/s]\u001b[A\n",
      "Epoch 16:  89%|████████▉ | 34/38 [00:46<00:05,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 35/38 [00:48<00:04,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "Epoch 16:  95%|█████████▍| 36/38 [00:49<00:02,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.48it/s]\u001b[A\n",
      "Epoch 16:  97%|█████████▋| 37/38 [00:49<00:01,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.67it/s]\u001b[A\n",
      "Epoch 16: 100%|██████████| 38/38 [00:49<00:00,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "Epoch 16: 100%|██████████| 38/38 [00:49<00:00,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.00]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 16: 100%|██████████| 38/38 [00:49<00:00,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 16:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]         \n",
      "Epoch 17:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:   3%|▎         | 1/38 [00:17<11:01, 17.88s/it, loss=1.11, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:   3%|▎         | 1/38 [00:17<11:02, 17.89s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:   5%|▌         | 2/38 [00:18<05:24,  9.03s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:   5%|▌         | 2/38 [00:18<05:25,  9.03s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:   8%|▊         | 3/38 [00:18<03:32,  6.07s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:   8%|▊         | 3/38 [00:18<03:32,  6.08s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  11%|█         | 4/38 [00:18<02:36,  4.60s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  11%|█         | 4/38 [00:18<02:36,  4.60s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  13%|█▎        | 5/38 [00:20<02:17,  4.15s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  13%|█▎        | 5/38 [00:20<02:17,  4.16s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  16%|█▌        | 6/38 [00:20<01:51,  3.49s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  16%|█▌        | 6/38 [00:20<01:51,  3.49s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  18%|█▊        | 7/38 [00:21<01:33,  3.02s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  18%|█▊        | 7/38 [00:21<01:33,  3.02s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  24%|██▎       | 9/38 [00:23<01:15,  2.62s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  24%|██▎       | 9/38 [00:23<01:15,  2.62s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  26%|██▋       | 10/38 [00:23<01:06,  2.37s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  26%|██▋       | 10/38 [00:23<01:06,  2.37s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  32%|███▏      | 12/38 [00:24<00:52,  2.01s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  32%|███▏      | 12/38 [00:24<00:52,  2.01s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  34%|███▍      | 13/38 [00:26<00:51,  2.04s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  34%|███▍      | 13/38 [00:26<00:51,  2.05s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  37%|███▋      | 14/38 [00:26<00:45,  1.91s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  37%|███▋      | 14/38 [00:26<00:45,  1.91s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  39%|███▉      | 15/38 [00:26<00:41,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20] \n",
      "Epoch 17:  42%|████▏     | 16/38 [00:27<00:37,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  42%|████▏     | 16/38 [00:27<00:37,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20] \n",
      "Epoch 17:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  55%|█████▌    | 21/38 [00:32<00:26,  1.56s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  55%|█████▌    | 21/38 [00:32<00:26,  1.56s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  58%|█████▊    | 22/38 [00:32<00:23,  1.49s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  58%|█████▊    | 22/38 [00:32<00:23,  1.49s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  63%|██████▎   | 24/38 [00:33<00:19,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  63%|██████▎   | 24/38 [00:33<00:19,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  74%|███████▎  | 28/38 [00:36<00:13,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  74%|███████▎  | 28/38 [00:36<00:13,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  76%|███████▋  | 29/38 [00:38<00:11,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  76%|███████▋  | 29/38 [00:38<00:11,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20] \n",
      "Epoch 17:  79%|███████▉  | 30/38 [00:38<00:10,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:  79%|███████▉  | 30/38 [00:38<00:10,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.48it/s]\u001b[A\n",
      "Epoch 17:  82%|████████▏ | 31/38 [00:46<00:10,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.50it/s]\u001b[A\n",
      "Epoch 17:  84%|████████▍ | 32/38 [00:46<00:08,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.25it/s]\u001b[A\n",
      "Epoch 17:  87%|████████▋ | 33/38 [00:46<00:07,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.98it/s]\u001b[A\n",
      "Epoch 17:  89%|████████▉ | 34/38 [00:46<00:05,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 35/38 [00:49<00:04,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.40it/s]\u001b[A\n",
      "Epoch 17:  95%|█████████▍| 36/38 [00:50<00:02,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.49it/s]\u001b[A\n",
      "Epoch 17:  97%|█████████▋| 37/38 [00:50<00:01,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.68it/s]\u001b[A\n",
      "Epoch 17: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 17: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 17:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]         \n",
      "Epoch 18:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:   3%|▎         | 1/38 [00:17<10:30, 17.05s/it, loss=1.11, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:   3%|▎         | 1/38 [00:17<10:31, 17.07s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20] \n",
      "Epoch 18:   5%|▌         | 2/38 [00:17<05:09,  8.61s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:   5%|▌         | 2/38 [00:17<05:10,  8.62s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:   8%|▊         | 3/38 [00:17<03:22,  5.80s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:   8%|▊         | 3/38 [00:17<03:23,  5.80s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20] \n",
      "Epoch 18:  13%|█▎        | 5/38 [00:20<02:12,  4.03s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  13%|█▎        | 5/38 [00:20<02:12,  4.03s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  16%|█▌        | 6/38 [00:20<01:48,  3.39s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  16%|█▌        | 6/38 [00:20<01:48,  3.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  18%|█▊        | 7/38 [00:20<01:30,  2.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  18%|█▊        | 7/38 [00:20<01:30,  2.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  21%|██        | 8/38 [00:20<01:17,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  21%|██        | 8/38 [00:20<01:17,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  24%|██▎       | 9/38 [00:23<01:14,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  24%|██▎       | 9/38 [00:23<01:14,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  26%|██▋       | 10/38 [00:23<01:05,  2.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  26%|██▋       | 10/38 [00:23<01:05,  2.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  37%|███▋      | 14/38 [00:26<00:46,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  37%|███▋      | 14/38 [00:26<00:46,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  39%|███▉      | 15/38 [00:27<00:41,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  39%|███▉      | 15/38 [00:27<00:41,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  42%|████▏     | 16/38 [00:27<00:37,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  42%|████▏     | 16/38 [00:27<00:37,  1.70s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20] \n",
      "Epoch 18:  55%|█████▌    | 21/38 [00:32<00:26,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  55%|█████▌    | 21/38 [00:32<00:26,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  71%|███████   | 27/38 [00:35<00:14,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  71%|███████   | 27/38 [00:35<00:14,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  74%|███████▎  | 28/38 [00:36<00:12,  1.29s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  74%|███████▎  | 28/38 [00:36<00:12,  1.29s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.37it/s]\u001b[A\n",
      "Epoch 18:  82%|████████▏ | 31/38 [00:45<00:10,  1.47s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.43it/s]\u001b[A\n",
      "Epoch 18:  84%|████████▍ | 32/38 [00:46<00:08,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.23it/s]\u001b[A\n",
      "Epoch 18:  87%|████████▋ | 33/38 [00:46<00:07,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.96it/s]\u001b[A\n",
      "Epoch 18:  89%|████████▉ | 34/38 [00:46<00:05,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 35/38 [00:48<00:04,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.40it/s]\u001b[A\n",
      "Epoch 18:  95%|█████████▍| 36/38 [00:49<00:02,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.50it/s]\u001b[A\n",
      "Epoch 18:  97%|█████████▋| 37/38 [00:49<00:01,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.69it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 18: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 18: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 18:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]         \n",
      "Epoch 19:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:   3%|▎         | 1/38 [00:16<10:24, 16.88s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:   3%|▎         | 1/38 [00:16<10:24, 16.89s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:   5%|▌         | 2/38 [00:17<05:10,  8.61s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:   5%|▌         | 2/38 [00:17<05:10,  8.62s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:   8%|▊         | 3/38 [00:17<03:23,  5.80s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:   8%|▊         | 3/38 [00:17<03:23,  5.81s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  13%|█▎        | 5/38 [00:19<02:07,  3.88s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  16%|█▌        | 6/38 [00:20<01:49,  3.43s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  16%|█▌        | 6/38 [00:20<01:49,  3.43s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  24%|██▎       | 9/38 [00:22<01:11,  2.48s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  24%|██▎       | 9/38 [00:22<01:11,  2.48s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  42%|████▏     | 16/38 [00:26<00:36,  1.68s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  76%|███████▋  | 29/38 [00:38<00:11,  1.32s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  76%|███████▋  | 29/38 [00:38<00:11,  1.32s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  79%|███████▉  | 30/38 [00:38<00:10,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19:  79%|███████▉  | 30/38 [00:38<00:10,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.05it/s]\u001b[A\n",
      "Epoch 19:  82%|████████▏ | 31/38 [00:46<00:10,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.75it/s]\u001b[A\n",
      "Epoch 19:  84%|████████▍ | 32/38 [00:46<00:08,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.33it/s]\u001b[A\n",
      "Epoch 19:  87%|████████▋ | 33/38 [00:46<00:07,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.08it/s]\u001b[A\n",
      "Epoch 19:  89%|████████▉ | 34/38 [00:46<00:05,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 35/38 [00:49<00:04,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "Epoch 19:  95%|█████████▍| 36/38 [00:49<00:02,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.51it/s]\u001b[A\n",
      "Epoch 19:  97%|█████████▋| 37/38 [00:50<00:01,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\u001b[A\n",
      "Epoch 19: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 19: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 19: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 19:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]         \n",
      "Epoch 20:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:   3%|▎         | 1/38 [00:17<10:35, 17.17s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:   3%|▎         | 1/38 [00:17<10:35, 17.18s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:   5%|▌         | 2/38 [00:17<05:12,  8.67s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:   5%|▌         | 2/38 [00:17<05:12,  8.67s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:   8%|▊         | 3/38 [00:17<03:24,  5.84s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:   8%|▊         | 3/38 [00:17<03:24,  5.84s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  11%|█         | 4/38 [00:17<02:30,  4.42s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  11%|█         | 4/38 [00:17<02:30,  4.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10] \n",
      "Epoch 20:  13%|█▎        | 5/38 [00:19<02:08,  3.88s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  13%|█▎        | 5/38 [00:19<02:08,  3.88s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  16%|█▌        | 6/38 [00:20<01:49,  3.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  16%|█▌        | 6/38 [00:20<01:49,  3.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  18%|█▊        | 7/38 [00:20<01:31,  2.95s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  18%|█▊        | 7/38 [00:20<01:31,  2.95s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  21%|██        | 8/38 [00:20<01:17,  2.60s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  21%|██        | 8/38 [00:20<01:18,  2.60s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  24%|██▎       | 9/38 [00:23<01:14,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  24%|██▎       | 9/38 [00:23<01:14,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  26%|██▋       | 10/38 [00:23<01:06,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  26%|██▋       | 10/38 [00:23<01:06,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  29%|██▉       | 11/38 [00:24<00:59,  2.19s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  29%|██▉       | 11/38 [00:24<00:59,  2.19s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  32%|███▏      | 12/38 [00:24<00:52,  2.02s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  32%|███▏      | 12/38 [00:24<00:52,  2.02s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  37%|███▋      | 14/38 [00:26<00:46,  1.93s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  37%|███▋      | 14/38 [00:26<00:46,  1.93s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  39%|███▉      | 15/38 [00:27<00:41,  1.81s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  39%|███▉      | 15/38 [00:27<00:41,  1.81s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  42%|████▏     | 16/38 [00:27<00:37,  1.71s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  42%|████▏     | 16/38 [00:27<00:37,  1.71s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  45%|████▍     | 17/38 [00:29<00:36,  1.74s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  45%|████▍     | 17/38 [00:29<00:36,  1.74s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  47%|████▋     | 18/38 [00:29<00:33,  1.65s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  47%|████▋     | 18/38 [00:29<00:33,  1.65s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  50%|█████     | 19/38 [00:29<00:29,  1.58s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  58%|█████▊    | 22/38 [00:32<00:23,  1.47s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  63%|██████▎   | 24/38 [00:33<00:19,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  63%|██████▎   | 24/38 [00:33<00:19,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10] \n",
      "Epoch 20:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.46it/s]\u001b[A\n",
      "Epoch 20:  82%|████████▏ | 31/38 [00:45<00:10,  1.45s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.59it/s]\u001b[A\n",
      "Epoch 20:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.41it/s]\u001b[A\n",
      "Epoch 20:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.16it/s]\u001b[A\n",
      "Epoch 20:  89%|████████▉ | 34/38 [00:45<00:05,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.41it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 35/38 [00:48<00:04,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "Epoch 20:  95%|█████████▍| 36/38 [00:48<00:02,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.53it/s]\u001b[A\n",
      "Epoch 20:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\u001b[A\n",
      "Epoch 20: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=36.10]\n",
      "Epoch 20: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=36.10]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 20: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 20:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]         \n",
      "Epoch 21:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:   3%|▎         | 1/38 [00:16<10:27, 16.97s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:   3%|▎         | 1/38 [00:16<10:28, 16.98s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:   5%|▌         | 2/38 [00:17<05:14,  8.73s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:   5%|▌         | 2/38 [00:17<05:14,  8.74s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:   8%|▊         | 3/38 [00:17<03:25,  5.88s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:   8%|▊         | 3/38 [00:17<03:25,  5.88s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  11%|█         | 4/38 [00:17<02:31,  4.45s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  11%|█         | 4/38 [00:17<02:31,  4.45s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  13%|█▎        | 5/38 [00:19<02:11,  3.98s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  13%|█▎        | 5/38 [00:19<02:11,  3.98s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  16%|█▌        | 6/38 [00:20<01:49,  3.43s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  16%|█▌        | 6/38 [00:20<01:49,  3.43s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  24%|██▎       | 9/38 [00:23<01:15,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  24%|██▎       | 9/38 [00:23<01:15,  2.61s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  26%|██▋       | 10/38 [00:23<01:06,  2.36s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  26%|██▋       | 10/38 [00:23<01:06,  2.37s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  29%|██▉       | 11/38 [00:23<00:58,  2.16s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  32%|███▏      | 12/38 [00:23<00:51,  2.00s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  32%|███▏      | 12/38 [00:23<00:51,  2.00s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  45%|████▍     | 17/38 [00:28<00:35,  1.68s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  47%|████▋     | 18/38 [00:28<00:31,  1.60s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  47%|████▋     | 18/38 [00:28<00:32,  1.60s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50] \n",
      "Epoch 21:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  53%|█████▎    | 20/38 [00:29<00:26,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  66%|██████▌   | 25/38 [00:35<00:18,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  66%|██████▌   | 25/38 [00:35<00:18,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  68%|██████▊   | 26/38 [00:35<00:16,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21:  79%|███████▉  | 30/38 [00:37<00:10,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.95it/s]\u001b[A\n",
      "Epoch 21:  82%|████████▏ | 31/38 [00:45<00:10,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.65it/s]\u001b[A\n",
      "Epoch 21:  84%|████████▍ | 32/38 [00:46<00:08,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.04it/s]\u001b[A\n",
      "Epoch 21:  87%|████████▋ | 33/38 [00:46<00:07,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.75it/s]\u001b[A\n",
      "Epoch 21:  89%|████████▉ | 34/38 [00:46<00:05,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.40it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 35/38 [00:49<00:04,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 21:  95%|█████████▍| 36/38 [00:49<00:02,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.49it/s]\u001b[A\n",
      "Epoch 21:  97%|█████████▋| 37/38 [00:50<00:01,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.68it/s]\u001b[A\n",
      "Epoch 21: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.50]\n",
      "Epoch 21: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=35.50]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 21: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 21:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]         \n",
      "Epoch 22:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:   3%|▎         | 1/38 [00:18<11:07, 18.04s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:   3%|▎         | 1/38 [00:18<11:08, 18.05s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:   5%|▌         | 2/38 [00:19<05:43,  9.53s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:   5%|▌         | 2/38 [00:19<05:43,  9.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90] \n",
      "Epoch 22:   8%|▊         | 3/38 [00:19<03:44,  6.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:   8%|▊         | 3/38 [00:19<03:44,  6.42s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  11%|█         | 4/38 [00:19<02:44,  4.85s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  11%|█         | 4/38 [00:19<02:45,  4.85s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90] \n",
      "Epoch 22:  13%|█▎        | 5/38 [00:20<02:17,  4.16s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  13%|█▎        | 5/38 [00:20<02:17,  4.17s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  16%|█▌        | 6/38 [00:22<01:58,  3.70s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  16%|█▌        | 6/38 [00:22<01:58,  3.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90] \n",
      "Epoch 22:  18%|█▊        | 7/38 [00:22<01:40,  3.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  18%|█▊        | 7/38 [00:22<01:40,  3.26s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  21%|██        | 8/38 [00:22<01:26,  2.87s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  21%|██        | 8/38 [00:22<01:26,  2.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  24%|██▎       | 9/38 [00:24<01:19,  2.73s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  24%|██▎       | 9/38 [00:24<01:19,  2.73s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  26%|██▋       | 10/38 [00:25<01:11,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  26%|██▋       | 10/38 [00:25<01:11,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  29%|██▉       | 11/38 [00:26<01:06,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  29%|██▉       | 11/38 [00:26<01:06,  2.45s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  32%|███▏      | 12/38 [00:27<00:58,  2.26s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  32%|███▏      | 12/38 [00:27<00:58,  2.26s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  34%|███▍      | 13/38 [00:27<00:52,  2.10s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  34%|███▍      | 13/38 [00:27<00:52,  2.11s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  37%|███▋      | 14/38 [00:28<00:48,  2.01s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  37%|███▋      | 14/38 [00:28<00:48,  2.01s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  39%|███▉      | 15/38 [00:29<00:45,  1.98s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  39%|███▉      | 15/38 [00:29<00:45,  1.98s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  42%|████▏     | 16/38 [00:29<00:40,  1.86s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  42%|████▏     | 16/38 [00:29<00:41,  1.86s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  45%|████▍     | 17/38 [00:29<00:37,  1.76s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  45%|████▍     | 17/38 [00:29<00:37,  1.76s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  47%|████▋     | 18/38 [00:31<00:34,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  47%|████▋     | 18/38 [00:31<00:34,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  50%|█████     | 19/38 [00:32<00:32,  1.71s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  50%|█████     | 19/38 [00:32<00:32,  1.71s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  53%|█████▎    | 20/38 [00:32<00:29,  1.64s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  53%|█████▎    | 20/38 [00:32<00:29,  1.64s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  55%|█████▌    | 21/38 [00:32<00:26,  1.57s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  55%|█████▌    | 21/38 [00:32<00:26,  1.57s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  58%|█████▊    | 22/38 [00:34<00:24,  1.55s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  58%|█████▊    | 22/38 [00:34<00:24,  1.55s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  61%|██████    | 23/38 [00:35<00:23,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  61%|██████    | 23/38 [00:35<00:23,  1.54s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  63%|██████▎   | 24/38 [00:35<00:20,  1.49s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  63%|██████▎   | 24/38 [00:35<00:20,  1.49s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  68%|██████▊   | 26/38 [00:36<00:16,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  68%|██████▊   | 26/38 [00:36<00:16,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  71%|███████   | 27/38 [00:37<00:15,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  71%|███████   | 27/38 [00:37<00:15,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  74%|███████▎  | 28/38 [00:37<00:13,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  74%|███████▎  | 28/38 [00:37<00:13,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  76%|███████▋  | 29/38 [00:38<00:11,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  76%|███████▋  | 29/38 [00:38<00:11,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  79%|███████▉  | 30/38 [00:39<00:10,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22:  79%|███████▉  | 30/38 [00:39<00:10,  1.31s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.06it/s]\u001b[A\n",
      "Epoch 22:  82%|████████▏ | 31/38 [00:46<00:10,  1.51s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.71it/s]\u001b[A\n",
      "Epoch 22:  84%|████████▍ | 32/38 [00:47<00:08,  1.48s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.45it/s]\u001b[A\n",
      "Epoch 22:  87%|████████▋ | 33/38 [00:47<00:07,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.21it/s]\u001b[A\n",
      "Epoch 22:  89%|████████▉ | 34/38 [00:47<00:05,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.39it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 35/38 [00:50<00:04,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 22:  95%|█████████▍| 36/38 [00:50<00:02,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.50it/s]\u001b[A\n",
      "Epoch 22:  97%|█████████▋| 37/38 [00:51<00:01,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.69it/s]\u001b[A\n",
      "Epoch 22: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "Epoch 22: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.90]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 22: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 22:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]         \n",
      "Epoch 23:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:   3%|▎         | 1/38 [00:17<10:40, 17.31s/it, loss=1.12, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:   3%|▎         | 1/38 [00:17<10:40, 17.32s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:   5%|▌         | 2/38 [00:17<05:14,  8.73s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:   5%|▌         | 2/38 [00:17<05:14,  8.74s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:   8%|▊         | 3/38 [00:17<03:29,  5.98s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:   8%|▊         | 3/38 [00:17<03:29,  5.98s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  11%|█         | 4/38 [00:18<02:33,  4.53s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  11%|█         | 4/38 [00:18<02:34,  4.53s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  13%|█▎        | 5/38 [00:19<02:09,  3.92s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  13%|█▎        | 5/38 [00:19<02:09,  3.92s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  16%|█▌        | 6/38 [00:20<01:48,  3.40s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  16%|█▌        | 6/38 [00:20<01:48,  3.40s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  18%|█▊        | 7/38 [00:21<01:33,  3.02s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  18%|█▊        | 7/38 [00:21<01:33,  3.02s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  26%|██▋       | 10/38 [00:23<01:05,  2.34s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  26%|██▋       | 10/38 [00:23<01:05,  2.34s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  29%|██▉       | 11/38 [00:24<00:59,  2.19s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  29%|██▉       | 11/38 [00:24<00:59,  2.19s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70] \n",
      "Epoch 23:  32%|███▏      | 12/38 [00:24<00:52,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  32%|███▏      | 12/38 [00:24<00:52,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  34%|███▍      | 13/38 [00:25<00:49,  1.99s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  34%|███▍      | 13/38 [00:25<00:49,  1.99s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  37%|███▋      | 14/38 [00:26<00:45,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  37%|███▋      | 14/38 [00:26<00:45,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  42%|████▏     | 16/38 [00:26<00:36,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  42%|████▏     | 16/38 [00:26<00:36,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  53%|█████▎    | 20/38 [00:29<00:26,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  53%|█████▎    | 20/38 [00:30<00:27,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  55%|█████▌    | 21/38 [00:31<00:25,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  55%|█████▌    | 21/38 [00:31<00:25,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  63%|██████▎   | 24/38 [00:33<00:19,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  63%|██████▎   | 24/38 [00:33<00:19,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  68%|██████▊   | 26/38 [00:36<00:16,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  68%|██████▊   | 26/38 [00:36<00:16,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.08it/s]\u001b[A\n",
      "Epoch 23:  82%|████████▏ | 31/38 [00:45<00:10,  1.48s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.42it/s]\u001b[A\n",
      "Epoch 23:  84%|████████▍ | 32/38 [00:46<00:08,  1.45s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.91it/s]\u001b[A\n",
      "Epoch 23:  87%|████████▋ | 33/38 [00:46<00:07,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.60it/s]\u001b[A\n",
      "Epoch 23:  89%|████████▉ | 34/38 [00:46<00:05,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.36it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 35/38 [00:49<00:04,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.35it/s]\u001b[A\n",
      "Epoch 23:  95%|█████████▍| 36/38 [00:50<00:02,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.42it/s]\u001b[A\n",
      "Epoch 23:  97%|█████████▋| 37/38 [00:50<00:01,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 23: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.70]\n",
      "Epoch 23: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=30.70]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 23: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 23:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]         \n",
      "Epoch 24:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:   3%|▎         | 1/38 [00:16<10:23, 16.86s/it, loss=1.12, v_num=33, train_acc1_step=16.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:   3%|▎         | 1/38 [00:16<10:24, 16.87s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:   5%|▌         | 2/38 [00:17<05:13,  8.71s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:   5%|▌         | 2/38 [00:17<05:13,  8.71s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:   8%|▊         | 3/38 [00:17<03:25,  5.86s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:   8%|▊         | 3/38 [00:17<03:25,  5.86s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  11%|█         | 4/38 [00:17<02:30,  4.43s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  11%|█         | 4/38 [00:17<02:30,  4.44s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  13%|█▎        | 5/38 [00:20<02:15,  4.10s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  13%|█▎        | 5/38 [00:20<02:15,  4.11s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  16%|█▌        | 6/38 [00:20<01:50,  3.45s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  16%|█▌        | 6/38 [00:20<01:50,  3.45s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  18%|█▊        | 7/38 [00:20<01:32,  2.98s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  18%|█▊        | 7/38 [00:20<01:32,  2.98s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  21%|██        | 8/38 [00:21<01:18,  2.63s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  21%|██        | 8/38 [00:21<01:18,  2.63s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  24%|██▎       | 9/38 [00:23<01:16,  2.62s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  24%|██▎       | 9/38 [00:23<01:16,  2.63s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  26%|██▋       | 10/38 [00:23<01:06,  2.38s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  26%|██▋       | 10/38 [00:23<01:06,  2.38s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  29%|██▉       | 11/38 [00:23<00:58,  2.18s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  29%|██▉       | 11/38 [00:23<00:58,  2.18s/it, loss=1.13, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  32%|███▏      | 12/38 [00:24<00:52,  2.01s/it, loss=1.13, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  32%|███▏      | 12/38 [00:24<00:52,  2.01s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  50%|█████     | 19/38 [00:30<00:30,  1.59s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  50%|█████     | 19/38 [00:30<00:30,  1.59s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  55%|█████▌    | 21/38 [00:31<00:25,  1.52s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  55%|█████▌    | 21/38 [00:31<00:25,  1.52s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  63%|██████▎   | 24/38 [00:33<00:19,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  63%|██████▎   | 24/38 [00:33<00:19,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  74%|███████▎  | 28/38 [00:37<00:13,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  74%|███████▎  | 28/38 [00:37<00:13,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  76%|███████▋  | 29/38 [00:37<00:11,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  76%|███████▋  | 29/38 [00:37<00:11,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  79%|███████▉  | 30/38 [00:37<00:10,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24:  79%|███████▉  | 30/38 [00:37<00:10,  1.27s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.23it/s]\u001b[A\n",
      "Epoch 24:  82%|████████▏ | 31/38 [00:46<00:10,  1.49s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.24it/s]\u001b[A\n",
      "Epoch 24:  84%|████████▍ | 32/38 [00:46<00:08,  1.46s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.90it/s]\u001b[A\n",
      "Epoch 24:  87%|████████▋ | 33/38 [00:46<00:07,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.60it/s]\u001b[A\n",
      "Epoch 24:  89%|████████▉ | 34/38 [00:46<00:05,  1.38s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.37it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 35/38 [00:49<00:04,  1.41s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.37it/s]\u001b[A\n",
      "Epoch 24:  95%|█████████▍| 36/38 [00:50<00:02,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.45it/s]\u001b[A\n",
      "Epoch 24:  97%|█████████▋| 37/38 [00:50<00:01,  1.37s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.64it/s]\u001b[A\n",
      "Epoch 24: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.70]\n",
      "Epoch 24: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.70]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 24: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 24:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]         \n",
      "Epoch 25:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:   3%|▎         | 1/38 [00:17<10:31, 17.06s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:   3%|▎         | 1/38 [00:17<10:31, 17.07s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:   5%|▌         | 2/38 [00:17<05:09,  8.61s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:   5%|▌         | 2/38 [00:17<05:10,  8.61s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:   8%|▊         | 3/38 [00:17<03:22,  5.79s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:   8%|▊         | 3/38 [00:17<03:22,  5.80s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  13%|█▎        | 5/38 [00:19<02:11,  3.99s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  13%|█▎        | 5/38 [00:19<02:11,  3.99s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00] \n",
      "Epoch 25:  16%|█▌        | 6/38 [00:20<01:47,  3.35s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  16%|█▌        | 6/38 [00:20<01:47,  3.36s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  18%|█▊        | 7/38 [00:20<01:29,  2.90s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  18%|█▊        | 7/38 [00:20<01:29,  2.90s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  21%|██        | 8/38 [00:20<01:16,  2.56s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.13, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.13, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  32%|███▏      | 12/38 [00:23<00:51,  1.97s/it, loss=1.13, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  32%|███▏      | 12/38 [00:23<00:51,  1.97s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  34%|███▍      | 13/38 [00:26<00:51,  2.06s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  34%|███▍      | 13/38 [00:26<00:51,  2.06s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  37%|███▋      | 14/38 [00:26<00:46,  1.92s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  37%|███▋      | 14/38 [00:26<00:46,  1.92s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  39%|███▉      | 15/38 [00:27<00:41,  1.81s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  39%|███▉      | 15/38 [00:27<00:41,  1.81s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  42%|████▏     | 16/38 [00:27<00:37,  1.70s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  42%|████▏     | 16/38 [00:27<00:37,  1.71s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  55%|█████▌    | 21/38 [00:32<00:26,  1.55s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  55%|█████▌    | 21/38 [00:32<00:26,  1.55s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  58%|█████▊    | 22/38 [00:32<00:23,  1.49s/it, loss=1.13, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  61%|██████    | 23/38 [00:32<00:21,  1.43s/it, loss=1.13, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  61%|██████    | 23/38 [00:32<00:21,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.14, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.14, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  74%|███████▎  | 28/38 [00:36<00:12,  1.29s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  74%|███████▎  | 28/38 [00:36<00:12,  1.29s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  76%|███████▋  | 29/38 [00:38<00:11,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  76%|███████▋  | 29/38 [00:38<00:11,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  79%|███████▉  | 30/38 [00:38<00:10,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25:  79%|███████▉  | 30/38 [00:38<00:10,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.58it/s]\u001b[A\n",
      "Epoch 25:  82%|████████▏ | 31/38 [00:45<00:10,  1.48s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.45it/s]\u001b[A\n",
      "Epoch 25:  84%|████████▍ | 32/38 [00:46<00:08,  1.45s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.32it/s]\u001b[A\n",
      "Epoch 25:  87%|████████▋ | 33/38 [00:46<00:07,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.05it/s]\u001b[A\n",
      "Epoch 25:  89%|████████▉ | 34/38 [00:46<00:05,  1.37s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 35/38 [00:49<00:04,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "Epoch 25:  95%|█████████▍| 36/38 [00:49<00:02,  1.38s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 25:  97%|█████████▋| 37/38 [00:50<00:01,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 25: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.00]\n",
      "Epoch 25: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=29.00]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 25: 100%|██████████| 38/38 [00:50<00:00,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 25:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]         \n",
      "Epoch 26:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:   3%|▎         | 1/38 [00:16<10:27, 16.96s/it, loss=1.12, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:   3%|▎         | 1/38 [00:16<10:27, 16.97s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:   5%|▌         | 2/38 [00:17<05:08,  8.56s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:   5%|▌         | 2/38 [00:17<05:08,  8.57s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:   8%|▊         | 3/38 [00:17<03:23,  5.81s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:   8%|▊         | 3/38 [00:17<03:23,  5.82s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  11%|█         | 4/38 [00:17<02:29,  4.41s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  13%|█▎        | 5/38 [00:19<02:05,  3.81s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  13%|█▎        | 5/38 [00:19<02:05,  3.81s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  16%|█▌        | 6/38 [00:19<01:43,  3.23s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  16%|█▌        | 6/38 [00:19<01:43,  3.23s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  18%|█▊        | 7/38 [00:19<01:28,  2.84s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  18%|█▊        | 7/38 [00:19<01:28,  2.84s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  21%|██        | 8/38 [00:20<01:15,  2.51s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  21%|██        | 8/38 [00:20<01:15,  2.51s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  24%|██▎       | 9/38 [00:21<01:09,  2.40s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  24%|██▎       | 9/38 [00:21<01:09,  2.40s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.13, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.13, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.13, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  34%|███▍      | 13/38 [00:24<00:46,  1.86s/it, loss=1.13, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  34%|███▍      | 13/38 [00:24<00:46,  1.86s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.13, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.12, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  45%|████▍     | 17/38 [00:27<00:33,  1.61s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  45%|████▍     | 17/38 [00:27<00:33,  1.61s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  53%|█████▎    | 20/38 [00:29<00:26,  1.50s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  55%|█████▌    | 21/38 [00:30<00:24,  1.47s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  55%|█████▌    | 21/38 [00:30<00:24,  1.47s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  63%|██████▎   | 24/38 [00:32<00:19,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  63%|██████▎   | 24/38 [00:32<00:19,  1.36s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.12, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.72it/s]\u001b[A\n",
      "Epoch 26:  82%|████████▏ | 31/38 [00:44<00:09,  1.43s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.49it/s]\u001b[A\n",
      "Epoch 26:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.14it/s]\u001b[A\n",
      "Epoch 26:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.87it/s]\u001b[A\n",
      "Epoch 26:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.48it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.38it/s]\u001b[A\n",
      "Epoch 26:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.52it/s]\u001b[A\n",
      "Epoch 26:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\u001b[A\n",
      "Epoch 26: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 26: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.90]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 26: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 26:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]         \n",
      "Epoch 27:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:   3%|▎         | 1/38 [00:16<10:09, 16.48s/it, loss=1.11, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:   3%|▎         | 1/38 [00:16<10:10, 16.49s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:   5%|▌         | 2/38 [00:16<04:59,  8.32s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:   5%|▌         | 2/38 [00:16<04:59,  8.33s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:   8%|▊         | 3/38 [00:16<03:16,  5.60s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:   8%|▊         | 3/38 [00:16<03:16,  5.60s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  11%|█         | 4/38 [00:16<02:24,  4.24s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  11%|█         | 4/38 [00:16<02:24,  4.25s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.12, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  18%|█▊        | 7/38 [00:20<01:28,  2.87s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  18%|█▊        | 7/38 [00:20<01:28,  2.87s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  24%|██▎       | 9/38 [00:21<01:10,  2.42s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  24%|██▎       | 9/38 [00:21<01:10,  2.42s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  26%|██▋       | 10/38 [00:23<01:06,  2.36s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  26%|██▋       | 10/38 [00:23<01:06,  2.37s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  32%|███▏      | 12/38 [00:24<00:52,  2.00s/it, loss=1.12, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  32%|███▏      | 12/38 [00:24<00:52,  2.00s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  34%|███▍      | 13/38 [00:25<00:49,  1.96s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  34%|███▍      | 13/38 [00:25<00:49,  1.96s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  37%|███▋      | 14/38 [00:26<00:46,  1.92s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  37%|███▋      | 14/38 [00:26<00:46,  1.92s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  39%|███▉      | 15/38 [00:27<00:41,  1.80s/it, loss=1.11, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  39%|███▉      | 15/38 [00:27<00:41,  1.80s/it, loss=1.11, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  42%|████▏     | 16/38 [00:27<00:37,  1.70s/it, loss=1.11, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  42%|████▏     | 16/38 [00:27<00:37,  1.70s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  47%|████▋     | 18/38 [00:30<00:33,  1.68s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  47%|████▋     | 18/38 [00:30<00:33,  1.68s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  53%|█████▎    | 20/38 [00:30<00:27,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  53%|█████▎    | 20/38 [00:30<00:27,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  55%|█████▌    | 21/38 [00:32<00:25,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  55%|█████▌    | 21/38 [00:32<00:25,  1.53s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  58%|█████▊    | 22/38 [00:32<00:23,  1.50s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  58%|█████▊    | 22/38 [00:32<00:23,  1.50s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  63%|██████▎   | 24/38 [00:33<00:19,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  63%|██████▎   | 24/38 [00:33<00:19,  1.39s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  66%|██████▌   | 25/38 [00:34<00:18,  1.40s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  66%|██████▌   | 25/38 [00:34<00:18,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00] \n",
      "Epoch 27:  68%|██████▊   | 26/38 [00:35<00:16,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  68%|██████▊   | 26/38 [00:35<00:16,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.64it/s]\u001b[A\n",
      "Epoch 27:  82%|████████▏ | 31/38 [00:45<00:10,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.47it/s]\u001b[A\n",
      "Epoch 27:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.19it/s]\u001b[A\n",
      "Epoch 27:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.93it/s]\u001b[A\n",
      "Epoch 27:  89%|████████▉ | 34/38 [00:45<00:05,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 35/38 [00:48<00:04,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.45it/s]\u001b[A\n",
      "Epoch 27:  95%|█████████▍| 36/38 [00:48<00:02,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.54it/s]\u001b[A\n",
      "Epoch 27:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\u001b[A\n",
      "Epoch 27: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=34.00]\n",
      "Epoch 27: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.00]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 27: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 27:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]         \n",
      "Epoch 28:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:   3%|▎         | 1/38 [00:17<10:47, 17.50s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:   3%|▎         | 1/38 [00:17<10:48, 17.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:   5%|▌         | 2/38 [00:17<05:18,  8.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:   5%|▌         | 2/38 [00:17<05:18,  8.84s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:   8%|▊         | 3/38 [00:17<03:28,  5.94s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:   8%|▊         | 3/38 [00:17<03:28,  5.95s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  11%|█         | 4/38 [00:17<02:32,  4.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  11%|█         | 4/38 [00:18<02:33,  4.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  13%|█▎        | 5/38 [00:20<02:14,  4.07s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  13%|█▎        | 5/38 [00:20<02:14,  4.08s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  16%|█▌        | 6/38 [00:20<01:49,  3.42s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  16%|█▌        | 6/38 [00:20<01:49,  3.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.09, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.09, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90] \n",
      "Epoch 28:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.09, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  32%|███▏      | 12/38 [00:23<00:51,  1.96s/it, loss=1.09, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  32%|███▏      | 12/38 [00:23<00:51,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90] \n",
      "Epoch 28:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.09, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.09, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90] \n",
      "Epoch 28:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  55%|█████▌    | 21/38 [00:30<00:25,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  55%|█████▌    | 21/38 [00:30<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.80it/s]\u001b[A\n",
      "Epoch 28:  82%|████████▏ | 31/38 [00:44<00:10,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.56it/s]\u001b[A\n",
      "Epoch 28:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.49it/s]\u001b[A\n",
      "Epoch 28:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.28it/s]\u001b[A\n",
      "Epoch 28:  89%|████████▉ | 34/38 [00:45<00:05,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.40it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 28:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.52it/s]\u001b[A\n",
      "Epoch 28:  97%|█████████▋| 37/38 [00:48<00:01,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.71it/s]\u001b[A\n",
      "Epoch 28: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 28: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=31.90]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 28: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 28:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]         \n",
      "Epoch 29:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:   3%|▎         | 1/38 [00:16<10:22, 16.83s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:   3%|▎         | 1/38 [00:16<10:22, 16.84s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:   5%|▌         | 2/38 [00:17<05:08,  8.56s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:   5%|▌         | 2/38 [00:17<05:08,  8.57s/it, loss=1.09, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:   8%|▊         | 3/38 [00:17<03:21,  5.76s/it, loss=1.09, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:   8%|▊         | 3/38 [00:17<03:21,  5.77s/it, loss=1.09, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  11%|█         | 4/38 [00:17<02:28,  4.36s/it, loss=1.09, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  11%|█         | 4/38 [00:17<02:28,  4.37s/it, loss=1.09, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.09, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  13%|█▎        | 5/38 [00:19<02:10,  3.96s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30] \n",
      "Epoch 29:  16%|█▌        | 6/38 [00:20<01:51,  3.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  16%|█▌        | 6/38 [00:20<01:51,  3.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  18%|█▊        | 7/38 [00:21<01:33,  3.02s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  18%|█▊        | 7/38 [00:21<01:33,  3.02s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  21%|██        | 8/38 [00:21<01:19,  2.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  21%|██        | 8/38 [00:21<01:19,  2.67s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  24%|██▎       | 9/38 [00:22<01:13,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  24%|██▎       | 9/38 [00:22<01:13,  2.53s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  26%|██▋       | 10/38 [00:24<01:09,  2.48s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  26%|██▋       | 10/38 [00:24<01:09,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30] \n",
      "Epoch 29:  29%|██▉       | 11/38 [00:25<01:01,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  29%|██▉       | 11/38 [00:25<01:01,  2.27s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  32%|███▏      | 12/38 [00:25<00:54,  2.10s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  32%|███▏      | 12/38 [00:25<00:54,  2.10s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  34%|███▍      | 13/38 [00:25<00:49,  2.00s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  34%|███▍      | 13/38 [00:25<00:49,  2.00s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  37%|███▋      | 14/38 [00:27<00:47,  1.97s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  37%|███▋      | 14/38 [00:27<00:47,  1.97s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  39%|███▉      | 15/38 [00:27<00:42,  1.85s/it, loss=1.11, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  39%|███▉      | 15/38 [00:27<00:42,  1.85s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  42%|████▏     | 16/38 [00:27<00:38,  1.74s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  42%|████▏     | 16/38 [00:27<00:38,  1.75s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  47%|████▋     | 18/38 [00:30<00:34,  1.70s/it, loss=1.11, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  47%|████▋     | 18/38 [00:30<00:34,  1.70s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  50%|█████     | 19/38 [00:30<00:30,  1.62s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  50%|█████     | 19/38 [00:30<00:30,  1.62s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  53%|█████▎    | 20/38 [00:30<00:27,  1.55s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  53%|█████▎    | 20/38 [00:31<00:27,  1.55s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  58%|█████▊    | 22/38 [00:33<00:24,  1.50s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  58%|█████▊    | 22/38 [00:33<00:24,  1.50s/it, loss=1.13, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.13, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  63%|██████▎   | 24/38 [00:33<00:19,  1.39s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  63%|██████▎   | 24/38 [00:33<00:19,  1.39s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.13, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  68%|██████▊   | 26/38 [00:36<00:16,  1.39s/it, loss=1.13, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  68%|██████▊   | 26/38 [00:36<00:16,  1.39s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.13, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  71%|███████   | 27/38 [00:36<00:14,  1.35s/it, loss=1.13, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  74%|███████▎  | 28/38 [00:36<00:13,  1.30s/it, loss=1.13, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  74%|███████▎  | 28/38 [00:36<00:13,  1.30s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  76%|███████▋  | 29/38 [00:37<00:11,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  76%|███████▋  | 29/38 [00:37<00:11,  1.28s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  79%|███████▉  | 30/38 [00:38<00:10,  1.29s/it, loss=1.12, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29:  79%|███████▉  | 30/38 [00:38<00:10,  1.29s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:00, 13.16it/s]\u001b[A\n",
      "Epoch 29:  82%|████████▏ | 31/38 [00:46<00:10,  1.50s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.45it/s]\u001b[A\n",
      "Epoch 29:  84%|████████▍ | 32/38 [00:47<00:08,  1.48s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.90it/s]\u001b[A\n",
      "Epoch 29:  87%|████████▋ | 33/38 [00:47<00:07,  1.44s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.58it/s]\u001b[A\n",
      "Epoch 29:  89%|████████▉ | 34/38 [00:47<00:05,  1.40s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 35/38 [00:50<00:04,  1.43s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.42it/s]\u001b[A\n",
      "Epoch 29:  95%|█████████▍| 36/38 [00:50<00:02,  1.41s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.49it/s]\u001b[A\n",
      "Epoch 29:  97%|█████████▋| 37/38 [00:51<00:01,  1.39s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.67it/s]\u001b[A\n",
      "Epoch 29: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=36.70, train_acc1_epoch=35.30]\n",
      "Epoch 29: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=35.30]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 29: 100%|██████████| 38/38 [00:51<00:00,  1.35s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 29:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]         \n",
      "Epoch 30:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:   3%|▎         | 1/38 [00:17<10:31, 17.06s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:   3%|▎         | 1/38 [00:17<10:31, 17.08s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:   5%|▌         | 2/38 [00:17<05:10,  8.61s/it, loss=1.12, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:   5%|▌         | 2/38 [00:17<05:10,  8.62s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:   8%|▊         | 3/38 [00:17<03:23,  5.80s/it, loss=1.11, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:   8%|▊         | 3/38 [00:17<03:23,  5.80s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.11, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.12, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  16%|█▌        | 6/38 [00:20<01:46,  3.34s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  16%|█▌        | 6/38 [00:20<01:46,  3.34s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.12, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  24%|██▎       | 9/38 [00:22<01:13,  2.55s/it, loss=1.11, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  24%|██▎       | 9/38 [00:22<01:13,  2.55s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.11, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.11, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  34%|███▍      | 13/38 [00:26<00:50,  2.02s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.11, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00] \n",
      "Epoch 30:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  42%|████▏     | 16/38 [00:26<00:36,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  55%|█████▌    | 21/38 [00:32<00:26,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  55%|█████▌    | 21/38 [00:32<00:26,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  58%|█████▊    | 22/38 [00:32<00:23,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  58%|█████▊    | 22/38 [00:32<00:23,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  61%|██████    | 23/38 [00:32<00:21,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  61%|██████    | 23/38 [00:32<00:21,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  63%|██████▎   | 24/38 [00:33<00:19,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  63%|██████▎   | 24/38 [00:33<00:19,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  66%|██████▌   | 25/38 [00:36<00:18,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  66%|██████▌   | 25/38 [00:36<00:18,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  68%|██████▊   | 26/38 [00:36<00:16,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  68%|██████▊   | 26/38 [00:36<00:16,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  71%|███████   | 27/38 [00:36<00:14,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  71%|███████   | 27/38 [00:36<00:14,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  74%|███████▎  | 28/38 [00:36<00:13,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  74%|███████▎  | 28/38 [00:36<00:13,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  76%|███████▋  | 29/38 [00:38<00:11,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  76%|███████▋  | 29/38 [00:38<00:11,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  79%|███████▉  | 30/38 [00:38<00:10,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30:  79%|███████▉  | 30/38 [00:38<00:10,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.33it/s]\u001b[A\n",
      "Epoch 30:  82%|████████▏ | 31/38 [00:45<00:10,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.36it/s]\u001b[A\n",
      "Epoch 30:  84%|████████▍ | 32/38 [00:46<00:08,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.22it/s]\u001b[A\n",
      "Epoch 30:  87%|████████▋ | 33/38 [00:46<00:07,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.93it/s]\u001b[A\n",
      "Epoch 30:  89%|████████▉ | 34/38 [00:46<00:05,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 35/38 [00:49<00:04,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 30:  95%|█████████▍| 36/38 [00:49<00:02,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.51it/s]\u001b[A\n",
      "Epoch 30:  97%|█████████▋| 37/38 [00:50<00:01,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\u001b[A\n",
      "Epoch 30: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 30: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.00]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 30: 100%|██████████| 38/38 [00:50<00:00,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 30:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]         \n",
      "Epoch 31:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:   3%|▎         | 1/38 [00:16<10:20, 16.78s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:   3%|▎         | 1/38 [00:16<10:21, 16.80s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:   5%|▌         | 2/38 [00:17<05:10,  8.61s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:   5%|▌         | 2/38 [00:17<05:10,  8.62s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:   8%|▊         | 3/38 [00:17<03:22,  5.80s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:   8%|▊         | 3/38 [00:17<03:23,  5.80s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  16%|█▌        | 6/38 [00:20<01:48,  3.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  16%|█▌        | 6/38 [00:20<01:48,  3.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  18%|█▊        | 7/38 [00:20<01:30,  2.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  18%|█▊        | 7/38 [00:20<01:30,  2.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  21%|██        | 8/38 [00:20<01:17,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  21%|██        | 8/38 [00:20<01:17,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  24%|██▎       | 9/38 [00:22<01:13,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  24%|██▎       | 9/38 [00:22<01:13,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  26%|██▋       | 10/38 [00:23<01:05,  2.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  26%|██▋       | 10/38 [00:23<01:05,  2.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  34%|███▍      | 13/38 [00:26<00:50,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  34%|███▍      | 13/38 [00:26<00:50,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  37%|███▋      | 14/38 [00:26<00:45,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  37%|███▋      | 14/38 [00:26<00:45,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  39%|███▉      | 15/38 [00:26<00:41,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  42%|████▏     | 16/38 [00:26<00:37,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  42%|████▏     | 16/38 [00:26<00:37,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  55%|█████▌    | 21/38 [00:33<00:26,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  55%|█████▌    | 21/38 [00:33<00:26,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  58%|█████▊    | 22/38 [00:33<00:24,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  58%|█████▊    | 22/38 [00:33<00:24,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  61%|██████    | 23/38 [00:33<00:21,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  61%|██████    | 23/38 [00:33<00:21,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  63%|██████▎   | 24/38 [00:33<00:19,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  63%|██████▎   | 24/38 [00:33<00:19,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  74%|███████▎  | 28/38 [00:36<00:12,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  74%|███████▎  | 28/38 [00:36<00:12,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  76%|███████▋  | 29/38 [00:38<00:12,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  76%|███████▋  | 29/38 [00:38<00:12,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  79%|███████▉  | 30/38 [00:38<00:10,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31:  79%|███████▉  | 30/38 [00:38<00:10,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  5.07it/s]\u001b[A\n",
      "Epoch 31:  82%|████████▏ | 31/38 [00:46<00:10,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.49it/s]\u001b[A\n",
      "Epoch 31:  84%|████████▍ | 32/38 [00:47<00:08,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.88it/s]\u001b[A\n",
      "Epoch 31:  87%|████████▋ | 33/38 [00:47<00:07,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.48it/s]\u001b[A\n",
      "Epoch 31:  89%|████████▉ | 34/38 [00:47<00:05,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.45it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 35/38 [00:49<00:04,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.46it/s]\u001b[A\n",
      "Epoch 31:  95%|█████████▍| 36/38 [00:50<00:02,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.53it/s]\u001b[A\n",
      "Epoch 31:  97%|█████████▋| 37/38 [00:50<00:01,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\u001b[A\n",
      "Epoch 31: 100%|██████████| 38/38 [00:50<00:00,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 31: 100%|██████████| 38/38 [00:50<00:00,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=30.30]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 31: 100%|██████████| 38/38 [00:50<00:00,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 31:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]         \n",
      "Epoch 32:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:   3%|▎         | 1/38 [00:17<10:57, 17.77s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:   3%|▎         | 1/38 [00:17<10:57, 17.78s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:   5%|▌         | 2/38 [00:17<05:22,  8.97s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:   5%|▌         | 2/38 [00:17<05:23,  8.97s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:   8%|▊         | 3/38 [00:18<03:31,  6.03s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:   8%|▊         | 3/38 [00:18<03:31,  6.04s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  11%|█         | 4/38 [00:18<02:35,  4.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  11%|█         | 4/38 [00:18<02:35,  4.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  13%|█▎        | 5/38 [00:21<02:21,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  13%|█▎        | 5/38 [00:21<02:21,  4.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  16%|█▌        | 6/38 [00:21<01:54,  3.59s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  16%|█▌        | 6/38 [00:21<01:55,  3.59s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  18%|█▊        | 7/38 [00:21<01:36,  3.10s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  18%|█▊        | 7/38 [00:21<01:36,  3.10s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  21%|██        | 8/38 [00:21<01:22,  2.74s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  21%|██        | 8/38 [00:21<01:22,  2.74s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  24%|██▎       | 9/38 [00:24<01:19,  2.75s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  24%|██▎       | 9/38 [00:24<01:19,  2.75s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  26%|██▋       | 10/38 [00:24<01:09,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  26%|██▋       | 10/38 [00:24<01:09,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  29%|██▉       | 11/38 [00:25<01:01,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  29%|██▉       | 11/38 [00:25<01:01,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  32%|███▏      | 12/38 [00:25<00:54,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  32%|███▏      | 12/38 [00:25<00:54,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  34%|███▍      | 13/38 [00:27<00:52,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  34%|███▍      | 13/38 [00:27<00:52,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  37%|███▋      | 14/38 [00:27<00:47,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  37%|███▋      | 14/38 [00:27<00:47,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  39%|███▉      | 15/38 [00:27<00:42,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  39%|███▉      | 15/38 [00:27<00:42,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  42%|████▏     | 16/38 [00:27<00:38,  1.74s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  42%|████▏     | 16/38 [00:27<00:38,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  45%|████▍     | 17/38 [00:30<00:37,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  45%|████▍     | 17/38 [00:30<00:37,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  47%|████▋     | 18/38 [00:30<00:33,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  47%|████▋     | 18/38 [00:30<00:33,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  50%|█████     | 19/38 [00:30<00:30,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  50%|█████     | 19/38 [00:30<00:30,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  53%|█████▎    | 20/38 [00:30<00:27,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  53%|█████▎    | 20/38 [00:30<00:27,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  55%|█████▌    | 21/38 [00:33<00:26,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  55%|█████▌    | 21/38 [00:33<00:26,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  58%|█████▊    | 22/38 [00:33<00:24,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  58%|█████▊    | 22/38 [00:33<00:24,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  61%|██████    | 23/38 [00:33<00:21,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  61%|██████    | 23/38 [00:33<00:21,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  63%|██████▎   | 24/38 [00:33<00:19,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  63%|██████▎   | 24/38 [00:33<00:19,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  66%|██████▌   | 25/38 [00:35<00:18,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  68%|██████▊   | 26/38 [00:35<00:16,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  68%|██████▊   | 26/38 [00:36<00:16,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  76%|███████▋  | 29/38 [00:37<00:11,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  76%|███████▋  | 29/38 [00:37<00:11,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  79%|███████▉  | 30/38 [00:38<00:10,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32:  79%|███████▉  | 30/38 [00:38<00:10,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.34it/s]\u001b[A\n",
      "Epoch 32:  82%|████████▏ | 31/38 [00:45<00:10,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.60it/s]\u001b[A\n",
      "Epoch 32:  84%|████████▍ | 32/38 [00:45<00:08,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.42it/s]\u001b[A\n",
      "Epoch 32:  87%|████████▋ | 33/38 [00:46<00:06,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.20it/s]\u001b[A\n",
      "Epoch 32:  89%|████████▉ | 34/38 [00:46<00:05,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 35/38 [00:48<00:04,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.42it/s]\u001b[A\n",
      "Epoch 32:  95%|█████████▍| 36/38 [00:49<00:02,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 32:  97%|█████████▋| 37/38 [00:49<00:01,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 32: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.10]\n",
      "Epoch 32: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.10]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 32: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 32:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]         \n",
      "Epoch 33:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:   3%|▎         | 1/38 [00:16<10:07, 16.41s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:   3%|▎         | 1/38 [00:16<10:07, 16.42s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:   5%|▌         | 2/38 [00:16<05:00,  8.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:   5%|▌         | 2/38 [00:16<05:00,  8.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:   8%|▊         | 3/38 [00:17<03:19,  5.71s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:   8%|▊         | 3/38 [00:17<03:19,  5.71s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  11%|█         | 4/38 [00:17<02:26,  4.32s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  11%|█         | 4/38 [00:17<02:27,  4.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  13%|█▎        | 5/38 [00:18<02:05,  3.79s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  13%|█▎        | 5/38 [00:18<02:05,  3.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  16%|█▌        | 6/38 [00:19<01:45,  3.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  16%|█▌        | 6/38 [00:19<01:45,  3.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  18%|█▊        | 7/38 [00:21<01:33,  3.00s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  18%|█▊        | 7/38 [00:21<01:33,  3.00s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  21%|██        | 8/38 [00:21<01:19,  2.65s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  21%|██        | 8/38 [00:21<01:19,  2.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  24%|██▎       | 9/38 [00:21<01:10,  2.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  24%|██▎       | 9/38 [00:21<01:10,  2.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  26%|██▋       | 10/38 [00:21<01:01,  2.20s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  26%|██▋       | 10/38 [00:21<01:01,  2.20s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  29%|██▉       | 11/38 [00:23<00:58,  2.17s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  32%|███▏      | 12/38 [00:23<00:51,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  32%|███▏      | 12/38 [00:23<00:51,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  66%|██████▌   | 25/38 [00:34<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  66%|██████▌   | 25/38 [00:34<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  76%|███████▋  | 29/38 [00:36<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  76%|███████▋  | 29/38 [00:36<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.67it/s]\u001b[A\n",
      "Epoch 33:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.70it/s]\u001b[A\n",
      "Epoch 33:  84%|████████▍ | 32/38 [00:43<00:08,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.50it/s]\u001b[A\n",
      "Epoch 33:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.28it/s]\u001b[A\n",
      "Epoch 33:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 35/38 [00:46<00:04,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.52it/s]\u001b[A\n",
      "Epoch 33:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 33:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\u001b[A\n",
      "Epoch 33: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "Epoch 33: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 33: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 33:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]         \n",
      "Epoch 34:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:   3%|▎         | 1/38 [00:17<10:31, 17.08s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:   3%|▎         | 1/38 [00:17<10:32, 17.09s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:   5%|▌         | 2/38 [00:17<05:10,  8.62s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:   5%|▌         | 2/38 [00:17<05:10,  8.63s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:   8%|▊         | 3/38 [00:17<03:22,  5.80s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:   8%|▊         | 3/38 [00:17<03:23,  5.80s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  11%|█         | 4/38 [00:17<02:29,  4.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  18%|█▊        | 7/38 [00:20<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  18%|█▊        | 7/38 [00:20<01:28,  2.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  26%|██▋       | 10/38 [00:22<01:04,  2.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  26%|██▋       | 10/38 [00:22<01:04,  2.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  29%|██▉       | 11/38 [00:23<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  29%|██▉       | 11/38 [00:23<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  45%|████▍     | 17/38 [00:28<00:35,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  45%|████▍     | 17/38 [00:28<00:35,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  47%|████▋     | 18/38 [00:28<00:31,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  47%|████▋     | 18/38 [00:28<00:31,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  71%|███████   | 27/38 [00:34<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:03,  2.27it/s]\u001b[A\n",
      "Epoch 34:  82%|████████▏ | 31/38 [00:44<00:09,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.99it/s]\u001b[A\n",
      "Epoch 34:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.38it/s]\u001b[A\n",
      "Epoch 34:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.15it/s]\u001b[A\n",
      "Epoch 34:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.52it/s]\u001b[A\n",
      "Epoch 34:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.53it/s]\u001b[A\n",
      "Epoch 34:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\u001b[A\n",
      "Epoch 34: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.00]\n",
      "Epoch 34: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.00]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 34: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 34:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]         \n",
      "Epoch 35:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:   3%|▎         | 1/38 [00:16<10:16, 16.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:   3%|▎         | 1/38 [00:16<10:16, 16.66s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:   5%|▌         | 2/38 [00:16<05:02,  8.40s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:   5%|▌         | 2/38 [00:16<05:02,  8.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:   8%|▊         | 3/38 [00:16<03:17,  5.66s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:   8%|▊         | 3/38 [00:16<03:18,  5.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  11%|█         | 4/38 [00:17<02:25,  4.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  11%|█         | 4/38 [00:17<02:25,  4.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  13%|█▎        | 5/38 [00:19<02:08,  3.89s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  13%|█▎        | 5/38 [00:19<02:08,  3.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  16%|█▌        | 6/38 [00:19<01:44,  3.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  16%|█▌        | 6/38 [00:19<01:44,  3.27s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  21%|██        | 8/38 [00:19<01:14,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  21%|██        | 8/38 [00:19<01:14,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  24%|██▎       | 9/38 [00:22<01:13,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  24%|██▎       | 9/38 [00:22<01:13,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  26%|██▋       | 10/38 [00:23<01:04,  2.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  29%|██▉       | 11/38 [00:23<00:56,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  29%|██▉       | 11/38 [00:23<00:57,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  34%|███▍      | 13/38 [00:26<00:50,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  34%|███▍      | 13/38 [00:26<00:50,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  37%|███▋      | 14/38 [00:26<00:45,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  37%|███▋      | 14/38 [00:26<00:45,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  42%|████▏     | 16/38 [00:26<00:37,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  42%|████▏     | 16/38 [00:26<00:37,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  55%|█████▌    | 21/38 [00:32<00:26,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  55%|█████▌    | 21/38 [00:32<00:26,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  58%|█████▊    | 22/38 [00:32<00:23,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  58%|█████▊    | 22/38 [00:32<00:23,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  61%|██████    | 23/38 [00:33<00:21,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  63%|██████▎   | 24/38 [00:33<00:19,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  63%|██████▎   | 24/38 [00:33<00:19,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.34it/s]\u001b[A\n",
      "Epoch 35:  82%|████████▏ | 31/38 [00:45<00:10,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.41it/s]\u001b[A\n",
      "Epoch 35:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.29it/s]\u001b[A\n",
      "Epoch 35:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.04it/s]\u001b[A\n",
      "Epoch 35:  89%|████████▉ | 34/38 [00:45<00:05,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 35/38 [00:48<00:04,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.46it/s]\u001b[A\n",
      "Epoch 35:  95%|█████████▍| 36/38 [00:48<00:02,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 35:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 35: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "Epoch 35: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.00]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 35: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 35:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]         \n",
      "Epoch 36:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:   3%|▎         | 1/38 [00:17<10:48, 17.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:   3%|▎         | 1/38 [00:17<10:48, 17.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:   5%|▌         | 2/38 [00:17<05:18,  8.84s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:   5%|▌         | 2/38 [00:17<05:18,  8.85s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:   8%|▊         | 3/38 [00:17<03:28,  5.95s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:   8%|▊         | 3/38 [00:17<03:28,  5.95s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  11%|█         | 4/38 [00:17<02:32,  4.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  11%|█         | 4/38 [00:18<02:33,  4.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  13%|█▎        | 5/38 [00:20<02:14,  4.08s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  13%|█▎        | 5/38 [00:20<02:14,  4.08s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  16%|█▌        | 6/38 [00:20<01:49,  3.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  16%|█▌        | 6/38 [00:20<01:49,  3.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  34%|███▍      | 13/38 [00:25<00:49,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  34%|███▍      | 13/38 [00:25<00:49,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  45%|████▍     | 17/38 [00:29<00:36,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  55%|█████▌    | 21/38 [00:32<00:26,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  55%|█████▌    | 21/38 [00:32<00:26,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  58%|█████▊    | 22/38 [00:32<00:23,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  58%|█████▊    | 22/38 [00:32<00:23,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  63%|██████▎   | 24/38 [00:32<00:19,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  63%|██████▎   | 24/38 [00:32<00:19,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  79%|███████▉  | 30/38 [00:37<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36:  79%|███████▉  | 30/38 [00:37<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.98it/s]\u001b[A\n",
      "Epoch 36:  82%|████████▏ | 31/38 [00:44<00:10,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.55it/s]\u001b[A\n",
      "Epoch 36:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.09it/s]\u001b[A\n",
      "Epoch 36:  87%|████████▋ | 33/38 [00:45<00:06,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.83it/s]\u001b[A\n",
      "Epoch 36:  89%|████████▉ | 34/38 [00:45<00:05,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.49it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.47it/s]\u001b[A\n",
      "Epoch 36:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.49it/s]\u001b[A\n",
      "Epoch 36:  97%|█████████▋| 37/38 [00:48<00:01,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.69it/s]\u001b[A\n",
      "Epoch 36: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "Epoch 36: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=27.10]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 36: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 36:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 37:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:   3%|▎         | 1/38 [00:17<10:36, 17.20s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:   3%|▎         | 1/38 [00:17<10:36, 17.21s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:   5%|▌         | 2/38 [00:17<05:12,  8.67s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:   5%|▌         | 2/38 [00:17<05:12,  8.68s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:   8%|▊         | 3/38 [00:17<03:24,  5.84s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:   8%|▊         | 3/38 [00:17<03:24,  5.84s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  11%|█         | 4/38 [00:17<02:30,  4.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  11%|█         | 4/38 [00:17<02:30,  4.42s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  13%|█▎        | 5/38 [00:20<02:13,  4.05s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  13%|█▎        | 5/38 [00:20<02:13,  4.05s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  16%|█▌        | 6/38 [00:20<01:48,  3.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  16%|█▌        | 6/38 [00:20<01:48,  3.40s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  18%|█▊        | 7/38 [00:20<01:31,  2.94s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  18%|█▊        | 7/38 [00:20<01:31,  2.94s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  21%|██        | 8/38 [00:20<01:17,  2.59s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  21%|██        | 8/38 [00:20<01:17,  2.59s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  24%|██▎       | 9/38 [00:22<01:11,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  24%|██▎       | 9/38 [00:22<01:11,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  29%|██▉       | 11/38 [00:23<00:58,  2.15s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  29%|██▉       | 11/38 [00:23<00:58,  2.15s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  32%|███▏      | 12/38 [00:23<00:51,  1.99s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  32%|███▏      | 12/38 [00:23<00:51,  1.99s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  34%|███▍      | 13/38 [00:24<00:46,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  34%|███▍      | 13/38 [00:24<00:46,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  39%|███▉      | 15/38 [00:26<00:40,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  42%|████▏     | 16/38 [00:26<00:36,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  45%|████▍     | 17/38 [00:26<00:33,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  45%|████▍     | 17/38 [00:26<00:33,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  53%|█████▎    | 20/38 [00:30<00:27,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  53%|█████▎    | 20/38 [00:30<00:27,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  55%|█████▌    | 21/38 [00:30<00:24,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  55%|█████▌    | 21/38 [00:30<00:24,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  63%|██████▎   | 24/38 [00:32<00:18,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  63%|██████▎   | 24/38 [00:32<00:18,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  66%|██████▌   | 25/38 [00:32<00:16,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  66%|██████▌   | 25/38 [00:32<00:16,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  68%|██████▊   | 26/38 [00:35<00:16,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  68%|██████▊   | 26/38 [00:35<00:16,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  79%|███████▉  | 30/38 [00:37<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37:  79%|███████▉  | 30/38 [00:37<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.51it/s]\u001b[A\n",
      "Epoch 37:  82%|████████▏ | 31/38 [00:44<00:10,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.55it/s]\u001b[A\n",
      "Epoch 37:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.25it/s]\u001b[A\n",
      "Epoch 37:  87%|████████▋ | 33/38 [00:45<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.00it/s]\u001b[A\n",
      "Epoch 37:  89%|████████▉ | 34/38 [00:45<00:05,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 37:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.53it/s]\u001b[A\n",
      "Epoch 37:  97%|█████████▋| 37/38 [00:48<00:01,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\u001b[A\n",
      "Epoch 37: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 37: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 37: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 37:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]         \n",
      "Epoch 38:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:   3%|▎         | 1/38 [00:16<09:59, 16.21s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:   3%|▎         | 1/38 [00:16<10:00, 16.22s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:   5%|▌         | 2/38 [00:16<05:01,  8.38s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:   5%|▌         | 2/38 [00:16<05:02,  8.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:   8%|▊         | 3/38 [00:16<03:17,  5.64s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:   8%|▊         | 3/38 [00:16<03:17,  5.65s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  13%|█▎        | 5/38 [00:19<02:06,  3.84s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  13%|█▎        | 5/38 [00:19<02:06,  3.85s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  16%|█▌        | 6/38 [00:19<01:45,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  18%|█▊        | 7/38 [00:19<01:27,  2.84s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  21%|██        | 8/38 [00:20<01:15,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  24%|██▎       | 9/38 [00:22<01:12,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  24%|██▎       | 9/38 [00:22<01:12,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  32%|███▏      | 12/38 [00:22<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  34%|███▍      | 13/38 [00:24<00:47,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  34%|███▍      | 13/38 [00:24<00:47,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  37%|███▋      | 14/38 [00:26<00:44,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  47%|████▋     | 18/38 [00:28<00:31,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  47%|████▋     | 18/38 [00:28<00:31,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  66%|██████▌   | 25/38 [00:33<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  71%|███████   | 27/38 [00:34<00:14,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.36it/s]\u001b[A\n",
      "Epoch 38:  82%|████████▏ | 31/38 [00:43<00:09,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.61it/s]\u001b[A\n",
      "Epoch 38:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.98it/s]\u001b[A\n",
      "Epoch 38:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.68it/s]\u001b[A\n",
      "Epoch 38:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "Epoch 38:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 38:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 38: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.10]\n",
      "Epoch 38: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.10]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 38: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 38:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]         \n",
      "Epoch 39:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:   3%|▎         | 1/38 [00:17<10:34, 17.14s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:   3%|▎         | 1/38 [00:17<10:34, 17.15s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:   5%|▌         | 2/38 [00:17<05:11,  8.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:   5%|▌         | 2/38 [00:17<05:11,  8.66s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:   8%|▊         | 3/38 [00:17<03:23,  5.82s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:   8%|▊         | 3/38 [00:17<03:23,  5.82s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  11%|█         | 4/38 [00:17<02:29,  4.41s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  13%|█▎        | 5/38 [00:19<02:08,  3.89s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  13%|█▎        | 5/38 [00:19<02:08,  3.89s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  16%|█▌        | 6/38 [00:19<01:44,  3.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  16%|█▌        | 6/38 [00:19<01:44,  3.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  18%|█▊        | 7/38 [00:19<01:27,  2.82s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  18%|█▊        | 7/38 [00:19<01:27,  2.82s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  21%|██        | 8/38 [00:19<01:14,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  21%|██        | 8/38 [00:19<01:14,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  24%|██▎       | 9/38 [00:22<01:11,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  24%|██▎       | 9/38 [00:22<01:11,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  26%|██▋       | 10/38 [00:22<01:02,  2.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  26%|██▋       | 10/38 [00:22<01:02,  2.24s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  29%|██▉       | 11/38 [00:22<00:55,  2.05s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  29%|██▉       | 11/38 [00:22<00:55,  2.05s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  32%|███▏      | 12/38 [00:22<00:49,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  32%|███▏      | 12/38 [00:22<00:49,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  34%|███▍      | 13/38 [00:24<00:47,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  34%|███▍      | 13/38 [00:24<00:47,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  37%|███▋      | 14/38 [00:24<00:42,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  37%|███▋      | 14/38 [00:24<00:42,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  39%|███▉      | 15/38 [00:24<00:38,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  39%|███▉      | 15/38 [00:24<00:38,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  42%|████▏     | 16/38 [00:25<00:34,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  42%|████▏     | 16/38 [00:25<00:34,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  50%|█████     | 19/38 [00:28<00:28,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  50%|█████     | 19/38 [00:28<00:28,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  55%|█████▌    | 21/38 [00:29<00:24,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  55%|█████▌    | 21/38 [00:29<00:24,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  58%|█████▊    | 22/38 [00:29<00:21,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  58%|█████▊    | 22/38 [00:29<00:21,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  66%|██████▌   | 25/38 [00:32<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  66%|██████▌   | 25/38 [00:32<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  68%|██████▊   | 26/38 [00:33<00:15,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  68%|██████▊   | 26/38 [00:33<00:15,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  79%|███████▉  | 30/38 [00:35<00:09,  1.18s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39:  79%|███████▉  | 30/38 [00:35<00:09,  1.18s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.98it/s]\u001b[A\n",
      "Epoch 39:  82%|████████▏ | 31/38 [00:42<00:09,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.63it/s]\u001b[A\n",
      "Epoch 39:  84%|████████▍ | 32/38 [00:43<00:08,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.30it/s]\u001b[A\n",
      "Epoch 39:  87%|████████▋ | 33/38 [00:43<00:06,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.06it/s]\u001b[A\n",
      "Epoch 39:  89%|████████▉ | 34/38 [00:43<00:05,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 35/38 [00:46<00:03,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 39:  95%|█████████▍| 36/38 [00:46<00:02,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 39:  97%|█████████▋| 37/38 [00:46<00:01,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 39: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "Epoch 39: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.50]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 39: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 39:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 40:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:   3%|▎         | 1/38 [00:16<10:26, 16.93s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:   3%|▎         | 1/38 [00:16<10:26, 16.94s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:   5%|▌         | 2/38 [00:17<05:07,  8.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:   5%|▌         | 2/38 [00:17<05:07,  8.55s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:   8%|▊         | 3/38 [00:17<03:21,  5.75s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:   8%|▊         | 3/38 [00:17<03:21,  5.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  11%|█         | 4/38 [00:17<02:27,  4.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  11%|█         | 4/38 [00:17<02:28,  4.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  13%|█▎        | 5/38 [00:20<02:12,  4.00s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  13%|█▎        | 5/38 [00:20<02:12,  4.01s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  16%|█▌        | 6/38 [00:20<01:47,  3.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  16%|█▌        | 6/38 [00:20<01:47,  3.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  18%|█▊        | 7/38 [00:20<01:31,  2.95s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  18%|█▊        | 7/38 [00:20<01:31,  2.95s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  21%|██        | 8/38 [00:20<01:17,  2.60s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  21%|██        | 8/38 [00:20<01:18,  2.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  29%|██▉       | 11/38 [00:23<00:57,  2.15s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  29%|██▉       | 11/38 [00:23<00:57,  2.15s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  34%|███▍      | 13/38 [00:25<00:48,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  39%|███▉      | 15/38 [00:26<00:41,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  42%|████▏     | 16/38 [00:27<00:37,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  42%|████▏     | 16/38 [00:27<00:37,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  55%|█████▌    | 21/38 [00:30<00:24,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  55%|█████▌    | 21/38 [00:30<00:24,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  58%|█████▊    | 22/38 [00:30<00:22,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  58%|█████▊    | 22/38 [00:30<00:22,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  61%|██████    | 23/38 [00:32<00:20,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  61%|██████    | 23/38 [00:32<00:20,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  76%|███████▋  | 29/38 [00:35<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  76%|███████▋  | 29/38 [00:36<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.55it/s]\u001b[A\n",
      "Epoch 40:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.88it/s]\u001b[A\n",
      "Epoch 40:  84%|████████▍ | 32/38 [00:43<00:08,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.53it/s]\u001b[A\n",
      "Epoch 40:  87%|████████▋ | 33/38 [00:44<00:06,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.31it/s]\u001b[A\n",
      "Epoch 40:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.41it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 35/38 [00:46<00:04,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.47it/s]\u001b[A\n",
      "Epoch 40:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 40:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 40: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 40: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 40: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 40:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]         \n",
      "Epoch 41:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:   3%|▎         | 1/38 [00:16<10:28, 16.97s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:   3%|▎         | 1/38 [00:16<10:28, 16.99s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:   5%|▌         | 2/38 [00:17<05:08,  8.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:   5%|▌         | 2/38 [00:17<05:08,  8.57s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:   8%|▊         | 3/38 [00:17<03:21,  5.77s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:   8%|▊         | 3/38 [00:17<03:21,  5.77s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  11%|█         | 4/38 [00:17<02:28,  4.36s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  11%|█         | 4/38 [00:17<02:28,  4.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  13%|█▎        | 5/38 [00:19<02:09,  3.93s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  13%|█▎        | 5/38 [00:19<02:09,  3.93s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  16%|█▌        | 6/38 [00:19<01:45,  3.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  16%|█▌        | 6/38 [00:19<01:45,  3.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  18%|█▊        | 7/38 [00:19<01:28,  2.85s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  18%|█▊        | 7/38 [00:19<01:28,  2.85s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  21%|██        | 8/38 [00:20<01:15,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  71%|███████   | 27/38 [00:34<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.34it/s]\u001b[A\n",
      "Epoch 41:  82%|████████▏ | 31/38 [00:44<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.50it/s]\u001b[A\n",
      "Epoch 41:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.29it/s]\u001b[A\n",
      "Epoch 41:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.05it/s]\u001b[A\n",
      "Epoch 41:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.40it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 41:  95%|█████████▍| 36/38 [00:47<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.57it/s]\u001b[A\n",
      "Epoch 41:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 41: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.80]\n",
      "Epoch 41: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.80]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 41: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 41:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]         \n",
      "Epoch 42:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:   3%|▎         | 1/38 [00:16<10:07, 16.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:   3%|▎         | 1/38 [00:16<10:07, 16.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:   5%|▌         | 2/38 [00:16<04:58,  8.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  11%|█         | 4/38 [00:16<02:23,  4.22s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  11%|█         | 4/38 [00:16<02:23,  4.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  13%|█▎        | 5/38 [00:18<02:03,  3.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  13%|█▎        | 5/38 [00:18<02:03,  3.75s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  16%|█▌        | 6/38 [00:20<01:47,  3.35s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  16%|█▌        | 6/38 [00:20<01:47,  3.35s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  24%|██▎       | 9/38 [00:21<01:09,  2.38s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  26%|██▋       | 10/38 [00:23<01:04,  2.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  26%|██▋       | 10/38 [00:23<01:04,  2.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  29%|██▉       | 11/38 [00:23<00:56,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  29%|██▉       | 11/38 [00:23<00:56,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  32%|███▏      | 12/38 [00:23<00:50,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  32%|███▏      | 12/38 [00:23<00:50,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  34%|███▍      | 13/38 [00:23<00:45,  1.82s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  34%|███▍      | 13/38 [00:23<00:45,  1.82s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  42%|████▏     | 16/38 [00:26<00:36,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  42%|████▏     | 16/38 [00:26<00:36,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  45%|████▍     | 17/38 [00:26<00:33,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  45%|████▍     | 17/38 [00:26<00:33,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  55%|█████▌    | 21/38 [00:29<00:24,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  55%|█████▌    | 21/38 [00:29<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.41it/s]\u001b[A\n",
      "Epoch 42:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.56it/s]\u001b[A\n",
      "Epoch 42:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.44it/s]\u001b[A\n",
      "Epoch 42:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.21it/s]\u001b[A\n",
      "Epoch 42:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 42:  95%|█████████▍| 36/38 [00:47<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 42:  97%|█████████▋| 37/38 [00:47<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\u001b[A\n",
      "Epoch 42: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "Epoch 42: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 42: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 42:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]         \n",
      "Epoch 43:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:   3%|▎         | 1/38 [00:16<10:04, 16.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:   3%|▎         | 1/38 [00:16<10:05, 16.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:   5%|▌         | 2/38 [00:16<05:01,  8.39s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:   5%|▌         | 2/38 [00:16<05:02,  8.39s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:   8%|▊         | 3/38 [00:16<03:17,  5.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:   8%|▊         | 3/38 [00:16<03:17,  5.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  13%|█▎        | 5/38 [00:19<02:06,  3.83s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  13%|█▎        | 5/38 [00:19<02:06,  3.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  18%|█▊        | 7/38 [00:19<01:26,  2.81s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  18%|█▊        | 7/38 [00:19<01:27,  2.81s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  21%|██        | 8/38 [00:19<01:14,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  21%|██        | 8/38 [00:19<01:14,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  24%|██▎       | 9/38 [00:22<01:12,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  24%|██▎       | 9/38 [00:22<01:12,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  26%|██▋       | 10/38 [00:22<01:03,  2.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  29%|██▉       | 11/38 [00:22<00:55,  2.07s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  29%|██▉       | 11/38 [00:22<00:56,  2.07s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  32%|███▏      | 12/38 [00:22<00:49,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  32%|███▏      | 12/38 [00:22<00:49,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  34%|███▍      | 13/38 [00:25<00:48,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  34%|███▍      | 13/38 [00:25<00:48,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  39%|███▉      | 15/38 [00:26<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  39%|███▉      | 15/38 [00:26<00:39,  1.74s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  42%|████▏     | 16/38 [00:26<00:35,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  42%|████▏     | 16/38 [00:26<00:35,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  45%|████▍     | 17/38 [00:28<00:34,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  45%|████▍     | 17/38 [00:28<00:34,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  68%|██████▊   | 26/38 [00:35<00:16,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  68%|██████▊   | 26/38 [00:35<00:16,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.42it/s]\u001b[A\n",
      "Epoch 43:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:01,  3.05it/s]\u001b[A\n",
      "Epoch 43:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.44it/s]\u001b[A\n",
      "Epoch 43:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.21it/s]\u001b[A\n",
      "Epoch 43:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.45it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 35/38 [00:47<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.54it/s]\u001b[A\n",
      "Epoch 43:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.57it/s]\u001b[A\n",
      "Epoch 43:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 43: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 43: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 43: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 43:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]         \n",
      "Epoch 44:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:   3%|▎         | 1/38 [00:16<10:13, 16.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:   3%|▎         | 1/38 [00:16<10:14, 16.60s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:   5%|▌         | 2/38 [00:16<05:01,  8.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:   5%|▌         | 2/38 [00:16<05:01,  8.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:   8%|▊         | 3/38 [00:16<03:17,  5.63s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:   8%|▊         | 3/38 [00:16<03:17,  5.64s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  11%|█         | 4/38 [00:17<02:24,  4.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  13%|█▎        | 5/38 [00:18<02:05,  3.79s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  13%|█▎        | 5/38 [00:18<02:05,  3.80s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  24%|██▎       | 9/38 [00:22<01:11,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  24%|██▎       | 9/38 [00:22<01:11,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  34%|███▍      | 13/38 [00:25<00:48,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  34%|███▍      | 13/38 [00:25<00:48,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  37%|███▋      | 14/38 [00:25<00:43,  1.82s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  50%|█████     | 19/38 [00:28<00:28,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  50%|█████     | 19/38 [00:28<00:28,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.45it/s]\u001b[A\n",
      "Epoch 44:  82%|████████▏ | 31/38 [00:44<00:10,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.55it/s]\u001b[A\n",
      "Epoch 44:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.34it/s]\u001b[A\n",
      "Epoch 44:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.08it/s]\u001b[A\n",
      "Epoch 44:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:01,  1.51it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 44:  95%|█████████▍| 36/38 [00:48<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 44:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 44: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "Epoch 44: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=29.80]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 44: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 44:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 45:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:   3%|▎         | 1/38 [00:16<10:08, 16.44s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:   3%|▎         | 1/38 [00:16<10:08, 16.45s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  11%|█         | 4/38 [00:16<02:23,  4.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  11%|█         | 4/38 [00:16<02:23,  4.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  13%|█▎        | 5/38 [00:18<02:04,  3.77s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  13%|█▎        | 5/38 [00:18<02:04,  3.77s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  16%|█▌        | 6/38 [00:19<01:42,  3.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  16%|█▌        | 6/38 [00:19<01:42,  3.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  18%|█▊        | 7/38 [00:19<01:26,  2.78s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  18%|█▊        | 7/38 [00:19<01:26,  2.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  24%|██▎       | 9/38 [00:22<01:11,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  24%|██▎       | 9/38 [00:22<01:11,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  29%|██▉       | 11/38 [00:22<00:55,  2.07s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  29%|██▉       | 11/38 [00:22<00:55,  2.07s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  32%|███▏      | 12/38 [00:22<00:49,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  32%|███▏      | 12/38 [00:22<00:49,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  45%|████▍     | 17/38 [00:27<00:33,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  45%|████▍     | 17/38 [00:27<00:33,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  55%|█████▌    | 21/38 [00:29<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  55%|█████▌    | 21/38 [00:29<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  66%|██████▌   | 25/38 [00:32<00:17,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  66%|██████▌   | 25/38 [00:32<00:17,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  71%|███████   | 27/38 [00:33<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  71%|███████   | 27/38 [00:33<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.03it/s]\u001b[A\n",
      "Epoch 45:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.73it/s]\u001b[A\n",
      "Epoch 45:  84%|████████▍ | 32/38 [00:43<00:08,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.20it/s]\u001b[A\n",
      "Epoch 45:  87%|████████▋ | 33/38 [00:43<00:06,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.93it/s]\u001b[A\n",
      "Epoch 45:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.39it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 35/38 [00:46<00:03,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.47it/s]\u001b[A\n",
      "Epoch 45:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.54it/s]\u001b[A\n",
      "Epoch 45:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\u001b[A\n",
      "Epoch 45: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 45: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 45:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 46:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:   3%|▎         | 1/38 [00:16<10:23, 16.85s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:   3%|▎         | 1/38 [00:16<10:23, 16.86s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:   5%|▌         | 2/38 [00:17<05:06,  8.50s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:   5%|▌         | 2/38 [00:17<05:06,  8.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:   8%|▊         | 3/38 [00:17<03:20,  5.72s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:   8%|▊         | 3/38 [00:17<03:20,  5.72s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  11%|█         | 4/38 [00:17<02:27,  4.33s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  11%|█         | 4/38 [00:17<02:27,  4.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  13%|█▎        | 5/38 [00:19<02:07,  3.88s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  18%|█▊        | 7/38 [00:19<01:27,  2.84s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  21%|██        | 8/38 [00:20<01:16,  2.56s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  24%|██▎       | 9/38 [00:21<01:09,  2.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  26%|██▋       | 10/38 [00:22<01:02,  2.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  26%|██▋       | 10/38 [00:22<01:02,  2.24s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  29%|██▉       | 11/38 [00:22<00:55,  2.05s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  29%|██▉       | 11/38 [00:22<00:55,  2.05s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  32%|███▏      | 12/38 [00:23<00:50,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  32%|███▏      | 12/38 [00:23<00:50,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  34%|███▍      | 13/38 [00:24<00:47,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  34%|███▍      | 13/38 [00:24<00:47,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  37%|███▋      | 14/38 [00:24<00:42,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  37%|███▋      | 14/38 [00:24<00:42,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  39%|███▉      | 15/38 [00:25<00:38,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  39%|███▉      | 15/38 [00:25<00:38,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  47%|████▋     | 18/38 [00:27<00:31,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  47%|████▋     | 18/38 [00:27<00:31,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  50%|█████     | 19/38 [00:28<00:28,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  50%|█████     | 19/38 [00:28<00:28,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  55%|█████▌    | 21/38 [00:30<00:24,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  55%|█████▌    | 21/38 [00:30<00:24,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  58%|█████▊    | 22/38 [00:30<00:22,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  58%|█████▊    | 22/38 [00:30<00:22,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  61%|██████    | 23/38 [00:31<00:20,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  61%|██████    | 23/38 [00:31<00:20,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  76%|███████▋  | 29/38 [00:36<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  76%|███████▋  | 29/38 [00:36<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.90it/s]\u001b[A\n",
      "Epoch 46:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.54it/s]\u001b[A\n",
      "Epoch 46:  84%|████████▍ | 32/38 [00:43<00:08,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.45it/s]\u001b[A\n",
      "Epoch 46:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.23it/s]\u001b[A\n",
      "Epoch 46:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 46:  92%|█████████▏| 35/38 [00:46<00:03,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.47it/s]\u001b[A\n",
      "Epoch 46:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.57it/s]\u001b[A\n",
      "Epoch 46:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 46: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 46: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 46:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 47:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:   3%|▎         | 1/38 [00:16<10:18, 16.71s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:   3%|▎         | 1/38 [00:16<10:18, 16.72s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:   5%|▌         | 2/38 [00:16<05:03,  8.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:   5%|▌         | 2/38 [00:16<05:03,  8.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:   8%|▊         | 3/38 [00:17<03:18,  5.67s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:   8%|▊         | 3/38 [00:17<03:18,  5.68s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  11%|█         | 4/38 [00:17<02:26,  4.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  11%|█         | 4/38 [00:17<02:26,  4.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  13%|█▎        | 5/38 [00:18<02:03,  3.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  13%|█▎        | 5/38 [00:18<02:03,  3.75s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  16%|█▌        | 6/38 [00:18<01:40,  3.15s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  16%|█▌        | 6/38 [00:18<01:40,  3.15s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  26%|██▋       | 10/38 [00:21<01:00,  2.16s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  26%|██▋       | 10/38 [00:21<01:00,  2.16s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  29%|██▉       | 11/38 [00:22<00:54,  2.01s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  29%|██▉       | 11/38 [00:22<00:54,  2.02s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  32%|███▏      | 12/38 [00:22<00:48,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  32%|███▏      | 12/38 [00:22<00:48,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  34%|███▍      | 13/38 [00:23<00:45,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  34%|███▍      | 13/38 [00:23<00:45,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  37%|███▋      | 14/38 [00:24<00:41,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  37%|███▋      | 14/38 [00:24<00:41,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  39%|███▉      | 15/38 [00:25<00:39,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  39%|███▉      | 15/38 [00:25<00:39,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  45%|████▍     | 17/38 [00:27<00:33,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  45%|████▍     | 17/38 [00:27<00:33,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  47%|████▋     | 18/38 [00:27<00:30,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  47%|████▋     | 18/38 [00:27<00:30,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  50%|█████     | 19/38 [00:28<00:28,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  50%|█████     | 19/38 [00:28<00:28,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  58%|█████▊    | 22/38 [00:30<00:22,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  58%|█████▊    | 22/38 [00:30<00:22,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  61%|██████    | 23/38 [00:32<00:20,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  61%|██████    | 23/38 [00:32<00:20,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  68%|██████▊   | 26/38 [00:33<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  68%|██████▊   | 26/38 [00:33<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.98it/s]\u001b[A\n",
      "Epoch 47:  82%|████████▏ | 31/38 [00:44<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.47it/s]\u001b[A\n",
      "Epoch 47:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.37it/s]\u001b[A\n",
      "Epoch 47:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.14it/s]\u001b[A\n",
      "Epoch 47:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.45it/s]\u001b[A\n",
      "Epoch 47:  95%|█████████▍| 36/38 [00:47<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 47:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 47: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 47: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 47: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 47:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]         \n",
      "Epoch 48:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:   3%|▎         | 1/38 [00:16<09:57, 16.16s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:   3%|▎         | 1/38 [00:16<09:58, 16.17s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:   5%|▌         | 2/38 [00:16<04:53,  8.16s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:   5%|▌         | 2/38 [00:16<04:53,  8.16s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:   8%|▊         | 3/38 [00:16<03:13,  5.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:   8%|▊         | 3/38 [00:16<03:13,  5.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  11%|█         | 4/38 [00:16<02:22,  4.18s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  11%|█         | 4/38 [00:16<02:22,  4.19s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  13%|█▎        | 5/38 [00:19<02:06,  3.85s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  13%|█▎        | 5/38 [00:19<02:07,  3.85s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  16%|█▌        | 6/38 [00:19<01:43,  3.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  16%|█▌        | 6/38 [00:19<01:43,  3.23s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  18%|█▊        | 7/38 [00:19<01:26,  2.79s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  18%|█▊        | 7/38 [00:19<01:26,  2.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  24%|██▎       | 9/38 [00:22<01:12,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  24%|██▎       | 9/38 [00:22<01:12,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  26%|██▋       | 10/38 [00:22<01:03,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  26%|██▋       | 10/38 [00:22<01:03,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  32%|███▏      | 12/38 [00:22<00:49,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  32%|███▏      | 12/38 [00:22<00:49,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  34%|███▍      | 13/38 [00:25<00:48,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  39%|███▉      | 15/38 [00:26<00:39,  1.74s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  39%|███▉      | 15/38 [00:26<00:39,  1.74s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  42%|████▏     | 16/38 [00:26<00:36,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  42%|████▏     | 16/38 [00:26<00:36,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  45%|████▍     | 17/38 [00:27<00:34,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  45%|████▍     | 17/38 [00:28<00:34,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  55%|█████▌    | 21/38 [00:30<00:25,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  55%|█████▌    | 21/38 [00:30<00:25,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  58%|█████▊    | 22/38 [00:31<00:22,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  58%|█████▊    | 22/38 [00:31<00:22,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  66%|██████▌   | 25/38 [00:34<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  66%|██████▌   | 25/38 [00:34<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.64it/s]\u001b[A\n",
      "Epoch 48:  82%|████████▏ | 31/38 [00:44<00:10,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.85it/s]\u001b[A\n",
      "Epoch 48:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.45it/s]\u001b[A\n",
      "Epoch 48:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.23it/s]\u001b[A\n",
      "Epoch 48:  89%|████████▉ | 34/38 [00:45<00:05,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.49it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 35/38 [00:47<00:04,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.52it/s]\u001b[A\n",
      "Epoch 48:  95%|█████████▍| 36/38 [00:48<00:02,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 48:  97%|█████████▋| 37/38 [00:48<00:01,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 48: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=32.60]\n",
      "Epoch 48: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 48: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 48:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]         \n",
      "Epoch 49:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:   3%|▎         | 1/38 [00:16<10:01, 16.24s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:   3%|▎         | 1/38 [00:16<10:01, 16.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:   5%|▌         | 2/38 [00:16<04:55,  8.20s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:   5%|▌         | 2/38 [00:16<04:55,  8.21s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:   8%|▊         | 3/38 [00:16<03:17,  5.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:   8%|▊         | 3/38 [00:16<03:17,  5.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  13%|█▎        | 5/38 [00:18<02:05,  3.79s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  13%|█▎        | 5/38 [00:18<02:05,  3.79s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  16%|█▌        | 6/38 [00:19<01:44,  3.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  16%|█▌        | 6/38 [00:19<01:44,  3.27s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  29%|██▉       | 11/38 [00:23<00:57,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  29%|██▉       | 11/38 [00:23<00:57,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  34%|███▍      | 13/38 [00:24<00:47,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  34%|███▍      | 13/38 [00:24<00:47,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  39%|███▉      | 15/38 [00:26<00:41,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  42%|████▏     | 16/38 [00:26<00:37,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  42%|████▏     | 16/38 [00:26<00:37,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  45%|████▍     | 17/38 [00:27<00:33,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  47%|████▋     | 18/38 [00:28<00:31,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  47%|████▋     | 18/38 [00:28<00:31,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  50%|█████     | 19/38 [00:28<00:28,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  55%|█████▌    | 21/38 [00:29<00:24,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  55%|█████▌    | 21/38 [00:29<00:24,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  63%|██████▎   | 24/38 [00:32<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  66%|██████▌   | 25/38 [00:32<00:16,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  66%|██████▌   | 25/38 [00:32<00:16,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.91it/s]\u001b[A\n",
      "Epoch 49:  82%|████████▏ | 31/38 [00:43<00:09,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.68it/s]\u001b[A\n",
      "Epoch 49:  84%|████████▍ | 32/38 [00:43<00:08,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.59it/s]\u001b[A\n",
      "Epoch 49:  87%|████████▋ | 33/38 [00:43<00:06,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.39it/s]\u001b[A\n",
      "Epoch 49:  89%|████████▉ | 34/38 [00:43<00:05,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.47it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 35/38 [00:46<00:03,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.47it/s]\u001b[A\n",
      "Epoch 49:  95%|█████████▍| 36/38 [00:46<00:02,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.59it/s]\u001b[A\n",
      "Epoch 49:  97%|█████████▋| 37/38 [00:47<00:01,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 49: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 49: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 49:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 50:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:   3%|▎         | 1/38 [00:17<10:45, 17.43s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:   3%|▎         | 1/38 [00:17<10:45, 17.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:   5%|▌         | 2/38 [00:17<05:16,  8.80s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:   5%|▌         | 2/38 [00:17<05:17,  8.81s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:   8%|▊         | 3/38 [00:17<03:27,  5.92s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:   8%|▊         | 3/38 [00:17<03:27,  5.92s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  11%|█         | 4/38 [00:17<02:32,  4.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  11%|█         | 4/38 [00:17<02:32,  4.48s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  13%|█▎        | 5/38 [00:20<02:14,  4.06s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  13%|█▎        | 5/38 [00:20<02:14,  4.07s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  16%|█▌        | 6/38 [00:20<01:49,  3.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  16%|█▌        | 6/38 [00:20<01:49,  3.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  18%|█▊        | 7/38 [00:20<01:31,  2.95s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  18%|█▊        | 7/38 [00:20<01:31,  2.95s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  21%|██        | 8/38 [00:20<01:17,  2.60s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  21%|██        | 8/38 [00:20<01:18,  2.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  45%|████▍     | 17/38 [00:28<00:35,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  45%|████▍     | 17/38 [00:28<00:35,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  53%|█████▎    | 20/38 [00:28<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  53%|█████▎    | 20/38 [00:28<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  55%|█████▌    | 21/38 [00:31<00:25,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  55%|█████▌    | 21/38 [00:31<00:25,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  61%|██████    | 23/38 [00:32<00:21,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.93it/s]\u001b[A\n",
      "Epoch 50:  82%|████████▏ | 31/38 [00:43<00:09,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.55it/s]\u001b[A\n",
      "Epoch 50:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.47it/s]\u001b[A\n",
      "Epoch 50:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.25it/s]\u001b[A\n",
      "Epoch 50:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 50:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 50:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 50: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 50: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 50:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 51:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:   3%|▎         | 1/38 [00:16<10:23, 16.86s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:   3%|▎         | 1/38 [00:16<10:24, 16.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:   5%|▌         | 2/38 [00:17<05:06,  8.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:   5%|▌         | 2/38 [00:17<05:06,  8.52s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:   8%|▊         | 3/38 [00:17<03:20,  5.73s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:   8%|▊         | 3/38 [00:17<03:20,  5.73s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  11%|█         | 4/38 [00:17<02:27,  4.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  11%|█         | 4/38 [00:17<02:27,  4.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  13%|█▎        | 5/38 [00:19<02:11,  3.99s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  13%|█▎        | 5/38 [00:19<02:11,  3.99s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  16%|█▌        | 6/38 [00:20<01:47,  3.35s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  16%|█▌        | 6/38 [00:20<01:47,  3.35s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  24%|██▎       | 9/38 [00:22<01:12,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  34%|███▍      | 13/38 [00:24<00:47,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  34%|███▍      | 13/38 [00:24<00:47,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  39%|███▉      | 15/38 [00:25<00:39,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  39%|███▉      | 15/38 [00:25<00:39,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  42%|████▏     | 16/38 [00:25<00:35,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  42%|████▏     | 16/38 [00:25<00:35,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  47%|████▋     | 18/38 [00:27<00:31,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  47%|████▋     | 18/38 [00:27<00:31,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.66it/s]\u001b[A\n",
      "Epoch 51:  82%|████████▏ | 31/38 [00:43<00:09,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.64it/s]\u001b[A\n",
      "Epoch 51:  84%|████████▍ | 32/38 [00:43<00:08,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.02it/s]\u001b[A\n",
      "Epoch 51:  87%|████████▋ | 33/38 [00:43<00:06,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.72it/s]\u001b[A\n",
      "Epoch 51:  89%|████████▉ | 34/38 [00:43<00:05,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 35/38 [00:46<00:03,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 51:  95%|█████████▍| 36/38 [00:46<00:02,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.53it/s]\u001b[A\n",
      "Epoch 51:  97%|█████████▋| 37/38 [00:47<00:01,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\u001b[A\n",
      "Epoch 51: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 51: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 51:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 52:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:   3%|▎         | 1/38 [00:16<09:56, 16.11s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:   3%|▎         | 1/38 [00:16<09:56, 16.12s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:   5%|▌         | 2/38 [00:16<04:52,  8.14s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:   5%|▌         | 2/38 [00:16<04:53,  8.14s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:   8%|▊         | 3/38 [00:16<03:12,  5.51s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:   8%|▊         | 3/38 [00:16<03:12,  5.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  11%|█         | 4/38 [00:16<02:21,  4.17s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  11%|█         | 4/38 [00:16<02:21,  4.17s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  13%|█▎        | 5/38 [00:19<02:06,  3.84s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  13%|█▎        | 5/38 [00:19<02:06,  3.84s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  16%|█▌        | 6/38 [00:19<01:43,  3.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  16%|█▌        | 6/38 [00:19<01:43,  3.23s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  18%|█▊        | 7/38 [00:19<01:26,  2.79s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  18%|█▊        | 7/38 [00:19<01:26,  2.79s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  24%|██▎       | 9/38 [00:21<01:10,  2.44s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  24%|██▎       | 9/38 [00:21<01:10,  2.44s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  29%|██▉       | 11/38 [00:22<00:54,  2.02s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  29%|██▉       | 11/38 [00:22<00:54,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  32%|███▏      | 12/38 [00:22<00:48,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  32%|███▏      | 12/38 [00:22<00:48,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  39%|███▉      | 15/38 [00:25<00:38,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  39%|███▉      | 15/38 [00:25<00:38,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  42%|████▏     | 16/38 [00:25<00:35,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  42%|████▏     | 16/38 [00:25<00:35,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  47%|████▋     | 18/38 [00:28<00:32,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  4.01it/s]\u001b[A\n",
      "Epoch 52:  82%|████████▏ | 31/38 [00:43<00:09,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.72it/s]\u001b[A\n",
      "Epoch 52:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.57it/s]\u001b[A\n",
      "Epoch 52:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.37it/s]\u001b[A\n",
      "Epoch 52:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:01,  1.51it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 52:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 52:  97%|█████████▋| 37/38 [00:47<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 52: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 52: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 52: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 52:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]         \n",
      "Epoch 53:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:   3%|▎         | 1/38 [00:15<09:46, 15.84s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:   3%|▎         | 1/38 [00:15<09:46, 15.86s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:   5%|▌         | 2/38 [00:16<04:48,  8.00s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:   5%|▌         | 2/38 [00:16<04:48,  8.01s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:   8%|▊         | 3/38 [00:16<03:09,  5.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:   8%|▊         | 3/38 [00:16<03:09,  5.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  11%|█         | 4/38 [00:16<02:19,  4.10s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  11%|█         | 4/38 [00:16<02:19,  4.11s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  13%|█▎        | 5/38 [00:18<02:04,  3.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  13%|█▎        | 5/38 [00:18<02:04,  3.78s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  16%|█▌        | 6/38 [00:19<01:41,  3.18s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  16%|█▌        | 6/38 [00:19<01:41,  3.18s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  18%|█▊        | 7/38 [00:19<01:25,  2.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  18%|█▊        | 7/38 [00:19<01:25,  2.75s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  21%|██        | 8/38 [00:19<01:12,  2.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  21%|██        | 8/38 [00:19<01:12,  2.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  24%|██▎       | 9/38 [00:22<01:11,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  24%|██▎       | 9/38 [00:22<01:11,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  26%|██▋       | 10/38 [00:22<01:02,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  26%|██▋       | 10/38 [00:22<01:02,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  32%|███▏      | 12/38 [00:22<00:49,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  32%|███▏      | 12/38 [00:22<00:49,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  39%|███▉      | 15/38 [00:25<00:38,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  39%|███▉      | 15/38 [00:25<00:38,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  42%|████▏     | 16/38 [00:25<00:35,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  42%|████▏     | 16/38 [00:25<00:35,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  45%|████▍     | 17/38 [00:28<00:35,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  45%|████▍     | 17/38 [00:28<00:35,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  53%|█████▎    | 20/38 [00:28<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  53%|█████▎    | 20/38 [00:28<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  68%|██████▊   | 26/38 [00:33<00:15,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  76%|███████▋  | 29/38 [00:35<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  76%|███████▋  | 29/38 [00:36<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.02it/s]\u001b[A\n",
      "Epoch 53:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.62it/s]\u001b[A\n",
      "Epoch 53:  84%|████████▍ | 32/38 [00:43<00:08,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.31it/s]\u001b[A\n",
      "Epoch 53:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.07it/s]\u001b[A\n",
      "Epoch 53:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 35/38 [00:46<00:04,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.42it/s]\u001b[A\n",
      "Epoch 53:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.49it/s]\u001b[A\n",
      "Epoch 53:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.68it/s]\u001b[A\n",
      "Epoch 53: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=31.90]\n",
      "Epoch 53: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.90]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 53: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 53:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]         \n",
      "Epoch 54:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:   3%|▎         | 1/38 [00:16<10:17, 16.68s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:   3%|▎         | 1/38 [00:16<10:17, 16.69s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:   5%|▌         | 2/38 [00:16<05:02,  8.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:   5%|▌         | 2/38 [00:16<05:03,  8.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:   8%|▊         | 3/38 [00:16<03:18,  5.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:   8%|▊         | 3/38 [00:17<03:18,  5.67s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  13%|█▎        | 5/38 [00:19<02:06,  3.84s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  13%|█▎        | 5/38 [00:19<02:06,  3.84s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  16%|█▌        | 6/38 [00:20<01:46,  3.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  16%|█▌        | 6/38 [00:20<01:46,  3.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  24%|██▎       | 9/38 [00:22<01:10,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  24%|██▎       | 9/38 [00:22<01:11,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  26%|██▋       | 10/38 [00:22<01:02,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  26%|██▋       | 10/38 [00:22<01:02,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  34%|███▍      | 13/38 [00:24<00:47,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  34%|███▍      | 13/38 [00:24<00:47,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  42%|████▏     | 16/38 [00:25<00:35,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  42%|████▏     | 16/38 [00:25<00:35,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  45%|████▍     | 17/38 [00:27<00:33,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  45%|████▍     | 17/38 [00:27<00:33,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  53%|█████▎    | 20/38 [00:28<00:25,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  53%|█████▎    | 20/38 [00:28<00:25,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  55%|█████▌    | 21/38 [00:30<00:24,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  55%|█████▌    | 21/38 [00:30<00:24,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  66%|██████▌   | 25/38 [00:32<00:16,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  66%|██████▌   | 25/38 [00:32<00:16,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  68%|██████▊   | 26/38 [00:33<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  71%|███████   | 27/38 [00:34<00:14,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.63it/s]\u001b[A\n",
      "Epoch 54:  82%|████████▏ | 31/38 [00:42<00:09,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.59it/s]\u001b[A\n",
      "Epoch 54:  84%|████████▍ | 32/38 [00:43<00:08,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.49it/s]\u001b[A\n",
      "Epoch 54:  87%|████████▋ | 33/38 [00:43<00:06,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.29it/s]\u001b[A\n",
      "Epoch 54:  89%|████████▉ | 34/38 [00:43<00:05,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 35/38 [00:46<00:03,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 54:  95%|█████████▍| 36/38 [00:46<00:02,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 54:  97%|█████████▋| 37/38 [00:47<00:01,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 54: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "Epoch 54: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 54: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 54:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 55:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:   3%|▎         | 1/38 [00:16<10:19, 16.75s/it, loss=1.1, v_num=33, train_acc1_step=66.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:   3%|▎         | 1/38 [00:16<10:20, 16.77s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:   5%|▌         | 2/38 [00:16<05:04,  8.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:   5%|▌         | 2/38 [00:16<05:04,  8.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:   8%|▊         | 3/38 [00:17<03:19,  5.69s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:   8%|▊         | 3/38 [00:17<03:19,  5.69s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  13%|█▎        | 5/38 [00:19<02:08,  3.90s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  13%|█▎        | 5/38 [00:19<02:08,  3.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  16%|█▌        | 6/38 [00:19<01:45,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  16%|█▌        | 6/38 [00:19<01:45,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  18%|█▊        | 7/38 [00:19<01:27,  2.84s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  18%|█▊        | 7/38 [00:19<01:27,  2.84s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  21%|██        | 8/38 [00:20<01:15,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  24%|██▎       | 9/38 [00:22<01:11,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  24%|██▎       | 9/38 [00:22<01:11,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  26%|██▋       | 10/38 [00:22<01:02,  2.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  26%|██▋       | 10/38 [00:22<01:02,  2.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  29%|██▉       | 11/38 [00:22<00:55,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  29%|██▉       | 11/38 [00:22<00:55,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  32%|███▏      | 12/38 [00:22<00:48,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  32%|███▏      | 12/38 [00:22<00:48,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  34%|███▍      | 13/38 [00:25<00:48,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  39%|███▉      | 15/38 [00:25<00:38,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  39%|███▉      | 15/38 [00:25<00:38,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  42%|████▏     | 16/38 [00:25<00:35,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  42%|████▏     | 16/38 [00:25<00:35,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  45%|████▍     | 17/38 [00:27<00:33,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  45%|████▍     | 17/38 [00:27<00:33,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  47%|████▋     | 18/38 [00:27<00:30,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  47%|████▋     | 18/38 [00:27<00:30,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  50%|█████     | 19/38 [00:27<00:27,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  50%|█████     | 19/38 [00:27<00:27,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  53%|█████▎    | 20/38 [00:28<00:25,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  53%|█████▎    | 20/38 [00:28<00:25,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  55%|█████▌    | 21/38 [00:29<00:24,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  55%|█████▌    | 21/38 [00:29<00:24,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  58%|█████▊    | 22/38 [00:30<00:21,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  58%|█████▊    | 22/38 [00:30<00:21,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  61%|██████    | 23/38 [00:30<00:19,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  61%|██████    | 23/38 [00:30<00:19,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  66%|██████▌   | 25/38 [00:32<00:17,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  66%|██████▌   | 25/38 [00:32<00:17,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  68%|██████▊   | 26/38 [00:32<00:15,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  68%|██████▊   | 26/38 [00:32<00:15,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  71%|███████   | 27/38 [00:33<00:13,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  71%|███████   | 27/38 [00:33<00:13,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.31it/s]\u001b[A\n",
      "Epoch 55:  82%|████████▏ | 31/38 [00:43<00:09,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.40it/s]\u001b[A\n",
      "Epoch 55:  84%|████████▍ | 32/38 [00:43<00:08,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.12it/s]\u001b[A\n",
      "Epoch 55:  87%|████████▋ | 33/38 [00:43<00:06,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.85it/s]\u001b[A\n",
      "Epoch 55:  89%|████████▉ | 34/38 [00:43<00:05,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 35/38 [00:46<00:03,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.41it/s]\u001b[A\n",
      "Epoch 55:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.57it/s]\u001b[A\n",
      "Epoch 55:  97%|█████████▋| 37/38 [00:47<00:01,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 55: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 55: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 55: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 55:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]         \n",
      "Epoch 56:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:   3%|▎         | 1/38 [00:16<10:22, 16.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:   3%|▎         | 1/38 [00:16<10:22, 16.84s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:   5%|▌         | 2/38 [00:16<05:05,  8.49s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:   5%|▌         | 2/38 [00:16<05:05,  8.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:   8%|▊         | 3/38 [00:17<03:19,  5.71s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:   8%|▊         | 3/38 [00:17<03:20,  5.72s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  11%|█         | 4/38 [00:17<02:27,  4.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  11%|█         | 4/38 [00:17<02:27,  4.33s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  13%|█▎        | 5/38 [00:19<02:10,  3.97s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  13%|█▎        | 5/38 [00:19<02:11,  3.97s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  16%|█▌        | 6/38 [00:20<01:46,  3.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  16%|█▌        | 6/38 [00:20<01:46,  3.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  34%|███▍      | 13/38 [00:26<00:50,  2.01s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  34%|███▍      | 13/38 [00:26<00:50,  2.01s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  68%|██████▊   | 26/38 [00:33<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  68%|██████▊   | 26/38 [00:33<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.80it/s]\u001b[A\n",
      "Epoch 56:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.36it/s]\u001b[A\n",
      "Epoch 56:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.86it/s]\u001b[A\n",
      "Epoch 56:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.55it/s]\u001b[A\n",
      "Epoch 56:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.42it/s]\u001b[A\n",
      "Epoch 56:  95%|█████████▍| 36/38 [00:47<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.52it/s]\u001b[A\n",
      "Epoch 56:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.71it/s]\u001b[A\n",
      "Epoch 56: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "Epoch 56: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.40]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 56: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 56:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]         \n",
      "Epoch 57:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:   3%|▎         | 1/38 [00:16<10:00, 16.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:   3%|▎         | 1/38 [00:16<10:00, 16.24s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:   5%|▌         | 2/38 [00:16<04:58,  8.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:   5%|▌         | 2/38 [00:16<04:58,  8.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:   8%|▊         | 3/38 [00:16<03:17,  5.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:   8%|▊         | 3/38 [00:16<03:17,  5.64s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  13%|█▎        | 5/38 [00:19<02:07,  3.86s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  18%|█▊        | 7/38 [00:19<01:26,  2.80s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  18%|█▊        | 7/38 [00:19<01:26,  2.81s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  21%|██        | 8/38 [00:19<01:14,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  21%|██        | 8/38 [00:19<01:14,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  24%|██▎       | 9/38 [00:22<01:11,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  24%|██▎       | 9/38 [00:22<01:11,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  26%|██▋       | 10/38 [00:22<01:03,  2.26s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  26%|██▋       | 10/38 [00:22<01:03,  2.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  29%|██▉       | 11/38 [00:22<00:55,  2.07s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  29%|██▉       | 11/38 [00:22<00:55,  2.07s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  32%|███▏      | 12/38 [00:22<00:49,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  32%|███▏      | 12/38 [00:22<00:49,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  34%|███▍      | 13/38 [00:25<00:48,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  37%|███▋      | 14/38 [00:26<00:44,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  45%|████▍     | 17/38 [00:27<00:34,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  55%|█████▌    | 21/38 [00:30<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  55%|█████▌    | 21/38 [00:30<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  66%|██████▌   | 25/38 [00:33<00:17,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.37it/s]\u001b[A\n",
      "Epoch 57:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.92it/s]\u001b[A\n",
      "Epoch 57:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.03it/s]\u001b[A\n",
      "Epoch 57:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.75it/s]\u001b[A\n",
      "Epoch 57:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.45it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 35/38 [00:47<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.45it/s]\u001b[A\n",
      "Epoch 57:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.51it/s]\u001b[A\n",
      "Epoch 57:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\u001b[A\n",
      "Epoch 57: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "Epoch 57: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.30]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 57: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 57:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 58:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:   3%|▎         | 1/38 [00:15<09:50, 15.96s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:   3%|▎         | 1/38 [00:15<09:51, 15.98s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:   5%|▌         | 2/38 [00:16<04:53,  8.14s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:   5%|▌         | 2/38 [00:16<04:53,  8.15s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:   8%|▊         | 3/38 [00:16<03:12,  5.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:   8%|▊         | 3/38 [00:16<03:12,  5.50s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  11%|█         | 4/38 [00:17<02:25,  4.28s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  11%|█         | 4/38 [00:17<02:25,  4.28s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  13%|█▎        | 5/38 [00:18<02:03,  3.74s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  13%|█▎        | 5/38 [00:18<02:03,  3.74s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  16%|█▌        | 6/38 [00:19<01:42,  3.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  16%|█▌        | 6/38 [00:19<01:42,  3.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  18%|█▊        | 7/38 [00:19<01:25,  2.77s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  18%|█▊        | 7/38 [00:19<01:26,  2.77s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  21%|██        | 8/38 [00:19<01:14,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  21%|██        | 8/38 [00:19<01:14,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  24%|██▎       | 9/38 [00:21<01:08,  2.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  24%|██▎       | 9/38 [00:21<01:08,  2.38s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  26%|██▋       | 10/38 [00:21<01:00,  2.15s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  26%|██▋       | 10/38 [00:21<01:00,  2.15s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  29%|██▉       | 11/38 [00:22<00:54,  2.02s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  29%|██▉       | 11/38 [00:22<00:54,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  34%|███▍      | 13/38 [00:24<00:47,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  34%|███▍      | 13/38 [00:24<00:47,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  37%|███▋      | 14/38 [00:24<00:42,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  37%|███▋      | 14/38 [00:24<00:42,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  39%|███▉      | 15/38 [00:24<00:37,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  39%|███▉      | 15/38 [00:24<00:37,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  45%|████▍     | 17/38 [00:27<00:34,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  50%|█████     | 19/38 [00:28<00:28,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  50%|█████     | 19/38 [00:28<00:28,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  76%|███████▋  | 29/38 [00:35<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  76%|███████▋  | 29/38 [00:36<00:11,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.79it/s]\u001b[A\n",
      "Epoch 58:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.55it/s]\u001b[A\n",
      "Epoch 58:  84%|████████▍ | 32/38 [00:43<00:08,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.82it/s]\u001b[A\n",
      "Epoch 58:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.51it/s]\u001b[A\n",
      "Epoch 58:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 35/38 [00:46<00:03,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "Epoch 58:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.50it/s]\u001b[A\n",
      "Epoch 58:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.69it/s]\u001b[A\n",
      "Epoch 58: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 58: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 58:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 59:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:   3%|▎         | 1/38 [00:16<10:18, 16.71s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:   3%|▎         | 1/38 [00:16<10:18, 16.72s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:   5%|▌         | 2/38 [00:16<05:03,  8.43s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:   5%|▌         | 2/38 [00:16<05:03,  8.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:   8%|▊         | 3/38 [00:17<03:18,  5.68s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:   8%|▊         | 3/38 [00:17<03:18,  5.68s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  11%|█         | 4/38 [00:17<02:26,  4.30s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  11%|█         | 4/38 [00:17<02:26,  4.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  13%|█▎        | 5/38 [00:19<02:09,  3.94s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  13%|█▎        | 5/38 [00:19<02:10,  3.94s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  16%|█▌        | 6/38 [00:19<01:45,  3.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  16%|█▌        | 6/38 [00:19<01:46,  3.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  18%|█▊        | 7/38 [00:20<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  18%|█▊        | 7/38 [00:20<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  24%|██▎       | 9/38 [00:22<01:10,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  24%|██▎       | 9/38 [00:22<01:11,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  26%|██▋       | 10/38 [00:22<01:03,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  26%|██▋       | 10/38 [00:22<01:03,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  32%|███▏      | 12/38 [00:22<00:49,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  32%|███▏      | 12/38 [00:22<00:49,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  39%|███▉      | 15/38 [00:26<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  39%|███▉      | 15/38 [00:26<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  42%|████▏     | 16/38 [00:26<00:35,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  42%|████▏     | 16/38 [00:26<00:35,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  47%|████▋     | 18/38 [00:29<00:32,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  50%|█████     | 19/38 [00:29<00:29,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  53%|█████▎    | 20/38 [00:29<00:26,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  63%|██████▎   | 24/38 [00:32<00:18,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  63%|██████▎   | 24/38 [00:32<00:18,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  68%|██████▊   | 26/38 [00:35<00:16,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  68%|██████▊   | 26/38 [00:35<00:16,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  71%|███████   | 27/38 [00:35<00:14,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  71%|███████   | 27/38 [00:35<00:14,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  74%|███████▎  | 28/38 [00:35<00:12,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.96it/s]\u001b[A\n",
      "Epoch 59:  82%|████████▏ | 31/38 [00:44<00:10,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.52it/s]\u001b[A\n",
      "Epoch 59:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.19it/s]\u001b[A\n",
      "Epoch 59:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.94it/s]\u001b[A\n",
      "Epoch 59:  89%|████████▉ | 34/38 [00:45<00:05,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.49it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 35/38 [00:47<00:04,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.46it/s]\u001b[A\n",
      "Epoch 59:  95%|█████████▍| 36/38 [00:48<00:02,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 59:  97%|█████████▋| 37/38 [00:48<00:01,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 59: 100%|██████████| 38/38 [00:48<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 59: 100%|██████████| 38/38 [00:48<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 59: 100%|██████████| 38/38 [00:48<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 59:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]         \n",
      "Epoch 60:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:   3%|▎         | 1/38 [00:16<10:13, 16.57s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:   3%|▎         | 1/38 [00:16<10:13, 16.58s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:   5%|▌         | 2/38 [00:16<05:01,  8.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:   5%|▌         | 2/38 [00:16<05:01,  8.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:   8%|▊         | 3/38 [00:16<03:17,  5.63s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:   8%|▊         | 3/38 [00:16<03:17,  5.63s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  11%|█         | 4/38 [00:17<02:24,  4.26s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  13%|█▎        | 5/38 [00:18<02:05,  3.79s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  13%|█▎        | 5/38 [00:18<02:05,  3.80s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  16%|█▌        | 6/38 [00:19<01:46,  3.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  16%|█▌        | 6/38 [00:19<01:46,  3.33s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  24%|██▎       | 9/38 [00:21<01:09,  2.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  24%|██▎       | 9/38 [00:21<01:09,  2.41s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  26%|██▋       | 10/38 [00:23<01:04,  2.32s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  26%|██▋       | 10/38 [00:23<01:04,  2.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  29%|██▉       | 11/38 [00:23<00:57,  2.12s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  32%|███▏      | 12/38 [00:23<00:50,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  32%|███▏      | 12/38 [00:23<00:50,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  34%|███▍      | 13/38 [00:24<00:46,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  34%|███▍      | 13/38 [00:24<00:46,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  50%|█████     | 19/38 [00:29<00:29,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  55%|█████▌    | 21/38 [00:30<00:24,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  55%|█████▌    | 21/38 [00:30<00:24,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  58%|█████▊    | 22/38 [00:32<00:23,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  58%|█████▊    | 22/38 [00:32<00:23,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  63%|██████▎   | 24/38 [00:32<00:18,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  63%|██████▎   | 24/38 [00:32<00:18,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  68%|██████▊   | 26/38 [00:34<00:16,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  68%|██████▊   | 26/38 [00:34<00:16,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  79%|███████▉  | 30/38 [00:37<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60:  79%|███████▉  | 30/38 [00:37<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.49it/s]\u001b[A\n",
      "Epoch 60:  82%|████████▏ | 31/38 [00:44<00:10,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.53it/s]\u001b[A\n",
      "Epoch 60:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.38it/s]\u001b[A\n",
      "Epoch 60:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.14it/s]\u001b[A\n",
      "Epoch 60:  89%|████████▉ | 34/38 [00:45<00:05,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.48it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.46it/s]\u001b[A\n",
      "Epoch 60:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 60:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 60: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "Epoch 60: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 60: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 60:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]         \n",
      "Epoch 61:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:   3%|▎         | 1/38 [00:16<10:08, 16.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:   3%|▎         | 1/38 [00:16<10:08, 16.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:   5%|▌         | 2/38 [00:16<05:00,  8.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:   5%|▌         | 2/38 [00:16<05:00,  8.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:   8%|▊         | 3/38 [00:16<03:16,  5.61s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:   8%|▊         | 3/38 [00:16<03:16,  5.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  11%|█         | 4/38 [00:16<02:24,  4.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  11%|█         | 4/38 [00:17<02:24,  4.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  13%|█▎        | 5/38 [00:19<02:08,  3.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  13%|█▎        | 5/38 [00:19<02:08,  3.89s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  18%|█▊        | 7/38 [00:20<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  18%|█▊        | 7/38 [00:20<01:28,  2.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  24%|██▎       | 9/38 [00:22<01:11,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  24%|██▎       | 9/38 [00:22<01:11,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  34%|███▍      | 13/38 [00:24<00:47,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  34%|███▍      | 13/38 [00:24<00:47,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  39%|███▉      | 15/38 [00:25<00:39,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  45%|████▍     | 17/38 [00:27<00:34,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  45%|████▍     | 17/38 [00:27<00:34,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.56it/s]\u001b[A\n",
      "Epoch 61:  82%|████████▏ | 31/38 [00:43<00:09,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.66it/s]\u001b[A\n",
      "Epoch 61:  84%|████████▍ | 32/38 [00:43<00:08,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.13it/s]\u001b[A\n",
      "Epoch 61:  87%|████████▋ | 33/38 [00:43<00:06,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.86it/s]\u001b[A\n",
      "Epoch 61:  89%|████████▉ | 34/38 [00:43<00:05,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.38it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 35/38 [00:46<00:03,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 61:  95%|█████████▍| 36/38 [00:46<00:02,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.55it/s]\u001b[A\n",
      "Epoch 61:  97%|█████████▋| 37/38 [00:47<00:01,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\u001b[A\n",
      "Epoch 61: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=25.00, val_acc1_epoch=33.30, train_acc1_epoch=33.60]\n",
      "Epoch 61: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=33.60]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 61: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 61:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]         \n",
      "Epoch 62:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:   3%|▎         | 1/38 [00:16<10:24, 16.89s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:   3%|▎         | 1/38 [00:16<10:25, 16.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:   5%|▌         | 2/38 [00:17<05:06,  8.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:   5%|▌         | 2/38 [00:17<05:06,  8.53s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:   8%|▊         | 3/38 [00:17<03:20,  5.73s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:   8%|▊         | 3/38 [00:17<03:20,  5.74s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  11%|█         | 4/38 [00:17<02:27,  4.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  11%|█         | 4/38 [00:17<02:27,  4.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  13%|█▎        | 5/38 [00:19<02:08,  3.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  13%|█▎        | 5/38 [00:19<02:08,  3.90s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  16%|█▌        | 6/38 [00:19<01:44,  3.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  21%|██        | 8/38 [00:20<01:15,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  24%|██▎       | 9/38 [00:22<01:11,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  24%|██▎       | 9/38 [00:22<01:11,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  26%|██▋       | 10/38 [00:22<01:02,  2.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  26%|██▋       | 10/38 [00:22<01:02,  2.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  29%|██▉       | 11/38 [00:22<00:55,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  29%|██▉       | 11/38 [00:22<00:55,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  32%|███▏      | 12/38 [00:22<00:49,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  32%|███▏      | 12/38 [00:22<00:49,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  39%|███▉      | 15/38 [00:26<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  39%|███▉      | 15/38 [00:26<00:39,  1.74s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  42%|████▏     | 16/38 [00:26<00:36,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  42%|████▏     | 16/38 [00:26<00:36,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.35it/s]\u001b[A\n",
      "Epoch 62:  82%|████████▏ | 31/38 [00:44<00:09,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.48it/s]\u001b[A\n",
      "Epoch 62:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.90it/s]\u001b[A\n",
      "Epoch 62:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.61it/s]\u001b[A\n",
      "Epoch 62:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.43it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.45it/s]\u001b[A\n",
      "Epoch 62:  95%|█████████▍| 36/38 [00:47<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.52it/s]\u001b[A\n",
      "Epoch 62:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.71it/s]\u001b[A\n",
      "Epoch 62: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "Epoch 62: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=32.60]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 62: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 62:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]         \n",
      "Epoch 63:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:   3%|▎         | 1/38 [00:16<10:28, 17.00s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:   3%|▎         | 1/38 [00:17<10:29, 17.01s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:   5%|▌         | 2/38 [00:17<05:08,  8.58s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:   5%|▌         | 2/38 [00:17<05:08,  8.58s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:   8%|▊         | 3/38 [00:17<03:21,  5.77s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:   8%|▊         | 3/38 [00:17<03:22,  5.77s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  11%|█         | 4/38 [00:17<02:28,  4.37s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  11%|█         | 4/38 [00:17<02:28,  4.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  13%|█▎        | 5/38 [00:20<02:12,  4.01s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  13%|█▎        | 5/38 [00:20<02:12,  4.01s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  16%|█▌        | 6/38 [00:20<01:47,  3.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  16%|█▌        | 6/38 [00:20<01:47,  3.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  18%|█▊        | 7/38 [00:20<01:30,  2.91s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  18%|█▊        | 7/38 [00:20<01:30,  2.91s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  21%|██        | 8/38 [00:20<01:16,  2.56s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  21%|██        | 8/38 [00:20<01:16,  2.56s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  32%|███▏      | 12/38 [00:23<00:50,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  34%|███▍      | 13/38 [00:25<00:49,  1.99s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  34%|███▍      | 13/38 [00:25<00:49,  1.99s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  37%|███▋      | 14/38 [00:26<00:44,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  37%|███▋      | 14/38 [00:26<00:44,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  39%|███▉      | 15/38 [00:26<00:40,  1.74s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  47%|████▋     | 18/38 [00:29<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  47%|████▋     | 18/38 [00:29<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.63it/s]\u001b[A\n",
      "Epoch 63:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.58it/s]\u001b[A\n",
      "Epoch 63:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.43it/s]\u001b[A\n",
      "Epoch 63:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.20it/s]\u001b[A\n",
      "Epoch 63:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.51it/s]\u001b[A\n",
      "Epoch 63:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.59it/s]\u001b[A\n",
      "Epoch 63:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 63: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "Epoch 63: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=31.50]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 63: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 63:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 64:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:   3%|▎         | 1/38 [00:16<09:57, 16.14s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:   3%|▎         | 1/38 [00:16<09:57, 16.15s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:   5%|▌         | 2/38 [00:16<04:53,  8.15s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:   5%|▌         | 2/38 [00:16<04:53,  8.15s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:   8%|▊         | 3/38 [00:16<03:13,  5.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:   8%|▊         | 3/38 [00:16<03:13,  5.53s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  11%|█         | 4/38 [00:16<02:22,  4.18s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  11%|█         | 4/38 [00:16<02:22,  4.19s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  13%|█▎        | 5/38 [00:18<02:02,  3.70s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  13%|█▎        | 5/38 [00:18<02:02,  3.71s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  16%|█▌        | 6/38 [00:19<01:42,  3.20s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  16%|█▌        | 6/38 [00:19<01:42,  3.20s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  18%|█▊        | 7/38 [00:19<01:28,  2.84s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  18%|█▊        | 7/38 [00:19<01:28,  2.84s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  21%|██        | 8/38 [00:20<01:15,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  21%|██        | 8/38 [00:20<01:15,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  24%|██▎       | 9/38 [00:21<01:09,  2.41s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  24%|██▎       | 9/38 [00:21<01:09,  2.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  26%|██▋       | 10/38 [00:22<01:03,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  26%|██▋       | 10/38 [00:22<01:03,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  32%|███▏      | 12/38 [00:22<00:49,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  32%|███▏      | 12/38 [00:22<00:49,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  34%|███▍      | 13/38 [00:24<00:47,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  34%|███▍      | 13/38 [00:24<00:47,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  45%|████▍     | 17/38 [00:27<00:33,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  45%|████▍     | 17/38 [00:27<00:33,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  55%|█████▌    | 21/38 [00:30<00:24,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  55%|█████▌    | 21/38 [00:30<00:24,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  66%|██████▌   | 25/38 [00:32<00:16,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  66%|██████▌   | 25/38 [00:32<00:16,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  71%|███████   | 27/38 [00:33<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  71%|███████   | 27/38 [00:33<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  76%|███████▋  | 29/38 [00:35<00:10,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  76%|███████▋  | 29/38 [00:35<00:10,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  79%|███████▉  | 30/38 [00:35<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.68it/s]\u001b[A\n",
      "Epoch 64:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.47it/s]\u001b[A\n",
      "Epoch 64:  84%|████████▍ | 32/38 [00:43<00:08,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.17it/s]\u001b[A\n",
      "Epoch 64:  87%|████████▋ | 33/38 [00:43<00:06,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.91it/s]\u001b[A\n",
      "Epoch 64:  89%|████████▉ | 34/38 [00:44<00:05,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.45it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 35/38 [00:46<00:03,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 64:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.52it/s]\u001b[A\n",
      "Epoch 64:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.71it/s]\u001b[A\n",
      "Epoch 64: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 64: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 64:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 65:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:   3%|▎         | 1/38 [00:16<09:55, 16.09s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:   3%|▎         | 1/38 [00:16<09:55, 16.10s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:   5%|▌         | 2/38 [00:16<04:52,  8.12s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:   5%|▌         | 2/38 [00:16<04:52,  8.13s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:   8%|▊         | 3/38 [00:16<03:11,  5.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:   8%|▊         | 3/38 [00:16<03:11,  5.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  11%|█         | 4/38 [00:16<02:21,  4.17s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  11%|█         | 4/38 [00:16<02:22,  4.18s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  13%|█▎        | 5/38 [00:18<02:04,  3.78s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  13%|█▎        | 5/38 [00:18<02:04,  3.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  16%|█▌        | 6/38 [00:19<01:41,  3.18s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  16%|█▌        | 6/38 [00:19<01:41,  3.18s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  18%|█▊        | 7/38 [00:19<01:27,  2.82s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  18%|█▊        | 7/38 [00:19<01:27,  2.82s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  21%|██        | 8/38 [00:19<01:14,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  21%|██        | 8/38 [00:19<01:14,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  26%|██▋       | 10/38 [00:21<01:00,  2.16s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  26%|██▋       | 10/38 [00:21<01:00,  2.17s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  29%|██▉       | 11/38 [00:22<00:55,  2.05s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  29%|██▉       | 11/38 [00:22<00:55,  2.05s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  32%|███▏      | 12/38 [00:22<00:49,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  32%|███▏      | 12/38 [00:22<00:49,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  34%|███▍      | 13/38 [00:24<00:46,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  34%|███▍      | 13/38 [00:24<00:46,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  37%|███▋      | 14/38 [00:24<00:42,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  37%|███▋      | 14/38 [00:24<00:42,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.09, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.09, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20] \n",
      "Epoch 65:  45%|████▍     | 17/38 [00:26<00:33,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  45%|████▍     | 17/38 [00:26<00:33,  1.58s/it, loss=1.09, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  47%|████▋     | 18/38 [00:26<00:29,  1.50s/it, loss=1.09, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  47%|████▋     | 18/38 [00:26<00:29,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20] \n",
      "Epoch 65:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  55%|█████▌    | 21/38 [00:29<00:23,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  55%|█████▌    | 21/38 [00:29<00:23,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  58%|█████▊    | 22/38 [00:29<00:21,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  58%|█████▊    | 22/38 [00:29<00:21,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  66%|██████▌   | 25/38 [00:32<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  66%|██████▌   | 25/38 [00:32<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  68%|██████▊   | 26/38 [00:33<00:15,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  68%|██████▊   | 26/38 [00:33<00:15,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  71%|███████   | 27/38 [00:35<00:14,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.46it/s]\u001b[A\n",
      "Epoch 65:  82%|████████▏ | 31/38 [00:43<00:09,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.57it/s]\u001b[A\n",
      "Epoch 65:  84%|████████▍ | 32/38 [00:43<00:08,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.21it/s]\u001b[A\n",
      "Epoch 65:  87%|████████▋ | 33/38 [00:43<00:06,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.94it/s]\u001b[A\n",
      "Epoch 65:  89%|████████▉ | 34/38 [00:43<00:05,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 35/38 [00:46<00:03,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 65:  95%|█████████▍| 36/38 [00:46<00:02,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.57it/s]\u001b[A\n",
      "Epoch 65:  97%|█████████▋| 37/38 [00:47<00:01,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 65: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 65: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 65:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 66:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:   3%|▎         | 1/38 [00:17<10:44, 17.41s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:   3%|▎         | 1/38 [00:17<10:44, 17.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:   5%|▌         | 2/38 [00:17<05:16,  8.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:   5%|▌         | 2/38 [00:17<05:16,  8.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:   8%|▊         | 3/38 [00:17<03:26,  5.91s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:   8%|▊         | 3/38 [00:17<03:26,  5.91s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  11%|█         | 4/38 [00:17<02:31,  4.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  11%|█         | 4/38 [00:17<02:32,  4.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  13%|█▎        | 5/38 [00:20<02:15,  4.10s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  13%|█▎        | 5/38 [00:20<02:15,  4.10s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  16%|█▌        | 6/38 [00:20<01:50,  3.44s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  16%|█▌        | 6/38 [00:20<01:50,  3.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  18%|█▊        | 7/38 [00:20<01:32,  2.97s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  18%|█▊        | 7/38 [00:20<01:32,  2.98s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  21%|██        | 8/38 [00:20<01:18,  2.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  21%|██        | 8/38 [00:20<01:18,  2.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  24%|██▎       | 9/38 [00:23<01:15,  2.59s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  24%|██▎       | 9/38 [00:23<01:15,  2.59s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  26%|██▋       | 10/38 [00:23<01:05,  2.35s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  26%|██▋       | 10/38 [00:23<01:05,  2.35s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  29%|██▉       | 11/38 [00:23<00:57,  2.15s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  29%|██▉       | 11/38 [00:23<00:58,  2.15s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  34%|███▍      | 13/38 [00:24<00:47,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  34%|███▍      | 13/38 [00:24<00:48,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  37%|███▋      | 14/38 [00:25<00:43,  1.82s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  37%|███▋      | 14/38 [00:25<00:43,  1.82s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  45%|████▍     | 17/38 [00:27<00:33,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  45%|████▍     | 17/38 [00:27<00:33,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  47%|████▋     | 18/38 [00:28<00:31,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  47%|████▋     | 18/38 [00:28<00:31,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  55%|█████▌    | 21/38 [00:29<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  55%|█████▌    | 21/38 [00:29<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  63%|██████▎   | 24/38 [00:32<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  63%|██████▎   | 24/38 [00:32<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:  79%|███████▉  | 30/38 [00:36<00:09,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.48it/s]\u001b[A\n",
      "Epoch 66:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.84it/s]\u001b[A\n",
      "Epoch 66:  84%|████████▍ | 32/38 [00:43<00:08,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.64it/s]\u001b[A\n",
      "Epoch 66:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.45it/s]\u001b[A\n",
      "Epoch 66:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.38it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 66:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.55it/s]\u001b[A\n",
      "Epoch 66:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\u001b[A\n",
      "Epoch 66: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 66: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 66:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 67:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:   3%|▎         | 1/38 [00:16<10:20, 16.77s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:   3%|▎         | 1/38 [00:16<10:21, 16.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:   5%|▌         | 2/38 [00:16<05:05,  8.47s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:   5%|▌         | 2/38 [00:16<05:05,  8.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:   8%|▊         | 3/38 [00:17<03:19,  5.70s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:   8%|▊         | 3/38 [00:17<03:19,  5.70s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  11%|█         | 4/38 [00:17<02:26,  4.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  13%|█▎        | 5/38 [00:20<02:13,  4.05s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  13%|█▎        | 5/38 [00:20<02:13,  4.05s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  16%|█▌        | 6/38 [00:20<01:48,  3.40s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  16%|█▌        | 6/38 [00:20<01:48,  3.40s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  18%|█▊        | 7/38 [00:20<01:30,  2.93s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  18%|█▊        | 7/38 [00:20<01:31,  2.94s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  21%|██        | 8/38 [00:20<01:17,  2.59s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  21%|██        | 8/38 [00:20<01:17,  2.59s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  24%|██▎       | 9/38 [00:22<01:12,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  34%|███▍      | 13/38 [00:26<00:50,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  34%|███▍      | 13/38 [00:26<00:50,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  45%|████▍     | 17/38 [00:28<00:35,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  45%|████▍     | 17/38 [00:28<00:35,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  47%|████▋     | 18/38 [00:28<00:31,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  71%|███████   | 27/38 [00:33<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  71%|███████   | 27/38 [00:33<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.45it/s]\u001b[A\n",
      "Epoch 67:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.47it/s]\u001b[A\n",
      "Epoch 67:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.36it/s]\u001b[A\n",
      "Epoch 67:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.14it/s]\u001b[A\n",
      "Epoch 67:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.45it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.42it/s]\u001b[A\n",
      "Epoch 67:  95%|█████████▍| 36/38 [00:47<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.53it/s]\u001b[A\n",
      "Epoch 67:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\u001b[A\n",
      "Epoch 67: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 67: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 67:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 68:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:   3%|▎         | 1/38 [00:17<10:34, 17.14s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:   3%|▎         | 1/38 [00:17<10:34, 17.15s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:   5%|▌         | 2/38 [00:17<05:11,  8.65s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:   5%|▌         | 2/38 [00:17<05:11,  8.66s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:   8%|▊         | 3/38 [00:17<03:23,  5.82s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:   8%|▊         | 3/38 [00:17<03:23,  5.82s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  11%|█         | 4/38 [00:17<02:29,  4.41s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  13%|█▎        | 5/38 [00:19<02:09,  3.93s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  13%|█▎        | 5/38 [00:19<02:09,  3.93s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  16%|█▌        | 6/38 [00:20<01:46,  3.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  16%|█▌        | 6/38 [00:20<01:47,  3.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  24%|██▎       | 9/38 [00:22<01:10,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  24%|██▎       | 9/38 [00:22<01:10,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  26%|██▋       | 10/38 [00:23<01:04,  2.30s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  26%|██▋       | 10/38 [00:23<01:04,  2.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  29%|██▉       | 11/38 [00:23<00:56,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  29%|██▉       | 11/38 [00:23<00:56,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  32%|███▏      | 12/38 [00:23<00:50,  1.95s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  37%|███▋      | 14/38 [00:26<00:44,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  37%|███▋      | 14/38 [00:26<00:44,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=0.000, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  45%|████▍     | 17/38 [00:28<00:35,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  55%|█████▌    | 21/38 [00:32<00:26,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  74%|███████▎  | 28/38 [00:35<00:12,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:  79%|███████▉  | 30/38 [00:37<00:10,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.35it/s]\u001b[A\n",
      "Epoch 68:  82%|████████▏ | 31/38 [00:45<00:10,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.58it/s]\u001b[A\n",
      "Epoch 68:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.51it/s]\u001b[A\n",
      "Epoch 68:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.29it/s]\u001b[A\n",
      "Epoch 68:  89%|████████▉ | 34/38 [00:45<00:05,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 35/38 [00:48<00:04,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 68:  95%|█████████▍| 36/38 [00:48<00:02,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 68:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 68: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 68: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 68:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 69:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:   3%|▎         | 1/38 [00:16<09:58, 16.17s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:   3%|▎         | 1/38 [00:16<09:58, 16.18s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:   5%|▌         | 2/38 [00:16<04:58,  8.28s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:   8%|▊         | 3/38 [00:16<03:15,  5.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  11%|█         | 4/38 [00:16<02:23,  4.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  11%|█         | 4/38 [00:16<02:23,  4.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  13%|█▎        | 5/38 [00:19<02:09,  3.93s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  13%|█▎        | 5/38 [00:19<02:09,  3.93s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  16%|█▌        | 6/38 [00:20<01:46,  3.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  16%|█▌        | 6/38 [00:20<01:46,  3.34s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  24%|██▎       | 9/38 [00:22<01:13,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  24%|██▎       | 9/38 [00:22<01:14,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  26%|██▋       | 10/38 [00:23<01:06,  2.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  26%|██▋       | 10/38 [00:23<01:06,  2.36s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  29%|██▉       | 11/38 [00:23<00:58,  2.16s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  29%|██▉       | 11/38 [00:23<00:58,  2.16s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  32%|███▏      | 12/38 [00:23<00:51,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  32%|███▏      | 12/38 [00:23<00:51,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  47%|████▋     | 18/38 [00:29<00:32,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.96it/s]\u001b[A\n",
      "Epoch 69:  82%|████████▏ | 31/38 [00:44<00:09,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.43it/s]\u001b[A\n",
      "Epoch 69:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.22it/s]\u001b[A\n",
      "Epoch 69:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.96it/s]\u001b[A\n",
      "Epoch 69:  89%|████████▉ | 34/38 [00:45<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.43it/s]\u001b[A\n",
      "Epoch 69:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.55it/s]\u001b[A\n",
      "Epoch 69:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\u001b[A\n",
      "Epoch 69: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 69: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 69:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 70:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:   3%|▎         | 1/38 [00:16<10:08, 16.45s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:   3%|▎         | 1/38 [00:16<10:09, 16.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:   5%|▌         | 2/38 [00:16<04:59,  8.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:   5%|▌         | 2/38 [00:16<04:59,  8.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:   8%|▊         | 3/38 [00:16<03:15,  5.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:   8%|▊         | 3/38 [00:16<03:15,  5.59s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  11%|█         | 4/38 [00:16<02:23,  4.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  11%|█         | 4/38 [00:16<02:23,  4.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  13%|█▎        | 5/38 [00:19<02:06,  3.83s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  13%|█▎        | 5/38 [00:19<02:06,  3.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  16%|█▌        | 6/38 [00:19<01:42,  3.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  16%|█▌        | 6/38 [00:19<01:42,  3.22s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  24%|██▎       | 9/38 [00:21<01:09,  2.40s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  24%|██▎       | 9/38 [00:21<01:09,  2.40s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  26%|██▋       | 10/38 [00:21<01:00,  2.17s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  26%|██▋       | 10/38 [00:21<01:00,  2.18s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  29%|██▉       | 11/38 [00:23<00:56,  2.10s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  29%|██▉       | 11/38 [00:23<00:56,  2.11s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  32%|███▏      | 12/38 [00:23<00:50,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  32%|███▏      | 12/38 [00:23<00:50,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  34%|███▍      | 13/38 [00:23<00:46,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  34%|███▍      | 13/38 [00:23<00:46,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  37%|███▋      | 14/38 [00:24<00:41,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  37%|███▋      | 14/38 [00:24<00:41,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  45%|████▍     | 17/38 [00:27<00:33,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  45%|████▍     | 17/38 [00:27<00:33,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  50%|█████     | 19/38 [00:30<00:30,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  50%|█████     | 19/38 [00:30<00:30,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  53%|█████▎    | 20/38 [00:30<00:27,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  55%|█████▌    | 21/38 [00:30<00:24,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  61%|██████    | 23/38 [00:32<00:21,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  66%|██████▌   | 25/38 [00:32<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  66%|██████▌   | 25/38 [00:32<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  68%|██████▊   | 26/38 [00:33<00:15,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  68%|██████▊   | 26/38 [00:33<00:15,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  71%|███████   | 27/38 [00:36<00:14,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  71%|███████   | 27/38 [00:36<00:14,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  74%|███████▎  | 28/38 [00:36<00:13,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  74%|███████▎  | 28/38 [00:36<00:13,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.90it/s]\u001b[A\n",
      "Epoch 70:  82%|████████▏ | 31/38 [00:44<00:09,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.58it/s]\u001b[A\n",
      "Epoch 70:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.06it/s]\u001b[A\n",
      "Epoch 70:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.79it/s]\u001b[A\n",
      "Epoch 70:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.40it/s]\u001b[A\n",
      "Epoch 70:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.54it/s]\u001b[A\n",
      "Epoch 70:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\u001b[A\n",
      "Epoch 70: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 70: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 70: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 70:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]         \n",
      "Epoch 71:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:   3%|▎         | 1/38 [00:16<10:07, 16.42s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:   3%|▎         | 1/38 [00:16<10:07, 16.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  11%|█         | 4/38 [00:16<02:23,  4.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  11%|█         | 4/38 [00:16<02:23,  4.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  13%|█▎        | 5/38 [00:19<02:10,  3.94s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  13%|█▎        | 5/38 [00:19<02:10,  3.94s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  16%|█▌        | 6/38 [00:19<01:45,  3.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  16%|█▌        | 6/38 [00:19<01:45,  3.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  18%|█▊        | 7/38 [00:20<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  18%|█▊        | 7/38 [00:20<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  24%|██▎       | 9/38 [00:22<01:12,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  24%|██▎       | 9/38 [00:22<01:12,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  26%|██▋       | 10/38 [00:22<01:03,  2.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  26%|██▋       | 10/38 [00:22<01:03,  2.26s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  50%|█████     | 19/38 [00:28<00:28,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  50%|█████     | 19/38 [00:28<00:28,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  58%|█████▊    | 22/38 [00:31<00:23,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  66%|██████▌   | 25/38 [00:34<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.49it/s]\u001b[A\n",
      "Epoch 71:  82%|████████▏ | 31/38 [00:45<00:10,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.53it/s]\u001b[A\n",
      "Epoch 71:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.45it/s]\u001b[A\n",
      "Epoch 71:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.26it/s]\u001b[A\n",
      "Epoch 71:  89%|████████▉ | 34/38 [00:45<00:05,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 35/38 [00:48<00:04,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 71:  95%|█████████▍| 36/38 [00:48<00:02,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 71:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\u001b[A\n",
      "Epoch 71: 100%|██████████| 38/38 [00:49<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "Epoch 71: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.90]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 71: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 71:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]         \n",
      "Epoch 72:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:   3%|▎         | 1/38 [00:16<10:21, 16.79s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:   3%|▎         | 1/38 [00:16<10:21, 16.80s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:   5%|▌         | 2/38 [00:16<05:05,  8.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:   5%|▌         | 2/38 [00:16<05:05,  8.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:   8%|▊         | 3/38 [00:17<03:19,  5.70s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:   8%|▊         | 3/38 [00:17<03:19,  5.71s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  11%|█         | 4/38 [00:17<02:26,  4.32s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  13%|█▎        | 5/38 [00:19<02:11,  3.98s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  13%|█▎        | 5/38 [00:19<02:11,  3.98s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  16%|█▌        | 6/38 [00:20<01:47,  3.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  16%|█▌        | 6/38 [00:20<01:47,  3.35s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  29%|██▉       | 11/38 [00:23<00:57,  2.13s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  29%|██▉       | 11/38 [00:23<00:57,  2.13s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  32%|███▏      | 12/38 [00:23<00:51,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  32%|███▏      | 12/38 [00:23<00:51,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  34%|███▍      | 13/38 [00:26<00:50,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  34%|███▍      | 13/38 [00:26<00:50,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  45%|████▍     | 17/38 [00:28<00:35,  1.69s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  45%|████▍     | 17/38 [00:28<00:35,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  47%|████▋     | 18/38 [00:28<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  55%|█████▌    | 21/38 [00:31<00:25,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  74%|███████▎  | 28/38 [00:34<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  76%|███████▋  | 29/38 [00:36<00:11,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.44it/s]\u001b[A\n",
      "Epoch 72:  82%|████████▏ | 31/38 [00:44<00:10,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.63it/s]\u001b[A\n",
      "Epoch 72:  84%|████████▍ | 32/38 [00:44<00:08,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.04it/s]\u001b[A\n",
      "Epoch 72:  87%|████████▋ | 33/38 [00:45<00:06,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.76it/s]\u001b[A\n",
      "Epoch 72:  89%|████████▉ | 34/38 [00:45<00:05,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.47it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.42it/s]\u001b[A\n",
      "Epoch 72:  95%|█████████▍| 36/38 [00:48<00:02,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.54it/s]\u001b[A\n",
      "Epoch 72:  97%|█████████▋| 37/38 [00:48<00:01,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\u001b[A\n",
      "Epoch 72: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "Epoch 72: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=30.30]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 72: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 72:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 73:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:   3%|▎         | 1/38 [00:16<10:07, 16.42s/it, loss=1.1, v_num=33, train_acc1_step=58.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:   3%|▎         | 1/38 [00:16<10:07, 16.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  11%|█         | 4/38 [00:16<02:23,  4.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  11%|█         | 4/38 [00:16<02:23,  4.22s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  13%|█▎        | 5/38 [00:18<02:01,  3.68s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  13%|█▎        | 5/38 [00:18<02:01,  3.68s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  16%|█▌        | 6/38 [00:19<01:42,  3.21s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  16%|█▌        | 6/38 [00:19<01:42,  3.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  18%|█▊        | 7/38 [00:20<01:30,  2.92s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  18%|█▊        | 7/38 [00:20<01:30,  2.92s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  21%|██        | 8/38 [00:20<01:17,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  21%|██        | 8/38 [00:20<01:17,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  24%|██▎       | 9/38 [00:21<01:09,  2.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  24%|██▎       | 9/38 [00:21<01:09,  2.40s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  26%|██▋       | 10/38 [00:21<01:00,  2.18s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  26%|██▋       | 10/38 [00:21<01:00,  2.18s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  29%|██▉       | 11/38 [00:23<00:58,  2.18s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  29%|██▉       | 11/38 [00:23<00:58,  2.18s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  32%|███▏      | 12/38 [00:24<00:52,  2.01s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  32%|███▏      | 12/38 [00:24<00:52,  2.01s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  34%|███▍      | 13/38 [00:24<00:46,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  34%|███▍      | 13/38 [00:24<00:47,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  37%|███▋      | 14/38 [00:24<00:42,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  37%|███▋      | 14/38 [00:24<00:42,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  39%|███▉      | 15/38 [00:27<00:41,  1.82s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  39%|███▉      | 15/38 [00:27<00:41,  1.82s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  42%|████▏     | 16/38 [00:27<00:37,  1.71s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  42%|████▏     | 16/38 [00:27<00:37,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  50%|█████     | 19/38 [00:30<00:30,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  50%|█████     | 19/38 [00:30<00:30,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  53%|█████▎    | 20/38 [00:30<00:27,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  53%|█████▎    | 20/38 [00:30<00:27,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  55%|█████▌    | 21/38 [00:30<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  61%|██████    | 23/38 [00:33<00:22,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  61%|██████    | 23/38 [00:33<00:22,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  63%|██████▎   | 24/38 [00:34<00:19,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  63%|██████▎   | 24/38 [00:34<00:19,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  71%|███████   | 27/38 [00:36<00:14,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  74%|███████▎  | 28/38 [00:36<00:12,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.73it/s]\u001b[A\n",
      "Epoch 73:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.55it/s]\u001b[A\n",
      "Epoch 73:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.47it/s]\u001b[A\n",
      "Epoch 73:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.23it/s]\u001b[A\n",
      "Epoch 73:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.49it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 73:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.57it/s]\u001b[A\n",
      "Epoch 73:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 73: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 73: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 73:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 74:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:   3%|▎         | 1/38 [00:16<09:55, 16.10s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:   3%|▎         | 1/38 [00:16<09:56, 16.11s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:   5%|▌         | 2/38 [00:16<04:53,  8.15s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:   5%|▌         | 2/38 [00:16<04:53,  8.15s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:   8%|▊         | 3/38 [00:16<03:11,  5.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:   8%|▊         | 3/38 [00:16<03:12,  5.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  11%|█         | 4/38 [00:16<02:21,  4.15s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  11%|█         | 4/38 [00:16<02:21,  4.16s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  16%|█▌        | 6/38 [00:19<01:44,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  16%|█▌        | 6/38 [00:19<01:44,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  18%|█▊        | 7/38 [00:19<01:27,  2.81s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  18%|█▊        | 7/38 [00:19<01:27,  2.81s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  21%|██        | 8/38 [00:19<01:14,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  21%|██        | 8/38 [00:19<01:14,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  24%|██▎       | 9/38 [00:21<01:10,  2.43s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  24%|██▎       | 9/38 [00:21<01:10,  2.43s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  29%|██▉       | 11/38 [00:22<00:54,  2.02s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  29%|██▉       | 11/38 [00:22<00:54,  2.02s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  32%|███▏      | 12/38 [00:22<00:48,  1.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  32%|███▏      | 12/38 [00:22<00:48,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  34%|███▍      | 13/38 [00:24<00:47,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  34%|███▍      | 13/38 [00:24<00:47,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  37%|███▋      | 14/38 [00:25<00:43,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  37%|███▋      | 14/38 [00:25<00:43,  1.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  39%|███▉      | 15/38 [00:25<00:38,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  39%|███▉      | 15/38 [00:25<00:38,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  42%|████▏     | 16/38 [00:25<00:34,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  42%|████▏     | 16/38 [00:25<00:34,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  45%|████▍     | 17/38 [00:27<00:33,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  45%|████▍     | 17/38 [00:27<00:33,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  50%|█████     | 19/38 [00:27<00:27,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  50%|█████     | 19/38 [00:27<00:27,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  53%|█████▎    | 20/38 [00:28<00:25,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  53%|█████▎    | 20/38 [00:28<00:25,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  55%|█████▌    | 21/38 [00:29<00:24,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  55%|█████▌    | 21/38 [00:29<00:24,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  58%|█████▊    | 22/38 [00:30<00:22,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  58%|█████▊    | 22/38 [00:30<00:22,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  61%|██████    | 23/38 [00:31<00:20,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  61%|██████    | 23/38 [00:31<00:20,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  63%|██████▎   | 24/38 [00:31<00:18,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  63%|██████▎   | 24/38 [00:31<00:18,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  66%|██████▌   | 25/38 [00:32<00:17,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  66%|██████▌   | 25/38 [00:32<00:17,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  76%|███████▋  | 29/38 [00:35<00:10,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  79%|███████▉  | 30/38 [00:35<00:09,  1.18s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:  79%|███████▉  | 30/38 [00:35<00:09,  1.18s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.62it/s]\u001b[A\n",
      "Epoch 74:  82%|████████▏ | 31/38 [00:42<00:09,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.60it/s]\u001b[A\n",
      "Epoch 74:  84%|████████▍ | 32/38 [00:43<00:08,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:01<00:01,  2.92it/s]\u001b[A\n",
      "Epoch 74:  87%|████████▋ | 33/38 [00:43<00:06,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.63it/s]\u001b[A\n",
      "Epoch 74:  89%|████████▉ | 34/38 [00:43<00:05,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.48it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 35/38 [00:45<00:03,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 74:  95%|█████████▍| 36/38 [00:46<00:02,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.54it/s]\u001b[A\n",
      "Epoch 74:  97%|█████████▋| 37/38 [00:47<00:01,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\u001b[A\n",
      "Epoch 74: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 74: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 74:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 75:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:   3%|▎         | 1/38 [00:16<10:26, 16.92s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:   3%|▎         | 1/38 [00:16<10:26, 16.94s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:   5%|▌         | 2/38 [00:17<05:07,  8.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:   5%|▌         | 2/38 [00:17<05:07,  8.55s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:   8%|▊         | 3/38 [00:17<03:21,  5.75s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:   8%|▊         | 3/38 [00:17<03:21,  5.75s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  11%|█         | 4/38 [00:17<02:27,  4.35s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  11%|█         | 4/38 [00:17<02:28,  4.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  13%|█▎        | 5/38 [00:18<02:03,  3.75s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  13%|█▎        | 5/38 [00:18<02:03,  3.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  16%|█▌        | 6/38 [00:18<01:40,  3.15s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  16%|█▌        | 6/38 [00:18<01:40,  3.15s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  18%|█▊        | 7/38 [00:19<01:24,  2.72s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  18%|█▊        | 7/38 [00:19<01:24,  2.72s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  24%|██▎       | 9/38 [00:22<01:10,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  24%|██▎       | 9/38 [00:22<01:10,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  29%|██▉       | 11/38 [00:22<00:54,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  29%|██▉       | 11/38 [00:22<00:54,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  32%|███▏      | 12/38 [00:22<00:48,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  32%|███▏      | 12/38 [00:22<00:48,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  34%|███▍      | 13/38 [00:25<00:49,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  37%|███▋      | 14/38 [00:25<00:44,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  39%|███▉      | 15/38 [00:26<00:40,  1.74s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  39%|███▉      | 15/38 [00:26<00:40,  1.74s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  42%|████▏     | 16/38 [00:26<00:36,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  42%|████▏     | 16/38 [00:26<00:36,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  50%|█████     | 19/38 [00:28<00:28,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  50%|█████     | 19/38 [00:28<00:28,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  66%|██████▌   | 25/38 [00:32<00:17,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  66%|██████▌   | 25/38 [00:32<00:17,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  74%|███████▎  | 28/38 [00:34<00:12,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.89it/s]\u001b[A\n",
      "Epoch 75:  82%|████████▏ | 31/38 [00:44<00:09,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.57it/s]\u001b[A\n",
      "Epoch 75:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.51it/s]\u001b[A\n",
      "Epoch 75:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.30it/s]\u001b[A\n",
      "Epoch 75:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 75:  95%|█████████▍| 36/38 [00:48<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.59it/s]\u001b[A\n",
      "Epoch 75:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 75: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 75: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 75:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 76:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:   3%|▎         | 1/38 [00:16<09:55, 16.09s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:   3%|▎         | 1/38 [00:16<09:55, 16.10s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:   5%|▌         | 2/38 [00:16<04:58,  8.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:   5%|▌         | 2/38 [00:16<04:58,  8.30s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:   8%|▊         | 3/38 [00:16<03:15,  5.58s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:   8%|▊         | 3/38 [00:16<03:15,  5.59s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  11%|█         | 4/38 [00:16<02:23,  4.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  11%|█         | 4/38 [00:16<02:23,  4.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  13%|█▎        | 5/38 [00:19<02:06,  3.83s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  13%|█▎        | 5/38 [00:19<02:06,  3.83s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  16%|█▌        | 6/38 [00:19<01:46,  3.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  18%|█▊        | 7/38 [00:20<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  18%|█▊        | 7/38 [00:20<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  26%|██▋       | 10/38 [00:22<01:02,  2.23s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  26%|██▋       | 10/38 [00:22<01:02,  2.23s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  29%|██▉       | 11/38 [00:22<00:55,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  29%|██▉       | 11/38 [00:22<00:55,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  32%|███▏      | 12/38 [00:22<00:48,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  32%|███▏      | 12/38 [00:22<00:49,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  34%|███▍      | 13/38 [00:23<00:45,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  34%|███▍      | 13/38 [00:23<00:45,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  37%|███▋      | 14/38 [00:24<00:42,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  37%|███▋      | 14/38 [00:24<00:42,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  39%|███▉      | 15/38 [00:24<00:38,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  39%|███▉      | 15/38 [00:24<00:38,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  42%|████▏     | 16/38 [00:25<00:34,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  42%|████▏     | 16/38 [00:25<00:34,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  45%|████▍     | 17/38 [00:26<00:32,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  45%|████▍     | 17/38 [00:26<00:32,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  50%|█████     | 19/38 [00:28<00:28,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  50%|█████     | 19/38 [00:28<00:28,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  53%|█████▎    | 20/38 [00:28<00:25,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  55%|█████▌    | 21/38 [00:28<00:23,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  55%|█████▌    | 21/38 [00:28<00:23,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  58%|█████▊    | 22/38 [00:30<00:22,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  58%|█████▊    | 22/38 [00:30<00:22,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  61%|██████    | 23/38 [00:30<00:20,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  61%|██████    | 23/38 [00:30<00:20,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  63%|██████▎   | 24/38 [00:31<00:18,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  63%|██████▎   | 24/38 [00:31<00:18,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  66%|██████▌   | 25/38 [00:31<00:16,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  66%|██████▌   | 25/38 [00:31<00:16,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  68%|██████▊   | 26/38 [00:33<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  68%|██████▊   | 26/38 [00:33<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=75.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=75.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  71%|███████   | 27/38 [00:34<00:13,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  74%|███████▎  | 28/38 [00:34<00:12,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  76%|███████▋  | 29/38 [00:35<00:10,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  76%|███████▋  | 29/38 [00:35<00:10,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.34it/s]\u001b[A\n",
      "Epoch 76:  82%|████████▏ | 31/38 [00:43<00:09,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.91it/s]\u001b[A\n",
      "Epoch 76:  84%|████████▍ | 32/38 [00:43<00:08,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.43it/s]\u001b[A\n",
      "Epoch 76:  87%|████████▋ | 33/38 [00:43<00:06,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.20it/s]\u001b[A\n",
      "Epoch 76:  89%|████████▉ | 34/38 [00:43<00:05,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 35/38 [00:46<00:03,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.51it/s]\u001b[A\n",
      "Epoch 76:  95%|█████████▍| 36/38 [00:46<00:02,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 76:  97%|█████████▋| 37/38 [00:47<00:01,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\u001b[A\n",
      "Epoch 76: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 76: 100%|██████████| 38/38 [00:47<00:00,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 76:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 77:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:   3%|▎         | 1/38 [00:15<09:44, 15.80s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:   3%|▎         | 1/38 [00:15<09:45, 15.81s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:   5%|▌         | 2/38 [00:17<05:12,  8.67s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:   5%|▌         | 2/38 [00:17<05:12,  8.67s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:   8%|▊         | 3/38 [00:17<03:24,  5.83s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:   8%|▊         | 3/38 [00:17<03:24,  5.84s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  11%|█         | 4/38 [00:17<02:30,  4.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  11%|█         | 4/38 [00:17<02:30,  4.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  13%|█▎        | 5/38 [00:18<02:00,  3.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  13%|█▎        | 5/38 [00:18<02:00,  3.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  16%|█▌        | 6/38 [00:20<01:48,  3.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  16%|█▌        | 6/38 [00:20<01:49,  3.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  18%|█▊        | 7/38 [00:20<01:31,  2.94s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  18%|█▊        | 7/38 [00:20<01:31,  2.94s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  21%|██        | 8/38 [00:20<01:17,  2.59s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  21%|██        | 8/38 [00:20<01:17,  2.59s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  24%|██▎       | 9/38 [00:21<01:09,  2.39s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  34%|███▍      | 13/38 [00:24<00:46,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  34%|███▍      | 13/38 [00:24<00:46,  1.88s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  47%|████▋     | 18/38 [00:28<00:31,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  47%|████▋     | 18/38 [00:28<00:31,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  71%|███████   | 27/38 [00:35<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  74%|███████▎  | 28/38 [00:35<00:12,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:  79%|███████▉  | 30/38 [00:36<00:09,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.52it/s]\u001b[A\n",
      "Epoch 77:  82%|████████▏ | 31/38 [00:44<00:10,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.51it/s]\u001b[A\n",
      "Epoch 77:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.39it/s]\u001b[A\n",
      "Epoch 77:  87%|████████▋ | 33/38 [00:44<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.15it/s]\u001b[A\n",
      "Epoch 77:  89%|████████▉ | 34/38 [00:44<00:05,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 77:  95%|█████████▍| 36/38 [00:47<00:02,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 77:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 77: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 77: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 77:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 78:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:   3%|▎         | 1/38 [00:16<10:14, 16.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:   3%|▎         | 1/38 [00:16<10:15, 16.63s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:   5%|▌         | 2/38 [00:16<05:01,  8.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:   5%|▌         | 2/38 [00:16<05:02,  8.39s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:   8%|▊         | 3/38 [00:16<03:17,  5.65s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:   8%|▊         | 3/38 [00:16<03:17,  5.65s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  11%|█         | 4/38 [00:17<02:25,  4.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  11%|█         | 4/38 [00:17<02:25,  4.28s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  13%|█▎        | 5/38 [00:19<02:09,  3.93s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  13%|█▎        | 5/38 [00:19<02:09,  3.93s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  16%|█▌        | 6/38 [00:19<01:45,  3.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  16%|█▌        | 6/38 [00:19<01:45,  3.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  18%|█▊        | 7/38 [00:19<01:28,  2.85s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  18%|█▊        | 7/38 [00:19<01:28,  2.86s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  21%|██        | 8/38 [00:20<01:15,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  24%|██▎       | 9/38 [00:23<01:14,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  26%|██▋       | 10/38 [00:23<01:05,  2.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  29%|██▉       | 11/38 [00:23<00:57,  2.13s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  29%|██▉       | 11/38 [00:23<00:57,  2.13s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  32%|███▏      | 12/38 [00:23<00:51,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  32%|███▏      | 12/38 [00:23<00:51,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  34%|███▍      | 13/38 [00:26<00:50,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  34%|███▍      | 13/38 [00:26<00:50,  2.04s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  37%|███▋      | 14/38 [00:26<00:45,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  37%|███▋      | 14/38 [00:26<00:45,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  39%|███▉      | 15/38 [00:26<00:41,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  39%|███▉      | 15/38 [00:26<00:41,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  42%|████▏     | 16/38 [00:26<00:37,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  42%|████▏     | 16/38 [00:26<00:37,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  45%|████▍     | 17/38 [00:29<00:36,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  47%|████▋     | 18/38 [00:29<00:33,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  50%|█████     | 19/38 [00:29<00:29,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  50%|█████     | 19/38 [00:30<00:30,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  53%|█████▎    | 20/38 [00:30<00:27,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  55%|█████▌    | 21/38 [00:32<00:26,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  55%|█████▌    | 21/38 [00:32<00:26,  1.55s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  58%|█████▊    | 22/38 [00:32<00:23,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  61%|██████    | 23/38 [00:32<00:21,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  61%|██████    | 23/38 [00:32<00:21,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  63%|██████▎   | 24/38 [00:32<00:19,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  66%|██████▌   | 25/38 [00:35<00:18,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  68%|██████▊   | 26/38 [00:35<00:16,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  71%|███████   | 27/38 [00:35<00:14,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  74%|███████▎  | 28/38 [00:35<00:12,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  76%|███████▋  | 29/38 [00:37<00:11,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:  79%|███████▉  | 30/38 [00:37<00:10,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.49it/s]\u001b[A\n",
      "Epoch 78:  82%|████████▏ | 31/38 [00:45<00:10,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.81it/s]\u001b[A\n",
      "Epoch 78:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.43it/s]\u001b[A\n",
      "Epoch 78:  87%|████████▋ | 33/38 [00:45<00:06,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.19it/s]\u001b[A\n",
      "Epoch 78:  89%|████████▉ | 34/38 [00:45<00:05,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 35/38 [00:48<00:04,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.51it/s]\u001b[A\n",
      "Epoch 78:  95%|█████████▍| 36/38 [00:48<00:02,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.59it/s]\u001b[A\n",
      "Epoch 78:  97%|█████████▋| 37/38 [00:49<00:01,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\u001b[A\n",
      "Epoch 78: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 78: 100%|██████████| 38/38 [00:49<00:00,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 78:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 79:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:   3%|▎         | 1/38 [00:16<10:19, 16.74s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:   3%|▎         | 1/38 [00:16<10:19, 16.75s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:   5%|▌         | 2/38 [00:16<05:04,  8.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:   5%|▌         | 2/38 [00:16<05:04,  8.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:   8%|▊         | 3/38 [00:17<03:19,  5.69s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:   8%|▊         | 3/38 [00:17<03:19,  5.69s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  13%|█▎        | 5/38 [00:19<02:10,  3.95s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  13%|█▎        | 5/38 [00:19<02:10,  3.96s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  18%|█▊        | 7/38 [00:20<01:28,  2.87s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  18%|█▊        | 7/38 [00:20<01:28,  2.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  32%|███▏      | 12/38 [00:23<00:50,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  32%|███▏      | 12/38 [00:23<00:50,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  45%|████▍     | 17/38 [00:28<00:34,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  47%|████▋     | 18/38 [00:28<00:31,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  47%|████▋     | 18/38 [00:28<00:31,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  53%|█████▎    | 20/38 [00:28<00:25,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  53%|█████▎    | 20/38 [00:28<00:25,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  76%|███████▋  | 29/38 [00:37<00:11,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:  79%|███████▉  | 30/38 [00:37<00:09,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.64it/s]\u001b[A\n",
      "Epoch 79:  82%|████████▏ | 31/38 [00:44<00:10,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.63it/s]\u001b[A\n",
      "Epoch 79:  84%|████████▍ | 32/38 [00:45<00:08,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.38it/s]\u001b[A\n",
      "Epoch 79:  87%|████████▋ | 33/38 [00:45<00:06,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.16it/s]\u001b[A\n",
      "Epoch 79:  89%|████████▉ | 34/38 [00:45<00:05,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 35/38 [00:48<00:04,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.53it/s]\u001b[A\n",
      "Epoch 79:  95%|█████████▍| 36/38 [00:48<00:02,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 79:  97%|█████████▋| 37/38 [00:48<00:01,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 79: 100%|██████████| 38/38 [00:48<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79: 100%|██████████| 38/38 [00:48<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 79: 100%|██████████| 38/38 [00:48<00:00,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 79:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 80:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:   3%|▎         | 1/38 [00:15<09:50, 15.95s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:   3%|▎         | 1/38 [00:15<09:50, 15.97s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:   5%|▌         | 2/38 [00:16<05:03,  8.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:   5%|▌         | 2/38 [00:16<05:03,  8.44s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:   8%|▊         | 3/38 [00:17<03:18,  5.67s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:   8%|▊         | 3/38 [00:17<03:18,  5.68s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  11%|█         | 4/38 [00:17<02:25,  4.29s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  11%|█         | 4/38 [00:17<02:26,  4.30s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  13%|█▎        | 5/38 [00:19<02:09,  3.91s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  13%|█▎        | 5/38 [00:19<02:09,  3.92s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  16%|█▌        | 6/38 [00:20<01:47,  3.37s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  16%|█▌        | 6/38 [00:20<01:47,  3.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  18%|█▊        | 7/38 [00:20<01:30,  2.91s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  18%|█▊        | 7/38 [00:20<01:30,  2.91s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  21%|██        | 8/38 [00:20<01:16,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  21%|██        | 8/38 [00:20<01:17,  2.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  26%|██▋       | 10/38 [00:22<01:04,  2.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  26%|██▋       | 10/38 [00:22<01:04,  2.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  29%|██▉       | 11/38 [00:23<00:56,  2.10s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  29%|██▉       | 11/38 [00:23<00:56,  2.10s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  32%|███▏      | 12/38 [00:23<00:50,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  32%|███▏      | 12/38 [00:23<00:50,  1.94s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  34%|███▍      | 13/38 [00:25<00:49,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  37%|███▋      | 14/38 [00:25<00:44,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  39%|███▉      | 15/38 [00:25<00:39,  1.73s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  42%|████▏     | 16/38 [00:26<00:35,  1.63s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  47%|████▋     | 18/38 [00:28<00:31,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  53%|█████▎    | 20/38 [00:28<00:25,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  53%|█████▎    | 20/38 [00:28<00:25,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  58%|█████▊    | 22/38 [00:30<00:22,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  58%|█████▊    | 22/38 [00:30<00:22,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  61%|██████    | 23/38 [00:31<00:20,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  63%|██████▎   | 24/38 [00:31<00:18,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  66%|██████▌   | 25/38 [00:33<00:17,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.53it/s]\u001b[A\n",
      "Epoch 80:  82%|████████▏ | 31/38 [00:43<00:09,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.51it/s]\u001b[A\n",
      "Epoch 80:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.38it/s]\u001b[A\n",
      "Epoch 80:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.15it/s]\u001b[A\n",
      "Epoch 80:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 80:  95%|█████████▍| 36/38 [00:47<00:02,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 80:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\u001b[A\n",
      "Epoch 80: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 80: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 80:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 81:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:   3%|▎         | 1/38 [00:16<10:20, 16.77s/it, loss=1.1, v_num=33, train_acc1_step=8.330, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:   3%|▎         | 1/38 [00:16<10:21, 16.79s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:   5%|▌         | 2/38 [00:16<05:04,  8.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:   5%|▌         | 2/38 [00:16<05:05,  8.47s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:   8%|▊         | 3/38 [00:17<03:19,  5.70s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:   8%|▊         | 3/38 [00:17<03:19,  5.70s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  11%|█         | 4/38 [00:17<02:26,  4.31s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  11%|█         | 4/38 [00:17<02:26,  4.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  13%|█▎        | 5/38 [00:18<02:03,  3.73s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  13%|█▎        | 5/38 [00:18<02:03,  3.73s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  16%|█▌        | 6/38 [00:19<01:41,  3.18s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  16%|█▌        | 6/38 [00:19<01:41,  3.18s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  18%|█▊        | 7/38 [00:19<01:25,  2.75s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  18%|█▊        | 7/38 [00:19<01:25,  2.75s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  21%|██        | 8/38 [00:19<01:12,  2.43s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  21%|██        | 8/38 [00:19<01:12,  2.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  24%|██▎       | 9/38 [00:21<01:10,  2.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  24%|██▎       | 9/38 [00:21<01:10,  2.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  26%|██▋       | 10/38 [00:21<01:01,  2.19s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  26%|██▋       | 10/38 [00:21<01:01,  2.19s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  29%|██▉       | 11/38 [00:22<00:54,  2.01s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  29%|██▉       | 11/38 [00:22<00:54,  2.01s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  32%|███▏      | 12/38 [00:22<00:48,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  32%|███▏      | 12/38 [00:22<00:48,  1.85s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  34%|███▍      | 13/38 [00:24<00:47,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  34%|███▍      | 13/38 [00:24<00:47,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  37%|███▋      | 14/38 [00:24<00:42,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  37%|███▋      | 14/38 [00:24<00:42,  1.77s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  39%|███▉      | 15/38 [00:24<00:38,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  39%|███▉      | 15/38 [00:24<00:38,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  42%|████▏     | 16/38 [00:25<00:34,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  42%|████▏     | 16/38 [00:25<00:34,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  45%|████▍     | 17/38 [00:27<00:33,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  45%|████▍     | 17/38 [00:27<00:33,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  47%|████▋     | 18/38 [00:27<00:30,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  47%|████▋     | 18/38 [00:27<00:30,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  50%|█████     | 19/38 [00:28<00:28,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  50%|█████     | 19/38 [00:28<00:28,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  53%|█████▎    | 20/38 [00:28<00:25,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  53%|█████▎    | 20/38 [00:28<00:25,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  58%|█████▊    | 22/38 [00:30<00:22,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  68%|██████▊   | 26/38 [00:34<00:15,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  76%|███████▋  | 29/38 [00:37<00:11,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  76%|███████▋  | 29/38 [00:37<00:11,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.61it/s]\u001b[A\n",
      "Epoch 81:  82%|████████▏ | 31/38 [00:44<00:10,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.61it/s]\u001b[A\n",
      "Epoch 81:  84%|████████▍ | 32/38 [00:44<00:08,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.50it/s]\u001b[A\n",
      "Epoch 81:  87%|████████▋ | 33/38 [00:45<00:06,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.28it/s]\u001b[A\n",
      "Epoch 81:  89%|████████▉ | 34/38 [00:45<00:05,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.53it/s]\u001b[A\n",
      "Epoch 81:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.63it/s]\u001b[A\n",
      "Epoch 81:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\u001b[A\n",
      "Epoch 81: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 81: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 81:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 82:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:   3%|▎         | 1/38 [00:16<10:18, 16.71s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:   3%|▎         | 1/38 [00:16<10:18, 16.73s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:   5%|▌         | 2/38 [00:16<05:03,  8.44s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:   5%|▌         | 2/38 [00:16<05:04,  8.45s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:   8%|▊         | 3/38 [00:17<03:18,  5.68s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:   8%|▊         | 3/38 [00:17<03:18,  5.68s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  11%|█         | 4/38 [00:17<02:26,  4.30s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  11%|█         | 4/38 [00:17<02:26,  4.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  13%|█▎        | 5/38 [00:19<02:10,  3.96s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  13%|█▎        | 5/38 [00:19<02:10,  3.96s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  16%|█▌        | 6/38 [00:19<01:46,  3.32s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  16%|█▌        | 6/38 [00:19<01:46,  3.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  18%|█▊        | 7/38 [00:20<01:29,  2.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  18%|█▊        | 7/38 [00:20<01:29,  2.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  21%|██        | 8/38 [00:20<01:15,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  21%|██        | 8/38 [00:20<01:16,  2.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  24%|██▎       | 9/38 [00:21<01:10,  2.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  24%|██▎       | 9/38 [00:21<01:10,  2.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  26%|██▋       | 10/38 [00:22<01:02,  2.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  29%|██▉       | 11/38 [00:22<00:54,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  29%|██▉       | 11/38 [00:22<00:54,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  32%|███▏      | 12/38 [00:22<00:48,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  32%|███▏      | 12/38 [00:22<00:48,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  34%|███▍      | 13/38 [00:25<00:49,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  34%|███▍      | 13/38 [00:26<00:50,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  45%|████▍     | 17/38 [00:28<00:34,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  45%|████▍     | 17/38 [00:28<00:34,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  47%|████▋     | 18/38 [00:28<00:31,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  50%|█████     | 19/38 [00:28<00:28,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  53%|█████▎    | 20/38 [00:28<00:25,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  55%|█████▌    | 21/38 [00:31<00:25,  1.48s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  58%|█████▊    | 22/38 [00:31<00:22,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  68%|██████▊   | 26/38 [00:33<00:15,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  74%|███████▎  | 28/38 [00:33<00:12,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  74%|███████▎  | 28/38 [00:33<00:12,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.37it/s]\u001b[A\n",
      "Epoch 82:  82%|████████▏ | 31/38 [00:43<00:09,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.58it/s]\u001b[A\n",
      "Epoch 82:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.33it/s]\u001b[A\n",
      "Epoch 82:  87%|████████▋ | 33/38 [00:44<00:06,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.08it/s]\u001b[A\n",
      "Epoch 82:  89%|████████▉ | 34/38 [00:44<00:05,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.49it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 35/38 [00:46<00:04,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "Epoch 82:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.58it/s]\u001b[A\n",
      "Epoch 82:  97%|█████████▋| 37/38 [00:47<00:01,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\u001b[A\n",
      "Epoch 82: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 82: 100%|██████████| 38/38 [00:47<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 82:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 83:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:   3%|▎         | 1/38 [00:15<09:48, 15.89s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:   3%|▎         | 1/38 [00:15<09:48, 15.90s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:   5%|▌         | 2/38 [00:16<04:48,  8.02s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:   5%|▌         | 2/38 [00:16<04:48,  8.03s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:   8%|▊         | 3/38 [00:16<03:09,  5.40s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:   8%|▊         | 3/38 [00:16<03:09,  5.40s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  11%|█         | 4/38 [00:16<02:20,  4.14s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  11%|█         | 4/38 [00:16<02:21,  4.15s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  13%|█▎        | 5/38 [00:18<02:03,  3.73s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  13%|█▎        | 5/38 [00:18<02:03,  3.74s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  16%|█▌        | 6/38 [00:19<01:41,  3.18s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  16%|█▌        | 6/38 [00:19<01:41,  3.19s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  18%|█▊        | 7/38 [00:19<01:25,  2.75s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  18%|█▊        | 7/38 [00:19<01:25,  2.75s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  21%|██        | 8/38 [00:19<01:14,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  24%|██▎       | 9/38 [00:20<01:06,  2.30s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  24%|██▎       | 9/38 [00:20<01:06,  2.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  26%|██▋       | 10/38 [00:22<01:01,  2.21s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  29%|██▉       | 11/38 [00:22<00:54,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  29%|██▉       | 11/38 [00:22<00:54,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  32%|███▏      | 12/38 [00:22<00:49,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  32%|███▏      | 12/38 [00:22<00:49,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  34%|███▍      | 13/38 [00:23<00:44,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  34%|███▍      | 13/38 [00:23<00:44,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  45%|████▍     | 17/38 [00:26<00:33,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  45%|████▍     | 17/38 [00:26<00:33,  1.58s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  47%|████▋     | 18/38 [00:27<00:30,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  47%|████▋     | 18/38 [00:27<00:30,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  50%|█████     | 19/38 [00:27<00:27,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  50%|█████     | 19/38 [00:27<00:27,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  53%|█████▎    | 20/38 [00:29<00:26,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  53%|█████▎    | 20/38 [00:29<00:26,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  55%|█████▌    | 21/38 [00:30<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  55%|█████▌    | 21/38 [00:30<00:24,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  58%|█████▊    | 22/38 [00:30<00:22,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  58%|█████▊    | 22/38 [00:30<00:22,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  61%|██████    | 23/38 [00:30<00:19,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  61%|██████    | 23/38 [00:30<00:19,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  63%|██████▎   | 24/38 [00:33<00:19,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  63%|██████▎   | 24/38 [00:33<00:19,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  66%|██████▌   | 25/38 [00:33<00:17,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  68%|██████▊   | 26/38 [00:33<00:15,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  71%|███████   | 27/38 [00:33<00:13,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  74%|███████▎  | 28/38 [00:36<00:12,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  76%|███████▋  | 29/38 [00:36<00:11,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.74it/s]\u001b[A\n",
      "Epoch 83:  82%|████████▏ | 31/38 [00:43<00:09,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.51it/s]\u001b[A\n",
      "Epoch 83:  84%|████████▍ | 32/38 [00:44<00:08,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.22it/s]\u001b[A\n",
      "Epoch 83:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.97it/s]\u001b[A\n",
      "Epoch 83:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.46it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 83:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 83:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\u001b[A\n",
      "Epoch 83: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 83: 100%|██████████| 38/38 [00:48<00:00,  1.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 83:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 84:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:   3%|▎         | 1/38 [00:17<10:42, 17.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:   3%|▎         | 1/38 [00:17<10:43, 17.39s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:   5%|▌         | 2/38 [00:17<05:15,  8.77s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:   5%|▌         | 2/38 [00:17<05:15,  8.77s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:   8%|▊         | 3/38 [00:17<03:26,  5.90s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:   8%|▊         | 3/38 [00:17<03:26,  5.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  11%|█         | 4/38 [00:17<02:31,  4.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  11%|█         | 4/38 [00:17<02:31,  4.46s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  13%|█▎        | 5/38 [00:19<02:06,  3.82s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  13%|█▎        | 5/38 [00:19<02:06,  3.82s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  16%|█▌        | 6/38 [00:19<01:42,  3.21s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  16%|█▌        | 6/38 [00:19<01:42,  3.21s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  18%|█▊        | 7/38 [00:19<01:25,  2.77s/it, loss=1.1, v_num=33, train_acc1_step=62.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  18%|█▊        | 7/38 [00:19<01:26,  2.77s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  21%|██        | 8/38 [00:19<01:13,  2.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  21%|██        | 8/38 [00:19<01:13,  2.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  24%|██▎       | 9/38 [00:22<01:12,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  24%|██▎       | 9/38 [00:22<01:13,  2.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  26%|██▋       | 10/38 [00:22<01:03,  2.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  29%|██▉       | 11/38 [00:22<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  34%|███▍      | 13/38 [00:26<00:50,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  34%|███▍      | 13/38 [00:26<00:50,  2.00s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  45%|████▍     | 17/38 [00:29<00:36,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  47%|████▋     | 18/38 [00:29<00:32,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  50%|█████     | 19/38 [00:29<00:29,  1.56s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  53%|█████▎    | 20/38 [00:29<00:26,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  55%|█████▌    | 21/38 [00:32<00:25,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  55%|█████▌    | 21/38 [00:32<00:25,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  58%|█████▊    | 22/38 [00:32<00:23,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  58%|█████▊    | 22/38 [00:32<00:23,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  61%|██████    | 23/38 [00:32<00:21,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  63%|██████▎   | 24/38 [00:32<00:18,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  63%|██████▎   | 24/38 [00:32<00:18,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  66%|██████▌   | 25/38 [00:34<00:18,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  68%|██████▊   | 26/38 [00:34<00:16,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  71%|███████   | 27/38 [00:34<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  71%|███████   | 27/38 [00:34<00:14,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  76%|███████▋  | 29/38 [00:37<00:11,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  76%|███████▋  | 29/38 [00:37<00:11,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.24it/s]\u001b[A\n",
      "Epoch 84:  82%|████████▏ | 31/38 [00:44<00:10,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.77it/s]\u001b[A\n",
      "Epoch 84:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.63it/s]\u001b[A\n",
      "Epoch 84:  87%|████████▋ | 33/38 [00:45<00:06,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.43it/s]\u001b[A\n",
      "Epoch 84:  89%|████████▉ | 34/38 [00:45<00:05,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.47it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.49it/s]\u001b[A\n",
      "Epoch 84:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.61it/s]\u001b[A\n",
      "Epoch 84:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\u001b[A\n",
      "Epoch 84: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 84: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 84:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 85:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:   3%|▎         | 1/38 [00:16<10:02, 16.29s/it, loss=1.1, v_num=33, train_acc1_step=16.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:   3%|▎         | 1/38 [00:16<10:03, 16.30s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:   5%|▌         | 2/38 [00:16<04:56,  8.22s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:   5%|▌         | 2/38 [00:16<04:56,  8.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:   8%|▊         | 3/38 [00:16<03:13,  5.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:   8%|▊         | 3/38 [00:16<03:13,  5.54s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  11%|█         | 4/38 [00:16<02:22,  4.19s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  11%|█         | 4/38 [00:16<02:22,  4.19s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  13%|█▎        | 5/38 [00:19<02:07,  3.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  18%|█▊        | 7/38 [00:19<01:27,  2.83s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  21%|██        | 8/38 [00:19<01:14,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  21%|██        | 8/38 [00:19<01:14,  2.50s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  24%|██▎       | 9/38 [00:22<01:12,  2.51s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  26%|██▋       | 10/38 [00:22<01:03,  2.27s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  29%|██▉       | 11/38 [00:22<00:56,  2.08s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  32%|███▏      | 12/38 [00:23<00:49,  1.92s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  37%|███▋      | 14/38 [00:25<00:43,  1.81s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  37%|███▋      | 14/38 [00:25<00:43,  1.82s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  39%|███▉      | 15/38 [00:25<00:39,  1.70s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  42%|████▏     | 16/38 [00:25<00:35,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  42%|████▏     | 16/38 [00:25<00:35,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  45%|████▍     | 17/38 [00:27<00:34,  1.64s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  47%|████▋     | 18/38 [00:28<00:32,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  47%|████▋     | 18/38 [00:28<00:32,  1.60s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  50%|█████     | 19/38 [00:29<00:29,  1.53s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  53%|█████▎    | 20/38 [00:29<00:26,  1.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  55%|█████▌    | 21/38 [00:31<00:25,  1.49s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  58%|█████▊    | 22/38 [00:31<00:22,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  61%|██████    | 23/38 [00:31<00:20,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  63%|██████▎   | 24/38 [00:31<00:18,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  66%|██████▌   | 25/38 [00:33<00:17,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  76%|███████▋  | 29/38 [00:36<00:11,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:  79%|███████▉  | 30/38 [00:37<00:09,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.31it/s]\u001b[A\n",
      "Epoch 85:  82%|████████▏ | 31/38 [00:44<00:10,  1.43s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.58it/s]\u001b[A\n",
      "Epoch 85:  84%|████████▍ | 32/38 [00:44<00:08,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.24it/s]\u001b[A\n",
      "Epoch 85:  87%|████████▋ | 33/38 [00:45<00:06,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.99it/s]\u001b[A\n",
      "Epoch 85:  89%|████████▉ | 34/38 [00:45<00:05,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.42it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 35/38 [00:47<00:04,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 85:  95%|█████████▍| 36/38 [00:48<00:02,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.60it/s]\u001b[A\n",
      "Epoch 85:  97%|█████████▋| 37/38 [00:48<00:01,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\u001b[A\n",
      "Epoch 85: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 85: 100%|██████████| 38/38 [00:48<00:00,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 85:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 86:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:   3%|▎         | 1/38 [00:16<10:07, 16.41s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:   3%|▎         | 1/38 [00:16<10:07, 16.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:   5%|▌         | 2/38 [00:16<04:58,  8.29s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:   8%|▊         | 3/38 [00:16<03:16,  5.62s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:   8%|▊         | 3/38 [00:16<03:16,  5.63s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  11%|█         | 4/38 [00:17<02:24,  4.26s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  11%|█         | 4/38 [00:17<02:24,  4.26s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  13%|█▎        | 5/38 [00:19<02:07,  3.86s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  13%|█▎        | 5/38 [00:19<02:07,  3.86s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  16%|█▌        | 6/38 [00:19<01:43,  3.24s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  16%|█▌        | 6/38 [00:19<01:43,  3.25s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  18%|█▊        | 7/38 [00:20<01:29,  2.89s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  21%|██        | 8/38 [00:20<01:16,  2.55s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  24%|██▎       | 9/38 [00:22<01:11,  2.47s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  24%|██▎       | 9/38 [00:22<01:11,  2.48s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  26%|██▋       | 10/38 [00:22<01:02,  2.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  26%|██▋       | 10/38 [00:22<01:02,  2.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  29%|██▉       | 11/38 [00:23<00:57,  2.13s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  32%|███▏      | 12/38 [00:23<00:51,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  32%|███▏      | 12/38 [00:23<00:51,  1.97s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  34%|███▍      | 13/38 [00:25<00:48,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  37%|███▋      | 14/38 [00:25<00:43,  1.80s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  39%|███▉      | 15/38 [00:26<00:40,  1.75s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  42%|████▏     | 16/38 [00:26<00:36,  1.65s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  45%|████▍     | 17/38 [00:27<00:34,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  47%|████▋     | 18/38 [00:27<00:30,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  53%|█████▎    | 20/38 [00:29<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  55%|█████▌    | 21/38 [00:30<00:24,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  58%|█████▊    | 22/38 [00:30<00:22,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  58%|█████▊    | 22/38 [00:30<00:22,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=6.250, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  61%|██████    | 23/38 [00:31<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  66%|██████▌   | 25/38 [00:33<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  66%|██████▌   | 25/38 [00:33<00:17,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  68%|██████▊   | 26/38 [00:33<00:15,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  68%|██████▊   | 26/38 [00:33<00:15,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  76%|███████▋  | 29/38 [00:35<00:11,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:  79%|███████▉  | 30/38 [00:35<00:09,  1.19s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:01,  3.56it/s]\u001b[A\n",
      "Epoch 86:  82%|████████▏ | 31/38 [00:43<00:09,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.62it/s]\u001b[A\n",
      "Epoch 86:  84%|████████▍ | 32/38 [00:43<00:08,  1.36s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.43it/s]\u001b[A\n",
      "Epoch 86:  87%|████████▋ | 33/38 [00:43<00:06,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:00<00:00,  4.19it/s]\u001b[A\n",
      "Epoch 86:  89%|████████▉ | 34/38 [00:43<00:05,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.47it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 35/38 [00:46<00:03,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:04<00:01,  1.48it/s]\u001b[A\n",
      "Epoch 86:  95%|█████████▍| 36/38 [00:46<00:02,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.57it/s]\u001b[A\n",
      "Epoch 86:  97%|█████████▋| 37/38 [00:47<00:01,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 86: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 86: 100%|██████████| 38/38 [00:47<00:00,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 86:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 87:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:   3%|▎         | 1/38 [00:17<10:33, 17.13s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:   3%|▎         | 1/38 [00:17<10:34, 17.14s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:   5%|▌         | 2/38 [00:17<05:11,  8.64s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:   5%|▌         | 2/38 [00:17<05:11,  8.65s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:   8%|▊         | 3/38 [00:17<03:23,  5.81s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:   8%|▊         | 3/38 [00:17<03:23,  5.82s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  11%|█         | 4/38 [00:17<02:29,  4.40s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  13%|█▎        | 5/38 [00:18<02:05,  3.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  13%|█▎        | 5/38 [00:18<02:05,  3.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  16%|█▌        | 6/38 [00:19<01:43,  3.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  16%|█▌        | 6/38 [00:19<01:43,  3.23s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  18%|█▊        | 7/38 [00:19<01:26,  2.79s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  18%|█▊        | 7/38 [00:19<01:26,  2.79s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  21%|██        | 8/38 [00:19<01:13,  2.46s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  24%|██▎       | 9/38 [00:22<01:12,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  24%|██▎       | 9/38 [00:22<01:12,  2.49s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  26%|██▋       | 10/38 [00:22<01:03,  2.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  26%|██▋       | 10/38 [00:22<01:03,  2.26s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  29%|██▉       | 11/38 [00:22<00:55,  2.06s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  29%|██▉       | 11/38 [00:22<00:55,  2.07s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  32%|███▏      | 12/38 [00:22<00:49,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  32%|███▏      | 12/38 [00:22<00:49,  1.91s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  34%|███▍      | 13/38 [00:25<00:48,  1.96s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  37%|███▋      | 14/38 [00:25<00:43,  1.83s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  39%|███▉      | 15/38 [00:25<00:39,  1.72s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  42%|████▏     | 16/38 [00:25<00:35,  1.62s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  45%|████▍     | 17/38 [00:28<00:35,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  45%|████▍     | 17/38 [00:28<00:35,  1.67s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  50%|█████     | 19/38 [00:28<00:28,  1.51s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  53%|█████▎    | 20/38 [00:28<00:25,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  53%|█████▎    | 20/38 [00:28<00:25,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  58%|█████▊    | 22/38 [00:31<00:22,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  58%|█████▊    | 22/38 [00:31<00:22,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  66%|██████▌   | 25/38 [00:34<00:17,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  68%|██████▊   | 26/38 [00:34<00:16,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  68%|██████▊   | 26/38 [00:34<00:16,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  71%|███████   | 27/38 [00:34<00:14,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  74%|███████▎  | 28/38 [00:35<00:12,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  3.24it/s]\u001b[A\n",
      "Epoch 87:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.87it/s]\u001b[A\n",
      "Epoch 87:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.10it/s]\u001b[A\n",
      "Epoch 87:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.84it/s]\u001b[A\n",
      "Epoch 87:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.41it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 35/38 [00:47<00:04,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 87:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 87:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\u001b[A\n",
      "Epoch 87: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 87: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 87:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 88:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:   3%|▎         | 1/38 [00:17<10:36, 17.21s/it, loss=1.1, v_num=33, train_acc1_step=33.30, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:   3%|▎         | 1/38 [00:17<10:37, 17.22s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:   5%|▌         | 2/38 [00:17<05:12,  8.68s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:   5%|▌         | 2/38 [00:17<05:12,  8.69s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:   8%|▊         | 3/38 [00:17<03:24,  5.84s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:   8%|▊         | 3/38 [00:17<03:24,  5.84s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  11%|█         | 4/38 [00:17<02:30,  4.42s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  11%|█         | 4/38 [00:17<02:30,  4.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  13%|█▎        | 5/38 [00:20<02:14,  4.08s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  13%|█▎        | 5/38 [00:20<02:14,  4.08s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  16%|█▌        | 6/38 [00:20<01:49,  3.43s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  16%|█▌        | 6/38 [00:20<01:49,  3.43s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  18%|█▊        | 7/38 [00:20<01:31,  2.96s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  21%|██        | 8/38 [00:20<01:18,  2.61s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  24%|██▎       | 9/38 [00:23<01:14,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  24%|██▎       | 9/38 [00:23<01:14,  2.58s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  26%|██▋       | 10/38 [00:23<01:05,  2.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  26%|██▋       | 10/38 [00:23<01:05,  2.34s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  29%|██▉       | 11/38 [00:23<00:57,  2.14s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  32%|███▏      | 12/38 [00:23<00:51,  1.98s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  34%|███▍      | 13/38 [00:26<00:50,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  34%|███▍      | 13/38 [00:26<00:50,  2.03s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  37%|███▋      | 14/38 [00:26<00:45,  1.89s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  37%|███▋      | 14/38 [00:26<00:45,  1.90s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  39%|███▉      | 15/38 [00:26<00:40,  1.78s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  42%|████▏     | 16/38 [00:26<00:36,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  42%|████▏     | 16/38 [00:26<00:36,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  45%|████▍     | 17/38 [00:28<00:35,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  45%|████▍     | 17/38 [00:28<00:35,  1.68s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  47%|████▋     | 18/38 [00:28<00:31,  1.59s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  50%|█████     | 19/38 [00:28<00:28,  1.52s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  53%|█████▎    | 20/38 [00:28<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  53%|█████▎    | 20/38 [00:28<00:26,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  55%|█████▌    | 21/38 [00:31<00:25,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  58%|█████▊    | 22/38 [00:31<00:22,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  58%|█████▊    | 22/38 [00:31<00:22,  1.44s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  61%|██████    | 23/38 [00:31<00:20,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  63%|██████▎   | 24/38 [00:31<00:18,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  66%|██████▌   | 25/38 [00:34<00:17,  1.37s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  68%|██████▊   | 26/38 [00:34<00:15,  1.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  71%|███████   | 27/38 [00:34<00:14,  1.28s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  74%|███████▎  | 28/38 [00:34<00:12,  1.24s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  76%|███████▋  | 29/38 [00:36<00:11,  1.25s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:  79%|███████▉  | 30/38 [00:36<00:09,  1.22s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.69it/s]\u001b[A\n",
      "Epoch 88:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:02,  2.60it/s]\u001b[A\n",
      "Epoch 88:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.22it/s]\u001b[A\n",
      "Epoch 88:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.97it/s]\u001b[A\n",
      "Epoch 88:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:01,  1.52it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 35/38 [00:46<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.50it/s]\u001b[A\n",
      "Epoch 88:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.54it/s]\u001b[A\n",
      "Epoch 88:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\u001b[A\n",
      "Epoch 88: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 88: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 88:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]         \n",
      "Epoch 89:   0%|          | 0/38 [00:00<?, ?it/s, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:   3%|▎         | 1/38 [00:16<09:59, 16.20s/it, loss=1.1, v_num=33, train_acc1_step=41.70, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:   3%|▎         | 1/38 [00:16<09:59, 16.21s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:   5%|▌         | 2/38 [00:16<05:00,  8.34s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:   5%|▌         | 2/38 [00:16<05:00,  8.35s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:   8%|▊         | 3/38 [00:16<03:16,  5.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:   8%|▊         | 3/38 [00:16<03:16,  5.62s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  11%|█         | 4/38 [00:16<02:24,  4.25s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  11%|█         | 4/38 [00:17<02:24,  4.25s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  13%|█▎        | 5/38 [00:18<02:01,  3.69s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  13%|█▎        | 5/38 [00:18<02:01,  3.69s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  16%|█▌        | 6/38 [00:19<01:46,  3.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  16%|█▌        | 6/38 [00:19<01:46,  3.33s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  18%|█▊        | 7/38 [00:20<01:29,  2.88s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  21%|██        | 8/38 [00:20<01:16,  2.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  24%|██▎       | 9/38 [00:21<01:10,  2.42s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  24%|██▎       | 9/38 [00:21<01:10,  2.42s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  26%|██▋       | 10/38 [00:22<01:04,  2.29s/it, loss=1.1, v_num=33, train_acc1_step=68.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  26%|██▋       | 10/38 [00:22<01:04,  2.29s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  29%|██▉       | 11/38 [00:23<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  29%|██▉       | 11/38 [00:23<00:56,  2.09s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  32%|███▏      | 12/38 [00:23<00:50,  1.93s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  34%|███▍      | 13/38 [00:23<00:45,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  34%|███▍      | 13/38 [00:23<00:45,  1.84s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  37%|███▋      | 14/38 [00:26<00:44,  1.87s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  39%|███▉      | 15/38 [00:26<00:40,  1.76s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  42%|████▏     | 16/38 [00:26<00:36,  1.66s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  45%|████▍     | 17/38 [00:26<00:32,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  45%|████▍     | 17/38 [00:26<00:32,  1.57s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  47%|████▋     | 18/38 [00:29<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  47%|████▋     | 18/38 [00:29<00:32,  1.61s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=37.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  50%|█████     | 19/38 [00:29<00:29,  1.54s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  53%|█████▎    | 20/38 [00:29<00:26,  1.47s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  55%|█████▌    | 21/38 [00:29<00:23,  1.40s/it, loss=1.1, v_num=33, train_acc1_step=43.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  55%|█████▌    | 21/38 [00:29<00:23,  1.41s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  58%|█████▊    | 22/38 [00:31<00:23,  1.45s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  61%|██████    | 23/38 [00:32<00:20,  1.39s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=31.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  63%|██████▎   | 24/38 [00:32<00:18,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  66%|██████▌   | 25/38 [00:32<00:16,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=18.80, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  66%|██████▌   | 25/38 [00:32<00:16,  1.29s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  68%|██████▊   | 26/38 [00:34<00:15,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=56.20, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  71%|███████   | 27/38 [00:34<00:13,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=25.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  74%|███████▎  | 28/38 [00:34<00:12,  1.23s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  76%|███████▋  | 29/38 [00:34<00:10,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=12.50, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  76%|███████▋  | 29/38 [00:34<00:10,  1.20s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89:  79%|███████▉  | 30/38 [00:36<00:09,  1.21s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "\n",
      "Validation:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validation DataLoader 0:  12%|█▎        | 1/8 [00:00<00:02,  2.86it/s]\u001b[A\n",
      "Epoch 89:  82%|████████▏ | 31/38 [00:43<00:09,  1.42s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  25%|██▌       | 2/8 [00:00<00:01,  3.22it/s]\u001b[A\n",
      "Epoch 89:  84%|████████▍ | 32/38 [00:44<00:08,  1.38s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  38%|███▊      | 3/8 [00:00<00:01,  3.26it/s]\u001b[A\n",
      "Epoch 89:  87%|████████▋ | 33/38 [00:44<00:06,  1.35s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  50%|█████     | 4/8 [00:01<00:01,  3.99it/s]\u001b[A\n",
      "Epoch 89:  89%|████████▉ | 34/38 [00:44<00:05,  1.31s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  62%|██████▎   | 5/8 [00:03<00:02,  1.44it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 35/38 [00:47<00:04,  1.34s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  75%|███████▌  | 6/8 [00:03<00:01,  1.52it/s]\u001b[A\n",
      "Epoch 89:  95%|█████████▍| 36/38 [00:47<00:02,  1.32s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0:  88%|████████▊ | 7/8 [00:04<00:00,  1.56it/s]\u001b[A\n",
      "Epoch 89:  97%|█████████▋| 37/38 [00:48<00:01,  1.30s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\u001b[A\n",
      "Epoch 89: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "\n",
      "                                                                      \u001b[A\n",
      "Epoch 89: 100%|██████████| 38/38 [00:48<00:00,  1.27s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n",
      "Epoch 89: 100%|██████████| 38/38 [00:56<00:00,  1.50s/it, loss=1.1, v_num=33, train_acc1_step=50.00, val_acc1_step=50.00, val_acc1_epoch=30.00, train_acc1_epoch=34.20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | normalize | Normalize | 0     \n",
      "1 | model     | VGG       | 139 M \n",
      "----------------------------------------\n",
      "139 M     Trainable params\n",
      "0         Non-trainable params\n",
      "139 M     Total params\n",
      "279.165   Total estimated model params size (MB)\n",
      "c:\\Users\\yannn\\miniconda3\\envs\\lightning\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1609: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=90` reached.\n",
      "FIT Profiler Report\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "|  Action                                                                                                                                                         \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "|  Total                                                                                                                                                          \t|  -              \t|  135647         \t|  5220.4         \t|  100 %          \t|\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "|  run_training_epoch                                                                                                                                             \t|  49.163         \t|  90             \t|  4424.7         \t|  84.758         \t|\n",
      "\n",
      "|  [TrainingEpochLoop].train_dataloader_next                                                                                                                      \t|  0.59814        \t|  2700           \t|  1615.0         \t|  30.936         \t|\n",
      "\n",
      "|  [EvaluationEpochLoop].val_dataloader_idx_0_next                                                                                                                \t|  1.2593         \t|  720            \t|  906.69         \t|  17.368         \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  8.6983         \t|  90             \t|  782.85         \t|  14.996         \t|\n",
      "\n",
      "|  run_training_batch                                                                                                                                             \t|  0.16532        \t|  2700           \t|  446.38         \t|  8.5506         \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.optimizer_step                                                                                                         \t|  0.16489        \t|  2700           \t|  445.2          \t|  8.5281         \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                   \t|  0.084017       \t|  2700           \t|  226.85         \t|  4.3454         \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                 \t|  0.12321        \t|  722            \t|  88.959         \t|  1.7041         \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                   \t|  0.013498       \t|  2700           \t|  36.445         \t|  0.69812        \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                        \t|  0.0092715      \t|  2700           \t|  25.033         \t|  0.47952        \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                 \t|  0.0040508      \t|  3422           \t|  13.862         \t|  0.26553        \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.transfer_batch_to_device                                                                                               \t|  0.0039965      \t|  3422           \t|  13.676         \t|  0.26197        \t|\n",
      "\n",
      "|  [EvaluationEpochLoop].None_dataloader_idx_0_next                                                                                                               \t|  3.3905         \t|  2              \t|  6.781          \t|  0.12989        \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.optimizer_zero_grad                                                                                                    \t|  0.0006463      \t|  2700           \t|  1.745          \t|  0.033426       \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                              \t|  0.00041551     \t|  722            \t|  0.3            \t|  0.0057467      \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  6.4074e-05     \t|  2700           \t|  0.173          \t|  0.0033139      \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.configure_gradient_clipping                                                                                            \t|  3.4444e-05     \t|  2700           \t|  0.093          \t|  0.0017815      \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                            \t|  8.8643e-05     \t|  722            \t|  0.064          \t|  0.001226       \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                    \t|  0.00069231     \t|  91             \t|  0.063          \t|  0.0012068      \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.lr_scheduler_step                                                                                                      \t|  0.00067778     \t|  90             \t|  0.061          \t|  0.0011685      \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                    \t|  1.7407e-05     \t|  2700           \t|  0.047          \t|  0.00090031     \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                  \t|  0.00035165     \t|  91             \t|  0.032          \t|  0.00061298     \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_zero_grad                                                                                                    \t|  1.1852e-05     \t|  2700           \t|  0.032          \t|  0.00061298     \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                   \t|  1.1852e-05     \t|  2700           \t|  0.032          \t|  0.00061298     \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                      \t|  1.1852e-05     \t|  2700           \t|  0.032          \t|  0.00061298     \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                             \t|  1.1481e-05     \t|  2700           \t|  0.031          \t|  0.00059382     \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                            \t|  0.016          \t|  1              \t|  0.016          \t|  0.00030649     \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.val_dataloader                                                                                                         \t|  0.016          \t|  1              \t|  0.016          \t|  0.00030649     \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_validation_model_eval                                                                                               \t|  0.00017582     \t|  91             \t|  0.016          \t|  0.00030649     \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  0.00017582     \t|  91             \t|  0.016          \t|  0.00030649     \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.train_dataloader                                                                                                       \t|  0.016          \t|  1              \t|  0.016          \t|  0.00030649     \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                    \t|  5.9259e-06     \t|  2700           \t|  0.016          \t|  0.00030649     \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                     \t|  5.9259e-06     \t|  2700           \t|  0.016          \t|  0.00030649     \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_backward                                                                                                     \t|  5.9259e-06     \t|  2700           \t|  0.016          \t|  0.00030649     \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                 \t|  5.5556e-06     \t|  2700           \t|  0.015          \t|  0.00028733     \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                            \t|  5.5556e-06     \t|  2700           \t|  0.015          \t|  0.00028733     \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  5.5556e-06     \t|  2700           \t|  0.015          \t|  0.00028733     \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_after_backward                                                                                                      \t|  5.5556e-06     \t|  2700           \t|  0.015          \t|  0.00028733     \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                   \t|  0.00016667     \t|  90             \t|  0.015          \t|  0.00028733     \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.configure_callbacks                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.prepare_data                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.setup                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.setup                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.configure_sharded_model                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.configure_optimizers                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_fit_start                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_fit_start                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_sanity_check_start                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                     \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_start                                                                                                    \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_validation_start                                                                                                    \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                             \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                            \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                               \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_epoch_start                                                                                              \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_validation_epoch_start                                                                                              \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_before_batch_transfer                                                                                               \t|  0.0            \t|  3422           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_after_batch_transfer                                                                                                \t|  0.0            \t|  3422           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                               \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_batch_start                                                                                              \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_validation_batch_start                                                                                              \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.validation_step_end                                                                                                    \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step_end                                                                                                             \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                 \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_batch_end                                                                                                \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_validation_batch_end                                                                                                \t|  0.0            \t|  722            \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.validation_epoch_end                                                                                                   \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                              \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                 \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_epoch_end                                                                                                \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_validation_epoch_end                                                                                                \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                       \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_validation_end                                                                                                      \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_validation_end                                                                                                      \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                               \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_validation_model_train                                                                                              \t|  0.0            \t|  91             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_sanity_check_end                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_start                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_train_start                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                 \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                    \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_epoch_start                                                                                                   \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_train_epoch_start                                                                                                   \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_batch_start                                                                                                   \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_train_batch_start                                                                                                   \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.training_step_end                                                                                                      \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.training_step_end                                                                                                               \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                  \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_before_zero_grad                                                                                                    \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                      \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_before_backward                                                                                                     \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                       \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_after_backward                                                                                                      \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_optimizer_step                                                                                               \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_before_optimizer_step                                                                                               \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_batch_end                                                                                                     \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_train_batch_end                                                                                                     \t|  0.0            \t|  2700           \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                      \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_epoch_end                                                                                                     \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                   \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                      \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_save_checkpoint                                                                                                     \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_save_checkpoint                                                                                                     \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_train_epoch_end                                                                                                     \t|  0.0            \t|  90             \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_end                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_train_end                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.on_fit_end                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.on_fit_end                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]GradientAccumulationScheduler.teardown                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "|  [LightningModule]ImageNetLightningModel.teardown                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python imagenet.py --arch vgg19 --num-classes 3 --accelerator gpu --batch-size 16 --precision 16 --data-path images/ --annotation-path D:/Github/TCC/ISIC/subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from imagenet import ImageNetLightningModel\n",
    "from torch.nn.functional import softmax\n",
    "from torchvision.io import read_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "*************** Loading model vgg19\n",
      "********************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageNetLightningModel(\n",
       "  (normalize): Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "  (model): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): ReLU(inplace=True)\n",
       "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (33): ReLU(inplace=True)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImageNetLightningModel.load_from_checkpoint(checkpoint_path=r'lightning_logs\\version_33\\checkpoints\\epoch=89-step=2700.ckpt', map_location=torch.device('cuda'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(read_image('images/ISIC_0025076.jpg').type(torch.float32) / 255).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = softmax(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3219, 0.3414, 0.3367]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf77e511ba9a774c6a5fec27afb257981cf7bf94e13d86a44eae1f22da98919e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
